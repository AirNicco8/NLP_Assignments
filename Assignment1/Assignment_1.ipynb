{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AirNicco8/NLP_Assignments/blob/main/Assignment1/A1_biLSTM256_2DENSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Due to**: 23/12/2021 (dd/mm/yyyy)\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Part-of Speech (POS) tagging as Sequence Labelling using Recurrent Neural Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4_wqPdlBcKS"
      },
      "source": [
        "# Intro\n",
        "\n",
        "In this assignment  we will ask you to perform POS tagging using neural architectures\n",
        "\n",
        "You are asked to follow these steps:\n",
        "*   Download the corpora and split it in training and test sets, structuring a dataframe.\n",
        "*   Embed the words using GloVe embeddings\n",
        "*   Create a baseline model, using a simple neural architecture\n",
        "*   Experiment doing small modifications to the baseline model, choose hyperparameters using the validation set\n",
        "*   Evaluate your two best model\n",
        "*   Analyze the errors of your model\n",
        "\n",
        "\n",
        "**Task**: given a corpus of documents, predict the POS tag for each word\n",
        "\n",
        "**Corpus**:\n",
        "Ignore the numeric value in the third column, use only the words/symbols and its label. \n",
        "The corpus is available at:\n",
        "https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\n",
        "\n",
        "**Splits**: documents 1-100 are the train set, 101-150 validation set, 151-199 test set.\n",
        "\n",
        "\n",
        "**Features**: you MUST use GloVe embeddings as the only input features to the model.\n",
        "\n",
        "**Splitting**: you can decide to split documents into sentences or not, the choice is yours.\n",
        "\n",
        "**I/O structure**: The input data will have three dimensions: 1-documents/sentences, 2-token, 3-features; for the output there are 2 possibilities: if you use one-hot encoding it will be 1-documents/sentences, 2-token labels, 3-classes, if you use a single integer that indicates the number of the class it will be 1-documents/sentences, 2-token labels.\n",
        "\n",
        "**Baseline**: two layers architecture: a Bidirectional LSTM layer and a Dense/Fully-Connected layer on top; the choice of hyper-parameters is yours.\n",
        "\n",
        "**Architectures**: experiment using a GRU instead of the LSTM, adding an additional LSTM layer, and adding an additional dense layer; do not mix these variantions.\n",
        "\n",
        "\n",
        "**Training and Experiments**: all the experiments must involve only the training and validation sets.\n",
        "\n",
        "**Evaluation**: in the end, only the two best models of your choice (according to the validation set) must be evaluated on the test set. The main metric must be F1-Macro computed between the various part of speech. DO NOT CONSIDER THE PUNCTUATION CLASSES.\n",
        "\n",
        "**Metrics**: the metric you must use to evaluate your final model is the F1-macro, WITHOUT considering punctuation/symbols classes; during the training process you can use accuracy because you can't use the F1 metric unless you use a single (gigantic) batch because there is no way to aggregate \"partial\" F1 scores computed on mini-batches.\n",
        "\n",
        "**Discussion and Error Analysis** : verify and discuss if the results on the test sets are coherent with those on the validation set; analyze the errors done by your model, try to understand which may be the causes and think about how to improve it.\n",
        "\n",
        "**Report**: you are asked to deliver the code of your experiments and a small pdf report of about 2 pages; the pdf must begin with the names of the people of your team and a small abstract (4-5 lines) that sums up your findings.\n",
        "\n",
        "# Out Of Vocabulary (OOV) terms\n",
        "\n",
        "How to handle words that are not in GloVe vocabulary?\n",
        "You can handle them as you want (random embedding, placeholder, whatever!), but they must be STATIC embeddings (you cannot train them).\n",
        "\n",
        "But there is a very important caveat! As usual, the element of the test set must not influence the elements of the other splits!\n",
        "\n",
        "So, when you compute new embeddings for train+validation, you must forget about test documents.\n",
        "The motivation is to emulate a real-world scenario, where you select and train a model in the first stage, without knowing nothing about the testing environment.\n",
        "\n",
        "For implementation convenience, you CAN use a single vocabulary file/matrix/whatever. The principle of the previous point is that the embeddings inside that file/matrix must be generated independently for train and test splits.\n",
        "\n",
        "Basically in a real-world scenario, this is what would happen:\n",
        "1. Starting vocabulary V1 (in this assignment, GloVe vocabulary)\n",
        "2. Compute embeddings for terms out of vocabulary V1 (OOV1) of the training split \n",
        "3. Add embeddings to the vocabulary, so to obtain vocabulary V2=V1+OOV1\n",
        "4. Training of the model(s)\n",
        "5. Compute embeddings for terms OOV2 of the validation split \n",
        "6. Add embeddings to the vocabulary, so to obtain vocabulary V3=V1+OOV1+OOV2\n",
        "7. Validation of the model(s)\n",
        "8. Compute embeddings for terms OOV3 of the test split \n",
        "9. Add embeddings to the vocabulary, so to obtain vocabulary V4=V1+OOV1+OOV2+OOV3\n",
        "10. Testing of the final model\n",
        "\n",
        "In this case, where we already have all the documents, we can simplify the process a bit, but the procedure must remain rigorous.\n",
        "\n",
        "1. Starting vocabulary V1 (in this assignment, GloVe vocabulary)\n",
        "2. Compute embeddings for terms out of vocabulary V1 (OOV1) of the training split \n",
        "3. Add embeddings to the vocabulary, so to obtain vocabulary V2=V1+OOV1\n",
        "4. Compute embeddings for terms OOV2 of the validation split \n",
        "5. Add embeddings to the vocabulary, so to obtain vocabulary V3=V1+OOV1+OOV2\n",
        "6. Compute embeddings for terms OOV3 of the test split \n",
        "7. Add embeddings to the vocabulary, so to obtain vocabulary V4=V1+OOV1+OOV2\n",
        "8. Training of the model(s)\n",
        "9. Validation of the model(s)\n",
        "10. Testing of the final model\n",
        "\n",
        "Step 2 and step 6 must be completely independent of each other, for what concerns the method and the documents. But they can rely on the previous vocabulary (V1 for step 2 and V3 for step 6)\n",
        "THEREFORE if a word is present both in the training set and the test split and not in the starting vocabulary, its embedding is computed in step 2) and it is not considered OOV anymore in step 6).\n",
        "\n",
        "# Report\n",
        "The report must not be just a copy and paste of graphs and tables!\n",
        "\n",
        "The report must not be longer than 2 pages and must contain:\n",
        "* The names of the member of your team\n",
        "* A short abstract (4-5 lines) that sum ups everything\n",
        "* A general description of the task you have addressed and how you have addressed it\n",
        "* A short description of the models you have used\n",
        "* Some tables that sum up your findings in validation and test and a discussion of those results\n",
        "* The most relevant findings of your error analysis\n",
        "\n",
        "# Evaluation Criterion\n",
        "\n",
        "The goal of this assignment is not to prove you can find best model ever, but to face a common task, structure it correctly, and follow a correct and rigorous experimental procedure.\n",
        "In other words, we don't care if you final models are awful as long as you have followed the correct procedure and wrote a decent report.\n",
        "\n",
        "The score of the assignment will be computed roughly as follows\n",
        "* 1 point for the general setting of the problem\n",
        "* 1 point for the handling of OOV terms\n",
        "* 1 point for the models\n",
        "* 1 point for train-validation-test procedure\n",
        "* 2 point for the discussion of the results, error analysis, and report\n",
        "\n",
        "This distribution of scores is tentative and we may decide to alter it at any moment.\n",
        "We also reserve the right to assign a small bonus (0.5 points) to any assignment that is particularly worthy. Similarly, in case of grave errors, we may decide to assign an equivalent malus (-0.5 points).\n",
        "\n",
        "# Contacts\n",
        "\n",
        "In case of any doubt, question, issue, or help we highly recommend you to check the [course useful material](https://virtuale.unibo.it/pluginfile.php/1036039/mod_resource/content/2/NLP_Course_Useful_Material.pdf) for additional information, and to use the Virtuale forums to discuss with other students.\n",
        "\n",
        "You can always contact us at the following email addresses. To increase the probability of a prompt response, we reccomend you to write to both the teaching assistants.\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it\n",
        "\n",
        "\n",
        "# FAQ\n",
        "* You can use a non-trainable Embedding layer to load the glove embeddings\n",
        "* You can use any library of your choice to implement the networks. Two options are tensorflow/keras or pythorch. Both these libraries have all the classes you need to implement these simple architectures and there are plenty of tutorials around, where you can learn how to use them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usG1eafJvaQ4"
      },
      "source": [
        "# Preparation of the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iUsOu-UvaQ4"
      },
      "source": [
        "## Import the basic libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "emdubW66fnlD"
      },
      "outputs": [],
      "source": [
        "import os, shutil  #  file management\n",
        "import sys \n",
        "import pandas as pd  #  dataframe management\n",
        "import numpy as np  #  data manipulation\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request  #  download files\n",
        "import zipfile  #  unzip files\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6B-w2pqyfpF1"
      },
      "outputs": [],
      "source": [
        "from keras import metrics \n",
        "from tensorflow.python.keras.metrics import Metric\n",
        "from sklearn.metrics import f1_score\n",
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFvajV2sni19",
        "outputId": "6f360e26-d607-4feb-e9e0-05e392ef26d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3qoNG45vaQ6"
      },
      "source": [
        "## Download the dataset\n",
        "Use the Dependency Treebank corpora from nltk. Download and extract it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3xn1MZPgA_v",
        "outputId": "7bed9a48-f95a-4912-c1f4-1d9ec84c59e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful download\n",
            "Successful extraction\n"
          ]
        }
      ],
      "source": [
        "dataset_folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\")\n",
        "\n",
        "if not os.path.exists(dataset_folder):\n",
        "    os.makedirs(dataset_folder)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip'\n",
        "\n",
        "dataset_path = os.path.join(dataset_folder, \"treebank.zip\")\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    urllib.request.urlretrieve(url, dataset_path)\n",
        "    print(\"Successful download\")\n",
        "\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_folder)\n",
        "print(\"Successful extraction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiO1v6SJmm37"
      },
      "source": [
        "# Pre Processing\n",
        "Reorder files and split train, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LKbUsrVHhGAG"
      },
      "outputs": [],
      "source": [
        "dataset_name = \"dependency_treebank\"\n",
        "\n",
        "\n",
        "folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\", dataset_name)\n",
        "\n",
        "pre_train = []\n",
        "pre_valid = []\n",
        "pre_test = []\n",
        "i = 1\n",
        "\n",
        "file_list = sorted(os.listdir(folder))\n",
        "\n",
        "for filename in file_list:\n",
        "  file_path = os.path.join(folder, filename)\n",
        "  if os.path.isfile(file_path):\n",
        "    # open the file\n",
        "      text = []\n",
        "      with open(file_path, mode='r', encoding='utf-8') as text_file:\n",
        "        text = text_file.read()\n",
        "        if i <= 100: # from 1 to 100 train set\n",
        "          pre_train.append(text)\n",
        "        elif i <= 150: # from 101 to 150 validation set\n",
        "          pre_valid.append(text)\n",
        "        else: # remainings are test set\n",
        "          pre_test.append(text)  \n",
        "  i+=1\n",
        "\n",
        "tmp_train = []\n",
        "tmp_valid = []\n",
        "tmp_test = []\n",
        "\n",
        "# split the contents of the files for the character '\\n'\n",
        "for paragraph in pre_train:\n",
        "   tmp_train.append(paragraph.split('\\n'))\n",
        "for paragraph in pre_valid:\n",
        "   tmp_valid.append(paragraph.split('\\n'))\n",
        "for paragraph in pre_test:\n",
        "   tmp_test.append(paragraph.split('\\n'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split each word with its tag"
      ],
      "metadata": {
        "id": "AR4rlQo5wL-H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GUgbTXi-F7Sa"
      },
      "outputs": [],
      "source": [
        "train = []\n",
        "valid = []\n",
        "test = []\n",
        "\n",
        "for i in tmp_train:\n",
        "  for j in i:\n",
        "    train.append(j.split('\\t'))\n",
        "\n",
        "for i in tmp_valid:\n",
        "  for j in i:\n",
        "    valid.append(j.split('\\t'))\n",
        "\n",
        "for i in tmp_test:\n",
        "  for j in i:\n",
        "    test.append(j.split('\\t'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the sentences by their respective tags by creating two lists of lists.\n",
        "\n",
        "One contains lists of words (which form sentences) and one contains lists of tags that refer to individual words"
      ],
      "metadata": {
        "id": "KB50HMDn18NX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bmzVaRuQFp0M"
      },
      "outputs": [],
      "source": [
        "train_sentences = []\n",
        "valid_sentences = []\n",
        "test_sentences = []\n",
        "\n",
        "train_tags = []\n",
        "valid_tags = []\n",
        "test_tags = []\n",
        "\n",
        "tmp_sentences = []\n",
        "tmp_tags = []\n",
        "for i in train:\n",
        "  if i[0] != '':\n",
        "    tmp_sentences.append(i[0])\n",
        "    tmp_tags.append(i[1])\n",
        "  else:\n",
        "    train_sentences.append(tmp_sentences)\n",
        "    train_tags.append(tmp_tags)\n",
        "    tmp_sentences = []\n",
        "    tmp_tags = []\n",
        "\n",
        "tmp_sentences = []\n",
        "tmp_tags = []\n",
        "for i in valid:\n",
        "  if i[0] != '':\n",
        "    tmp_sentences.append(i[0])\n",
        "    tmp_tags.append(i[1])\n",
        "  else:\n",
        "    valid_sentences.append(tmp_sentences)\n",
        "    valid_tags.append(tmp_tags)\n",
        "    tmp_sentences = []\n",
        "    tmp_tags = []\n",
        "\n",
        "tmp_sentences = []\n",
        "tmp_tags = []\n",
        "for i in test:\n",
        "  if i[0] != '':\n",
        "    tmp_sentences.append(i[0])\n",
        "    tmp_tags.append(i[1])\n",
        "  else:\n",
        "    test_sentences.append(tmp_sentences)\n",
        "    test_tags.append(tmp_tags)\n",
        "    tmp_sentences = []\n",
        "    tmp_tags = []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We flatten the lists so that we have a 3 simple lists with the words in order"
      ],
      "metadata": {
        "id": "f8hhGpCK2yS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tB65cUFLIeEr"
      },
      "outputs": [],
      "source": [
        "flat_train = [item for sublist in train_sentences for item in sublist]\n",
        "flat_valid = [item for sublist in valid_sentences for item in sublist]\n",
        "flat_test = [item for sublist in test_sentences for item in sublist]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4IenRMamtLg"
      },
      "source": [
        "# Tokenization\n",
        "We create the vocabulary index based on word frequency and then we take each word in the text and replaces it with its corresponding integer value from the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TZO6ga1EGHdh"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "train_tokenizer = Tokenizer()                     # instantiate tokeniser\n",
        "train_tokenizer.fit_on_texts(train_sentences)                    # fit tokeniser on data\n",
        "train_encoded = train_tokenizer.texts_to_sequences(train_sentences)\n",
        "\n",
        "valid_tokenizer = Tokenizer()       \n",
        "valid_tokenizer.fit_on_texts(valid_sentences)                  # instantiate tokeniser\n",
        "valid_encoded = valid_tokenizer.texts_to_sequences(valid_sentences)\n",
        "\n",
        "test_tokenizer = Tokenizer()                     # instantiate tokeniser\n",
        "test_tokenizer.fit_on_texts(test_sentences)                    # fit tokeniser on data\n",
        "test_encoded = test_tokenizer.texts_to_sequences(test_sentences)  # use the tokeniser to encode input sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MSvhz4IvmziU"
      },
      "outputs": [],
      "source": [
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(train_tags)\n",
        "tags_encoded = tag_tokenizer.texts_to_sequences(train_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We pick the differences between the 3 vocabularies and we concatenate them"
      ],
      "metadata": {
        "id": "IYaZwQfqWoDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FMsG0Yw1l50L"
      },
      "outputs": [],
      "source": [
        "vocabulary = list(set(train_tokenizer.word_index.keys()))\n",
        "vocabulary += list(set(valid_tokenizer.word_index.keys()) - \n",
        "                   set(train_tokenizer.word_index.keys()))\n",
        "vocabulary += list(set(test_tokenizer.word_index.keys()) - set(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dS9RwnOtJuas"
      },
      "outputs": [],
      "source": [
        "word_index = dict(zip(vocabulary, range(2, len(vocabulary)+3)))\n",
        "word_index['-PAD-'] = 0\n",
        "word_index['-OOV-'] = 1\n",
        "\n",
        "tags = set([item for sublist in train_tags for item in sublist])\n",
        "\n",
        "tag2index = {t: i + 1 for i, t in enumerate(tags)}\n",
        "tag2index['-PAD-'] = 0 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and setup the GloVe Model"
      ],
      "metadata": {
        "id": "it-cE6dfR6Lj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoj4Zx51J2MU",
        "outputId": "93a45f71-1fde-41d4-c1d3-1c9110e7dbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-20 17:45:45--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-12-20 17:45:45--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-12-20 17:45:46--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.00MB/s    in 2m 41s  \n",
            "\n",
            "2021-12-20 17:48:27 (5.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc-T6FcLKtS9",
        "outputId": "2206b529-7e53-46d7-c6b0-953fe21fcb4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "path_to_glove_file = os.path.join(os.getcwd(), \"glove.6B.100d.txt\")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2IN3Mh-m85T"
      },
      "source": [
        "# Embedding\n",
        "- padding\n",
        "- one hot encoding of tags\n",
        "- punctuation identification\n",
        "\n",
        "Create the embedding matrix which maps each word index to its GloVe embedding (100 dimensions).\n",
        "\n",
        "We had to consider what to do with the words that were not present in the downloaded embeddings: we chose to map them randomly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0mOStEPMeXt",
        "outputId": "8c595d6d-ed5f-41ba-8c4f-b884442c23b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 10271 words (678 misses)\n"
          ]
        }
      ],
      "source": [
        "num_tokens = len(vocabulary) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        embedding_matrix += np.random.uniform(low=-0.05,\n",
        "                                              high=0.05,\n",
        "                                              size=embedding_dim)\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the embedding layer and the maximum length based on the sentences of each set"
      ],
      "metadata": {
        "id": "8aVXEf0skeQa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OpYrHs0RMtQJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f8EZM31Js06-"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = len(max(train_sentences, key=len))\n",
        "MAX_LENGTH2 = len(max(valid_sentences, key=len))\n",
        "MAX_LENGTH3 = len(max(test_sentences, key=len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iSRa9SwTuNrX"
      },
      "outputs": [],
      "source": [
        "train_sentences_X, valid_sentences_X, train_tags_y, valid_tags_y, = [], [], [], []\n",
        " \n",
        "for sentence in train_sentences:\n",
        "    sentence_int = []\n",
        "    for word in sentence:\n",
        "        try:\n",
        "            sentence_int.append(word_index[word.lower()])\n",
        "        except KeyError:\n",
        "            sentence_int.append(word_index['-OOV-'])\n",
        " \n",
        "    train_sentences_X.append(sentence_int)\n",
        "\n",
        "for sentence in valid_sentences:\n",
        "    sentence_int = []\n",
        "    for word in sentence:\n",
        "        try:\n",
        "            sentence_int.append(word_index[word.lower()])\n",
        "        except KeyError:\n",
        "            sentence_int.append(word_index['-OOV-'])\n",
        " \n",
        "    valid_sentences_X.append(sentence_int)\n",
        "\n",
        "\n",
        "for sentence in train_tags:\n",
        "    train_tags_y.append([tag2index[tag] for tag in sentence])\n",
        "\n",
        "for sentence in valid_tags:\n",
        "    valid_tags_y.append([tag2index[tag] for tag in sentence])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padded the sentences to the length of the longest one present in the train split (MAX_LENGTH)"
      ],
      "metadata": {
        "id": "kzvPLh_Snn4V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Yf-XlSrStQx3"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        " \n",
        "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "valid_sentences_X = pad_sequences(valid_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "valid_tags_y = pad_sequences(valid_tags_y, maxlen=MAX_LENGTH, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the method to categorize and map tags into integer indexes"
      ],
      "metadata": {
        "id": "IxzClSXao14z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nUtevCQrnskt"
      },
      "outputs": [],
      "source": [
        "def to_categorical(sequences, categories):\n",
        "    cat_sequences = []\n",
        "    for s in sequences:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(categories))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define categories for punctuation, symbols and padding"
      ],
      "metadata": {
        "id": "cYoq3Ui5pT9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eT8PjDIynuHG"
      },
      "outputs": [],
      "source": [
        "point = [tag2index['.']]\n",
        "virg = [tag2index[',']]\n",
        "weird_apex = [tag2index['``']]\n",
        "single_apex = [tag2index[\"''\"]]\n",
        "two_dots = [tag2index[':']]\n",
        "pad = [tag2index['-PAD-']]\n",
        "\n",
        "punct_cat_classes = to_categorical([point, virg, weird_apex, single_apex, two_dots, pad], len(tag2index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAqZ0Xkrnw_d",
        "outputId": "3fcb52d5-c6be-4f47-87e5-e5eb7a28061a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "cumulative_tags = np.zeros(46)\n",
        "for i in punct_cat_classes:\n",
        "  print(i[0])\n",
        "  cumulative_tags += i[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qzJNfc1xn7jA"
      },
      "outputs": [],
      "source": [
        "where_tags = np.where(np.logical_not(cumulative_tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LrzwDP5Wn9TK"
      },
      "outputs": [],
      "source": [
        "no_punct_indexes = where_tags[0]\n",
        "n_classes = len(no_punct_indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ik32ea9dn-5m"
      },
      "outputs": [],
      "source": [
        "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
        "cat_val_tags_y = to_categorical(valid_tags_y, len(tag2index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbT_r953oBA5"
      },
      "source": [
        "#Mini Data Vizualization Inset\n",
        "Observe the distribution of the tags and their frequency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sPiOzlwroPuJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YIyRpFGVoKlH"
      },
      "outputs": [],
      "source": [
        "distribution_tags = np.zeros(46)\n",
        "for i in cat_train_tags_y:\n",
        "  for t in i:\n",
        "    distribution_tags += t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OAbGJViloL0O"
      },
      "outputs": [],
      "source": [
        "s = sum(distribution_tags[1:])\n",
        "norm = [float(i)/s for i in distribution_tags[1:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "px2v7JyxoQrz",
        "outputId": "3197b598-6837-4914-d7a6-5893c7fba984"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.bar(np.arange(len(norm)),norm)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0m_PqWUoRsV"
      },
      "source": [
        "#F1 Metric\n",
        "Definition of the methods to calculate the F1 Metric\n",
        "\n",
        "##Precision metric.\n",
        "```\n",
        "Only computes a batch-wise average of precision.\n",
        "Computes the precision, a metric for multi-label classification of\n",
        "how many selected items are relevant.\n",
        "```\n",
        "\n",
        "##Recall metric.\n",
        "\n",
        "```\n",
        "Only computes a batch-wise average of recall.\n",
        "Computes the recall, a metric for multi-label classification of\n",
        "how many relevant items are selected.\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZDaBrpk3oYXO"
      },
      "outputs": [],
      "source": [
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def f1_binary(y_true, y_pred):\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
        "\n",
        "def metric_wrapper(index):\n",
        "  def f1_for_class(y_true, y_pred):\n",
        "    #get only the desired class\n",
        "    true = y_true[:,:,index]\n",
        "    pred = y_pred[:,:,index]\n",
        "    #return dice per class\n",
        "    tmp = f1_binary(true,pred)\n",
        "    return tmp\n",
        "  f1_for_class.__name__ = 'f1_' + str(index)\n",
        "  return f1_for_class\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    result = 0.0\n",
        "    for class_id in no_punct_indexes:\n",
        "        y_true_single_class = y_true[:,:,class_id]\n",
        "        y_pred_single_class = y_pred[:,:,class_id]\n",
        "        f1_single = f1_binary(y_true_single_class, y_pred_single_class)\n",
        "        result += f1_single / float(n_classes)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQz388M4oaCW"
      },
      "source": [
        "#Model compile and fit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of the model, in this case we're using:\n",
        "\n",
        "*   Input Layer\n",
        "*   Embedding Layer\n",
        "*   **Specific Model Layers**\n",
        "*   Activation layer with softmax activation function\n",
        "\n",
        "The model is compiled using *categorical_crossentropy* as loss,\n",
        "*Adam(0.001)* optimizer, *accuracy* and *macro_f1* as metrics.\n",
        "\n",
        "Then the trainingis done for 40 epochs on a batch size of 128.\n"
      ],
      "metadata": {
        "id": "sfli4cpdt1Qh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional LSTM + 2 Dense Layer"
      ],
      "metadata": {
        "id": "H2IfH0KupuHE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsVGByW_sdec",
        "outputId": "f733bae9-413b-4892-85b4-a45f35e2ac46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 249, 100)          1094900   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 249, 512)         731136    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 249, 46)           23598     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 249, 46)           2162      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,851,796\n",
            "Trainable params: 756,896\n",
            "Non-trainable params: 1,094,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        " \n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(Dense(len(tag2index)))\n",
        "model.add(Dense(len(tag2index)))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(0.001),\n",
        "             metrics=['accuracy', f1, [metric_wrapper(i) for i in no_punct_indexes]])\n",
        " \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWIokkJwokrV",
        "outputId": "22f4d490-2242-4019-b4bb-6165e1cb5f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "16/16 [==============================] - 100s 5s/step - loss: 0.7419 - accuracy: 0.8470 - f1: 0.0000e+00 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.3528 - val_accuracy: 0.9169 - val_f1: 0.0000e+00 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 2/40\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.3180 - accuracy: 0.9170 - f1: 0.0000e+00 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2979 - val_accuracy: 0.9238 - val_f1: 0.0000e+00 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 3/40\n",
            "16/16 [==============================] - 84s 5s/step - loss: 0.2861 - accuracy: 0.9276 - f1: 0.0000e+00 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2747 - val_accuracy: 0.9304 - val_f1: 0.0000e+00 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 4/40\n",
            "16/16 [==============================] - 79s 5s/step - loss: 0.2657 - accuracy: 0.9340 - f1: 0.0000e+00 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2584 - val_accuracy: 0.9375 - val_f1: 0.0000e+00 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 5/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2483 - accuracy: 0.9401 - f1: 2.6085e-04 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.0104 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2411 - val_accuracy: 0.9418 - val_f1: 7.4110e-04 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0296 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 6/40\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.2295 - accuracy: 0.9436 - f1: 0.0036 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.1440 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2215 - val_accuracy: 0.9444 - val_f1: 0.0052 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.2089 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 7/40\n",
            "16/16 [==============================] - 83s 5s/step - loss: 0.2093 - accuracy: 0.9459 - f1: 0.0129 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.3592 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 8.9095e-04 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.1312 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0242 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2007 - val_accuracy: 0.9480 - val_f1: 0.0205 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.3224 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0078 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.3872 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.1015 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 8/40\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.1886 - accuracy: 0.9504 - f1: 0.0384 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.4801 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0336 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.4670 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0033 - f1_36: 0.0000e+00 - f1_37: 0.5518 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1806 - val_accuracy: 0.9528 - val_f1: 0.0482 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.4346 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.1303 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.4955 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0292 - val_f1_36: 0.0000e+00 - val_f1_37: 0.8396 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 9/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1690 - accuracy: 0.9553 - f1: 0.0567 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.5407 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.1432 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.6382 - f1_31: 6.3131e-04 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0734 - f1_36: 0.0000e+00 - f1_37: 0.8730 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1620 - val_accuracy: 0.9578 - val_f1: 0.0666 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.5226 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.2470 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.7102 - val_f1_31: 0.0135 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.2696 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9021 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 10/40\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.1514 - accuracy: 0.9604 - f1: 0.0793 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.5846 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.2980 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.0195 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.3130 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.7472 - f1_31: 0.0391 - f1_32: 0.0012 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.2622 - f1_36: 0.0000e+00 - f1_37: 0.9065 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1461 - val_accuracy: 0.9631 - val_f1: 0.0987 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.5660 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.4102 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.0134 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.7220 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.7567 - val_f1_31: 0.1033 - val_f1_32: 0.0158 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.4449 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9138 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 11/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1361 - accuracy: 0.9654 - f1: 0.1126 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.6375 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.4289 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.1778 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.8809 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.8028 - f1_31: 0.1703 - f1_32: 0.0611 - f1_33: 0.0196 - f1_34: 0.0000e+00 - f1_35: 0.4073 - f1_36: 0.0000e+00 - f1_37: 0.9099 - f1_38: 0.0000e+00 - f1_39: 0.0085 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1326 - val_accuracy: 0.9664 - val_f1: 0.1241 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.6266 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.4802 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.2691 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.9703 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.8094 - val_f1_31: 0.1946 - val_f1_32: 0.1038 - val_f1_33: 0.0518 - val_f1_34: 0.0000e+00 - val_f1_35: 0.5392 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9124 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0062 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 12/40\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.1230 - accuracy: 0.9690 - f1: 0.1430 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.6840 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.5233 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.3910 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9820 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.8440 - f1_31: 0.3320 - f1_32: 0.1854 - f1_33: 0.1336 - f1_34: 0.0000e+00 - f1_35: 0.5129 - f1_36: 0.0000e+00 - f1_37: 0.9112 - f1_38: 0.1134 - f1_39: 0.1052 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1210 - val_accuracy: 0.9692 - val_f1: 0.1504 - val_f1_1: 0.0490 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.6362 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.6093 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.3719 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.9835 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0044 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.8642 - val_f1_31: 0.3233 - val_f1_32: 0.2534 - val_f1_33: 0.1796 - val_f1_34: 0.0000e+00 - val_f1_35: 0.5775 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9128 - val_f1_38: 0.1326 - val_f1_39: 0.1182 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 13/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1120 - accuracy: 0.9717 - f1: 0.1885 - f1_1: 0.3316 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.7133 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.6019 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.5446 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9972 - f1_24: 0.0000e+00 - f1_25: 0.0320 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.8703 - f1_31: 0.4456 - f1_32: 0.3208 - f1_33: 0.3356 - f1_34: 0.0000e+00 - f1_35: 0.6006 - f1_36: 0.0000e+00 - f1_37: 0.9127 - f1_38: 0.5489 - f1_39: 0.2843 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1114 - val_accuracy: 0.9715 - val_f1: 0.2053 - val_f1_1: 0.6043 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.6669 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.6299 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.6764 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.9986 - val_f1_24: 0.0000e+00 - val_f1_25: 0.1573 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.8713 - val_f1_31: 0.4598 - val_f1_32: 0.3130 - val_f1_33: 0.3965 - val_f1_34: 0.0000e+00 - val_f1_35: 0.6406 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9091 - val_f1_38: 0.6083 - val_f1_39: 0.2795 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 14/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1026 - accuracy: 0.9742 - f1: 0.2300 - f1_1: 0.8133 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.7378 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.6472 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.6685 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9982 - f1_24: 0.0000e+00 - f1_25: 0.2265 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.8812 - f1_31: 0.5339 - f1_32: 0.3899 - f1_33: 0.5185 - f1_34: 0.0000e+00 - f1_35: 0.6599 - f1_36: 0.0000e+00 - f1_37: 0.9119 - f1_38: 0.7753 - f1_39: 0.4381 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1030 - val_accuracy: 0.9738 - val_f1: 0.2394 - val_f1_1: 0.9761 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.6966 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.6474 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.7091 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.0000e+00 - val_f1_25: 0.4834 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.8823 - val_f1_31: 0.5587 - val_f1_32: 0.4165 - val_f1_33: 0.4857 - val_f1_34: 0.0000e+00 - val_f1_35: 0.6752 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9101 - val_f1_38: 0.7341 - val_f1_39: 0.3992 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 15/40\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.0945 - accuracy: 0.9761 - f1: 0.2592 - f1_1: 0.9866 - f1_2: 0.0000e+00 - f1_3: 0.0040 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.7619 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0746 - f1_11: 0.6817 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.7490 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9987 - f1_24: 0.0600 - f1_25: 0.5251 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.8945 - f1_31: 0.6031 - f1_32: 0.4614 - f1_33: 0.6186 - f1_34: 0.0000e+00 - f1_35: 0.6904 - f1_36: 0.0000e+00 - f1_37: 0.9097 - f1_38: 0.8195 - f1_39: 0.5296 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.0960 - val_accuracy: 0.9751 - val_f1: 0.2668 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0019 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7061 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.3638 - val_f1_11: 0.6841 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.8245 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.0740 - val_f1_25: 0.5798 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.8946 - val_f1_31: 0.5336 - val_f1_32: 0.4880 - val_f1_33: 0.6072 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7495 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9145 - val_f1_38: 0.7633 - val_f1_39: 0.4780 - val_f1_41: 0.0134 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 16/40\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.0879 - accuracy: 0.9777 - f1: 0.2923 - f1_1: 0.9929 - f1_2: 0.0000e+00 - f1_3: 0.0171 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.7635 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.6369 - f1_11: 0.7070 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.8008 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9982 - f1_24: 0.2229 - f1_25: 0.6616 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9000 - f1_31: 0.6522 - f1_32: 0.5101 - f1_33: 0.6725 - f1_34: 0.0000e+00 - f1_35: 0.7145 - f1_36: 0.0000e+00 - f1_37: 0.9166 - f1_38: 0.8272 - f1_39: 0.6080 - f1_41: 0.0919 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.0899 - val_accuracy: 0.9768 - val_f1: 0.2977 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0223 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7400 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7003 - val_f1_11: 0.6982 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.8508 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.2974 - val_f1_25: 0.7200 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.8957 - val_f1_31: 0.5805 - val_f1_32: 0.4763 - val_f1_33: 0.6687 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7624 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9178 - val_f1_38: 0.7737 - val_f1_39: 0.5596 - val_f1_41: 0.2480 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 17/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0820 - accuracy: 0.9792 - f1: 0.3138 - f1_1: 0.9945 - f1_2: 0.0000e+00 - f1_3: 0.0496 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.7835 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.7858 - f1_11: 0.7285 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.8307 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.3426 - f1_25: 0.7507 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9070 - f1_31: 0.6805 - f1_32: 0.5353 - f1_33: 0.7211 - f1_34: 0.0000e+00 - f1_35: 0.7517 - f1_36: 0.0000e+00 - f1_37: 0.9181 - f1_38: 0.8275 - f1_39: 0.6483 - f1_41: 0.2914 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0087 - val_loss: 0.0848 - val_accuracy: 0.9779 - val_f1: 0.3177 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.1895 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.6864 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.8252 - val_f1_11: 0.7188 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0047 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.8469 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.4499 - val_f1_25: 0.7875 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9073 - val_f1_31: 0.6600 - val_f1_32: 0.5784 - val_f1_33: 0.6769 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7656 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9260 - val_f1_38: 0.7737 - val_f1_39: 0.5987 - val_f1_41: 0.2878 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0285\n",
            "Epoch 18/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0771 - accuracy: 0.9803 - f1: 0.3293 - f1_1: 0.9921 - f1_2: 0.0000e+00 - f1_3: 0.1082 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.7918 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.8832 - f1_11: 0.7370 - f1_12: 0.0000e+00 - f1_13: 0.0020 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.8661 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.4204 - f1_25: 0.7892 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9119 - f1_31: 0.7203 - f1_32: 0.5564 - f1_33: 0.7501 - f1_34: 0.0000e+00 - f1_35: 0.7700 - f1_36: 0.0000e+00 - f1_37: 0.9249 - f1_38: 0.8262 - f1_39: 0.6809 - f1_41: 0.4045 - f1_42: 0.0000e+00 - f1_43: 0.0123 - f1_44: 0.0000e+00 - f1_45: 0.0280 - val_loss: 0.0797 - val_accuracy: 0.9791 - val_f1: 0.3306 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0797 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7237 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9113 - val_f1_11: 0.7579 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0319 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.8873 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.5193 - val_f1_25: 0.8127 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9068 - val_f1_31: 0.6356 - val_f1_32: 0.5678 - val_f1_33: 0.7527 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7840 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9311 - val_f1_38: 0.7730 - val_f1_39: 0.6062 - val_f1_41: 0.3894 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0819 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0732\n",
            "Epoch 19/40\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.0726 - accuracy: 0.9814 - f1: 0.3455 - f1_1: 0.9934 - f1_2: 0.0000e+00 - f1_3: 0.1715 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.7984 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9211 - f1_11: 0.7610 - f1_12: 0.0000e+00 - f1_13: 0.0102 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.8756 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.4212 - f1_25: 0.8200 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9165 - f1_31: 0.7295 - f1_32: 0.5765 - f1_33: 0.7593 - f1_34: 0.0000e+00 - f1_35: 0.7827 - f1_36: 0.0000e+00 - f1_37: 0.9302 - f1_38: 0.8241 - f1_39: 0.7005 - f1_41: 0.4628 - f1_42: 0.0000e+00 - f1_43: 0.2907 - f1_44: 0.0000e+00 - f1_45: 0.0782 - val_loss: 0.0761 - val_accuracy: 0.9799 - val_f1: 0.3481 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.1677 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7409 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9346 - val_f1_11: 0.7604 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0613 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.8972 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.5342 - val_f1_25: 0.8365 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9181 - val_f1_31: 0.6186 - val_f1_32: 0.5871 - val_f1_33: 0.7879 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8021 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9377 - val_f1_38: 0.7737 - val_f1_39: 0.6458 - val_f1_41: 0.4692 - val_f1_42: 0.0000e+00 - val_f1_43: 0.3271 - val_f1_44: 0.0000e+00 - val_f1_45: 0.1268\n",
            "Epoch 20/40\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.0688 - accuracy: 0.9822 - f1: 0.3634 - f1_1: 0.9945 - f1_2: 0.0000e+00 - f1_3: 0.2252 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8085 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9350 - f1_11: 0.7734 - f1_12: 0.0000e+00 - f1_13: 0.0224 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.9078 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9987 - f1_24: 0.4819 - f1_25: 0.8534 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9184 - f1_31: 0.7436 - f1_32: 0.6027 - f1_33: 0.7908 - f1_34: 0.0000e+00 - f1_35: 0.8006 - f1_36: 0.0000e+00 - f1_37: 0.9355 - f1_38: 0.8225 - f1_39: 0.7239 - f1_41: 0.6082 - f1_42: 0.0000e+00 - f1_43: 0.4659 - f1_44: 0.0000e+00 - f1_45: 0.1231 - val_loss: 0.0727 - val_accuracy: 0.9808 - val_f1: 0.3619 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.2681 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7225 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9418 - val_f1_11: 0.7729 - val_f1_12: 0.0000e+00 - val_f1_13: 0.1019 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.9003 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.5753 - val_f1_25: 0.8527 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9187 - val_f1_31: 0.6742 - val_f1_32: 0.6272 - val_f1_33: 0.7897 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7950 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9418 - val_f1_38: 0.7737 - val_f1_39: 0.6732 - val_f1_41: 0.5020 - val_f1_42: 0.0000e+00 - val_f1_43: 0.4750 - val_f1_44: 0.0000e+00 - val_f1_45: 0.1734\n",
            "Epoch 21/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0654 - accuracy: 0.9831 - f1: 0.3772 - f1_1: 0.9934 - f1_2: 0.0000e+00 - f1_3: 0.2890 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8106 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9356 - f1_11: 0.7770 - f1_12: 0.0000e+00 - f1_13: 0.0944 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.9206 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.4967 - f1_25: 0.8614 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9251 - f1_31: 0.7644 - f1_32: 0.6313 - f1_33: 0.8094 - f1_34: 0.0000e+00 - f1_35: 0.8088 - f1_36: 0.0000e+00 - f1_37: 0.9386 - f1_38: 0.8240 - f1_39: 0.7389 - f1_41: 0.6556 - f1_42: 0.0000e+00 - f1_43: 0.5728 - f1_44: 0.0000e+00 - f1_45: 0.2424 - val_loss: 0.0702 - val_accuracy: 0.9815 - val_f1: 0.3677 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.2623 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7785 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9438 - val_f1_11: 0.7608 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0895 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.9164 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.5460 - val_f1_25: 0.8687 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9231 - val_f1_31: 0.6636 - val_f1_32: 0.5735 - val_f1_33: 0.7745 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8201 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9455 - val_f1_38: 0.7717 - val_f1_39: 0.7178 - val_f1_41: 0.6416 - val_f1_42: 0.0000e+00 - val_f1_43: 0.4828 - val_f1_44: 0.0000e+00 - val_f1_45: 0.2295\n",
            "Epoch 22/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0625 - accuracy: 0.9838 - f1: 0.3883 - f1_1: 0.9930 - f1_2: 0.0000e+00 - f1_3: 0.3591 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8152 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9371 - f1_11: 0.7860 - f1_12: 0.0000e+00 - f1_13: 0.1343 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.9283 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.5610 - f1_25: 0.8767 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9294 - f1_31: 0.7796 - f1_32: 0.6356 - f1_33: 0.8099 - f1_34: 0.0000e+00 - f1_35: 0.8237 - f1_36: 0.0000e+00 - f1_37: 0.9419 - f1_38: 0.8256 - f1_39: 0.7600 - f1_41: 0.7076 - f1_42: 0.0000e+00 - f1_43: 0.6288 - f1_44: 0.0000e+00 - f1_45: 0.2992 - val_loss: 0.0667 - val_accuracy: 0.9824 - val_f1: 0.3829 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.3417 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7770 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9532 - val_f1_11: 0.7822 - val_f1_12: 0.0000e+00 - val_f1_13: 0.1634 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_19: 0.9176 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.6140 - val_f1_25: 0.8691 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9290 - val_f1_31: 0.6784 - val_f1_32: 0.6356 - val_f1_33: 0.8126 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8360 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9493 - val_f1_38: 0.7739 - val_f1_39: 0.7039 - val_f1_41: 0.6640 - val_f1_42: 0.0000e+00 - val_f1_43: 0.5896 - val_f1_44: 0.0000e+00 - val_f1_45: 0.3259\n",
            "Epoch 23/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0599 - accuracy: 0.9846 - f1: 0.3999 - f1_1: 0.9861 - f1_2: 0.0000e+00 - f1_3: 0.3686 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8188 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9436 - f1_11: 0.7932 - f1_12: 0.0000e+00 - f1_13: 0.2250 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_19: 0.9366 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9987 - f1_24: 0.5793 - f1_25: 0.8845 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9329 - f1_31: 0.7911 - f1_32: 0.6544 - f1_33: 0.8291 - f1_34: 0.0000e+00 - f1_35: 0.8268 - f1_36: 0.0000e+00 - f1_37: 0.9436 - f1_38: 0.8311 - f1_39: 0.7689 - f1_41: 0.7442 - f1_42: 0.0000e+00 - f1_43: 0.7161 - f1_44: 0.0000e+00 - f1_45: 0.4212 - val_loss: 0.0646 - val_accuracy: 0.9832 - val_f1: 0.3973 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.4487 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7628 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9603 - val_f1_11: 0.7509 - val_f1_12: 0.0000e+00 - val_f1_13: 0.2430 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0096 - val_f1_19: 0.9239 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.6399 - val_f1_25: 0.8717 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9304 - val_f1_31: 0.7439 - val_f1_32: 0.6678 - val_f1_33: 0.8051 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8407 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9530 - val_f1_38: 0.7726 - val_f1_39: 0.7307 - val_f1_41: 0.7081 - val_f1_42: 0.0000e+00 - val_f1_43: 0.6799 - val_f1_44: 0.0000e+00 - val_f1_45: 0.4500\n",
            "Epoch 24/40\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.0574 - accuracy: 0.9851 - f1: 0.4113 - f1_1: 0.9934 - f1_2: 0.0000e+00 - f1_3: 0.4494 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8251 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9457 - f1_11: 0.7937 - f1_12: 0.0000e+00 - f1_13: 0.2846 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0089 - f1_19: 0.9419 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9985 - f1_24: 0.6238 - f1_25: 0.8932 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9351 - f1_31: 0.7977 - f1_32: 0.6606 - f1_33: 0.8382 - f1_34: 0.0000e+00 - f1_35: 0.8516 - f1_36: 0.0000e+00 - f1_37: 0.9462 - f1_38: 0.8315 - f1_39: 0.7811 - f1_41: 0.7864 - f1_42: 0.0000e+00 - f1_43: 0.8233 - f1_44: 0.0000e+00 - f1_45: 0.4408 - val_loss: 0.0630 - val_accuracy: 0.9832 - val_f1: 0.4050 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.4995 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7098 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9594 - val_f1_11: 0.8076 - val_f1_12: 0.0000e+00 - val_f1_13: 0.2764 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0915 - val_f1_19: 0.9180 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.6798 - val_f1_25: 0.8678 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9230 - val_f1_31: 0.7496 - val_f1_32: 0.6748 - val_f1_33: 0.8131 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8560 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9546 - val_f1_38: 0.7781 - val_f1_39: 0.7160 - val_f1_41: 0.7133 - val_f1_42: 0.0000e+00 - val_f1_43: 0.7121 - val_f1_44: 0.0000e+00 - val_f1_45: 0.5038\n",
            "Epoch 25/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0555 - accuracy: 0.9855 - f1: 0.4240 - f1_1: 0.9913 - f1_2: 0.0000e+00 - f1_3: 0.4766 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8217 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9475 - f1_11: 0.8064 - f1_12: 0.0000e+00 - f1_13: 0.3078 - f1_14: 0.0000e+00 - f1_15: 0.0662 - f1_16: 0.0000e+00 - f1_17: 0.1741 - f1_19: 0.9434 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9984 - f1_24: 0.6289 - f1_25: 0.8966 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9362 - f1_31: 0.8128 - f1_32: 0.6748 - f1_33: 0.8484 - f1_34: 0.0000e+00 - f1_35: 0.8564 - f1_36: 0.0000e+00 - f1_37: 0.9501 - f1_38: 0.8523 - f1_39: 0.7935 - f1_41: 0.8152 - f1_42: 0.0000e+00 - f1_43: 0.8382 - f1_44: 0.0000e+00 - f1_45: 0.5244 - val_loss: 0.0603 - val_accuracy: 0.9843 - val_f1: 0.4209 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.4373 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7961 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9710 - val_f1_11: 0.7785 - val_f1_12: 0.0000e+00 - val_f1_13: 0.3425 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0485 - val_f1_16: 0.0000e+00 - val_f1_17: 0.2781 - val_f1_19: 0.9294 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.6746 - val_f1_25: 0.8865 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9328 - val_f1_31: 0.7568 - val_f1_32: 0.6525 - val_f1_33: 0.8272 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8525 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9575 - val_f1_38: 0.8325 - val_f1_39: 0.7741 - val_f1_41: 0.8110 - val_f1_42: 0.0000e+00 - val_f1_43: 0.8244 - val_f1_44: 0.0000e+00 - val_f1_45: 0.4737\n",
            "Epoch 26/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0532 - accuracy: 0.9862 - f1: 0.4356 - f1_1: 0.9938 - f1_2: 0.0000e+00 - f1_3: 0.5303 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8300 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9627 - f1_11: 0.8108 - f1_12: 0.0000e+00 - f1_13: 0.4239 - f1_14: 0.0000e+00 - f1_15: 0.0962 - f1_16: 0.0000e+00 - f1_17: 0.1972 - f1_19: 0.9513 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.6684 - f1_25: 0.9033 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9395 - f1_31: 0.8192 - f1_32: 0.6867 - f1_33: 0.8607 - f1_34: 0.0000e+00 - f1_35: 0.8619 - f1_36: 0.0000e+00 - f1_37: 0.9532 - f1_38: 0.8613 - f1_39: 0.8031 - f1_41: 0.8597 - f1_42: 0.0000e+00 - f1_43: 0.8701 - f1_44: 0.0000e+00 - f1_45: 0.5418 - val_loss: 0.0580 - val_accuracy: 0.9846 - val_f1: 0.4242 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.4650 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7768 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9829 - val_f1_11: 0.8086 - val_f1_12: 0.0000e+00 - val_f1_13: 0.3831 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0485 - val_f1_16: 0.0000e+00 - val_f1_17: 0.1992 - val_f1_19: 0.9311 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.6957 - val_f1_25: 0.8877 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9408 - val_f1_31: 0.7741 - val_f1_32: 0.6698 - val_f1_33: 0.8312 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8687 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9574 - val_f1_38: 0.8020 - val_f1_39: 0.7614 - val_f1_41: 0.8110 - val_f1_42: 0.0000e+00 - val_f1_43: 0.8587 - val_f1_44: 0.0000e+00 - val_f1_45: 0.5148\n",
            "Epoch 27/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0512 - accuracy: 0.9868 - f1: 0.4454 - f1_1: 0.9941 - f1_2: 0.0000e+00 - f1_3: 0.5487 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8390 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9732 - f1_11: 0.8189 - f1_12: 0.0000e+00 - f1_13: 0.4614 - f1_14: 0.0000e+00 - f1_15: 0.1455 - f1_16: 0.0000e+00 - f1_17: 0.2499 - f1_19: 0.9510 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9973 - f1_24: 0.6982 - f1_25: 0.9159 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9439 - f1_31: 0.8279 - f1_32: 0.7016 - f1_33: 0.8614 - f1_34: 0.0000e+00 - f1_35: 0.8768 - f1_36: 0.0000e+00 - f1_37: 0.9546 - f1_38: 0.8895 - f1_39: 0.8110 - f1_41: 0.8702 - f1_42: 0.0000e+00 - f1_43: 0.8967 - f1_44: 0.0000e+00 - f1_45: 0.5878 - val_loss: 0.0570 - val_accuracy: 0.9848 - val_f1: 0.4404 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.5200 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.8034 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9847 - val_f1_11: 0.7775 - val_f1_12: 0.0000e+00 - val_f1_13: 0.3501 - val_f1_14: 0.0000e+00 - val_f1_15: 0.1894 - val_f1_16: 0.0000e+00 - val_f1_17: 0.4299 - val_f1_19: 0.9365 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.6958 - val_f1_25: 0.9024 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9382 - val_f1_31: 0.7890 - val_f1_32: 0.6692 - val_f1_33: 0.8416 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8608 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9582 - val_f1_38: 0.8671 - val_f1_39: 0.7860 - val_f1_41: 0.9036 - val_f1_42: 0.0000e+00 - val_f1_43: 0.8691 - val_f1_44: 0.0000e+00 - val_f1_45: 0.5467\n",
            "Epoch 28/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0497 - accuracy: 0.9871 - f1: 0.4586 - f1_1: 0.9929 - f1_2: 0.0000e+00 - f1_3: 0.5751 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8452 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9746 - f1_11: 0.8228 - f1_12: 0.0000e+00 - f1_13: 0.4887 - f1_14: 0.0000e+00 - f1_15: 0.2435 - f1_16: 0.0000e+00 - f1_17: 0.4769 - f1_19: 0.9566 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9989 - f1_24: 0.7114 - f1_25: 0.9122 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9448 - f1_31: 0.8271 - f1_32: 0.7088 - f1_33: 0.8663 - f1_34: 0.0000e+00 - f1_35: 0.8769 - f1_36: 0.0000e+00 - f1_37: 0.9544 - f1_38: 0.9093 - f1_39: 0.8231 - f1_41: 0.9071 - f1_42: 0.0000e+00 - f1_43: 0.9139 - f1_44: 0.0000e+00 - f1_45: 0.6133 - val_loss: 0.0552 - val_accuracy: 0.9855 - val_f1: 0.4515 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.6173 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7922 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9847 - val_f1_11: 0.8132 - val_f1_12: 0.0000e+00 - val_f1_13: 0.4636 - val_f1_14: 0.0000e+00 - val_f1_15: 0.1575 - val_f1_16: 0.0000e+00 - val_f1_17: 0.6511 - val_f1_19: 0.9434 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7215 - val_f1_25: 0.9018 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9297 - val_f1_31: 0.7738 - val_f1_32: 0.6913 - val_f1_33: 0.8437 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8772 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9587 - val_f1_38: 0.8412 - val_f1_39: 0.7720 - val_f1_41: 0.8524 - val_f1_42: 0.0000e+00 - val_f1_43: 0.8931 - val_f1_44: 0.0000e+00 - val_f1_45: 0.5833\n",
            "Epoch 29/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0480 - accuracy: 0.9874 - f1: 0.4666 - f1_1: 0.9945 - f1_2: 0.0000e+00 - f1_3: 0.6084 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8456 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9784 - f1_11: 0.8295 - f1_12: 0.0000e+00 - f1_13: 0.5469 - f1_14: 0.0000e+00 - f1_15: 0.2800 - f1_16: 0.0000e+00 - f1_17: 0.5730 - f1_19: 0.9579 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9987 - f1_24: 0.7387 - f1_25: 0.9201 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.9446 - f1_31: 0.8378 - f1_32: 0.7133 - f1_33: 0.8713 - f1_34: 0.0000e+00 - f1_35: 0.8827 - f1_36: 0.0000e+00 - f1_37: 0.9571 - f1_38: 0.9111 - f1_39: 0.8254 - f1_41: 0.8911 - f1_42: 0.0000e+00 - f1_43: 0.9290 - f1_44: 0.0000e+00 - f1_45: 0.6302 - val_loss: 0.0538 - val_accuracy: 0.9855 - val_f1: 0.4503 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.5242 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.8093 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9892 - val_f1_11: 0.8101 - val_f1_12: 0.0000e+00 - val_f1_13: 0.4386 - val_f1_14: 0.0000e+00 - val_f1_15: 0.1894 - val_f1_16: 0.0000e+00 - val_f1_17: 0.5358 - val_f1_19: 0.9392 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.6999 - val_f1_25: 0.9053 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9447 - val_f1_31: 0.7770 - val_f1_32: 0.6731 - val_f1_33: 0.8483 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8797 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9610 - val_f1_38: 0.8853 - val_f1_39: 0.7988 - val_f1_41: 0.9008 - val_f1_42: 0.0000e+00 - val_f1_43: 0.8946 - val_f1_44: 0.0000e+00 - val_f1_45: 0.6114\n",
            "Epoch 30/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0466 - accuracy: 0.9879 - f1: 0.4718 - f1_1: 0.9903 - f1_2: 0.0000e+00 - f1_3: 0.6242 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8466 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9846 - f1_11: 0.8301 - f1_12: 0.0000e+00 - f1_13: 0.5269 - f1_14: 0.0000e+00 - f1_15: 0.3550 - f1_16: 0.0000e+00 - f1_17: 0.5820 - f1_19: 0.9562 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.7447 - f1_25: 0.9183 - f1_26: 0.0096 - f1_27: 0.0000e+00 - f1_29: 0.9472 - f1_31: 0.8415 - f1_32: 0.7209 - f1_33: 0.8780 - f1_34: 0.0000e+00 - f1_35: 0.8905 - f1_36: 0.0000e+00 - f1_37: 0.9587 - f1_38: 0.9308 - f1_39: 0.8349 - f1_41: 0.9122 - f1_42: 0.0000e+00 - f1_43: 0.9439 - f1_44: 0.0000e+00 - f1_45: 0.6478 - val_loss: 0.0527 - val_accuracy: 0.9858 - val_f1: 0.4555 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.6570 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7792 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9847 - val_f1_11: 0.8217 - val_f1_12: 0.0000e+00 - val_f1_13: 0.4827 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2374 - val_f1_16: 0.0000e+00 - val_f1_17: 0.5228 - val_f1_19: 0.9465 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7131 - val_f1_25: 0.9135 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9461 - val_f1_31: 0.8086 - val_f1_32: 0.6870 - val_f1_33: 0.8595 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8838 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9618 - val_f1_38: 0.8497 - val_f1_39: 0.8091 - val_f1_41: 0.8962 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9183 - val_f1_44: 0.0000e+00 - val_f1_45: 0.5428\n",
            "Epoch 31/40\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.0452 - accuracy: 0.9880 - f1: 0.4767 - f1_1: 0.9952 - f1_2: 0.0000e+00 - f1_3: 0.6437 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8547 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9853 - f1_11: 0.8324 - f1_12: 0.0000e+00 - f1_13: 0.5818 - f1_14: 0.0000e+00 - f1_15: 0.3320 - f1_16: 0.0000e+00 - f1_17: 0.5494 - f1_19: 0.9585 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9987 - f1_24: 0.7656 - f1_25: 0.9221 - f1_26: 0.0857 - f1_27: 0.0000e+00 - f1_29: 0.9485 - f1_31: 0.8514 - f1_32: 0.7275 - f1_33: 0.8820 - f1_34: 0.0000e+00 - f1_35: 0.8898 - f1_36: 0.0000e+00 - f1_37: 0.9616 - f1_38: 0.9277 - f1_39: 0.8431 - f1_41: 0.9371 - f1_42: 0.0000e+00 - f1_43: 0.9574 - f1_44: 0.0000e+00 - f1_45: 0.6370 - val_loss: 0.0516 - val_accuracy: 0.9861 - val_f1: 0.4683 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.6156 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7868 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9930 - val_f1_11: 0.8244 - val_f1_12: 0.0000e+00 - val_f1_13: 0.5559 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2258 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7634 - val_f1_19: 0.9426 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7290 - val_f1_25: 0.9105 - val_f1_26: 0.0107 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9442 - val_f1_31: 0.7958 - val_f1_32: 0.6991 - val_f1_33: 0.8561 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8844 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9618 - val_f1_38: 0.9277 - val_f1_39: 0.8127 - val_f1_41: 0.9087 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9394 - val_f1_44: 0.0000e+00 - val_f1_45: 0.6472\n",
            "Epoch 32/40\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.0439 - accuracy: 0.9885 - f1: 0.4857 - f1_1: 0.9932 - f1_2: 0.0000e+00 - f1_3: 0.6560 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8576 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9848 - f1_11: 0.8416 - f1_12: 0.0000e+00 - f1_13: 0.5913 - f1_14: 0.0000e+00 - f1_15: 0.4394 - f1_16: 0.0000e+00 - f1_17: 0.6691 - f1_19: 0.9633 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9987 - f1_24: 0.7756 - f1_25: 0.9229 - f1_26: 0.1042 - f1_27: 0.0000e+00 - f1_29: 0.9502 - f1_31: 0.8543 - f1_32: 0.7376 - f1_33: 0.8862 - f1_34: 0.0000e+00 - f1_35: 0.8865 - f1_36: 0.0000e+00 - f1_37: 0.9641 - f1_38: 0.9465 - f1_39: 0.8438 - f1_41: 0.9346 - f1_42: 0.0000e+00 - f1_43: 0.9619 - f1_44: 0.0000e+00 - f1_45: 0.6641 - val_loss: 0.0502 - val_accuracy: 0.9864 - val_f1: 0.4712 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.6513 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.8150 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9912 - val_f1_11: 0.8283 - val_f1_12: 0.0000e+00 - val_f1_13: 0.5232 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2330 - val_f1_16: 0.0000e+00 - val_f1_17: 0.8009 - val_f1_19: 0.9442 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7338 - val_f1_25: 0.9145 - val_f1_26: 0.0221 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9453 - val_f1_31: 0.8062 - val_f1_32: 0.6969 - val_f1_33: 0.8538 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8870 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9632 - val_f1_38: 0.9089 - val_f1_39: 0.8113 - val_f1_41: 0.9425 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9280 - val_f1_44: 0.0000e+00 - val_f1_45: 0.6496\n",
            "Epoch 33/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0426 - accuracy: 0.9887 - f1: 0.4915 - f1_1: 0.9917 - f1_2: 0.0000e+00 - f1_3: 0.6730 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8629 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9871 - f1_11: 0.8454 - f1_12: 0.0000e+00 - f1_13: 0.6027 - f1_14: 0.0000e+00 - f1_15: 0.4362 - f1_16: 0.0000e+00 - f1_17: 0.7588 - f1_19: 0.9638 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.7763 - f1_25: 0.9288 - f1_26: 0.1404 - f1_27: 0.0000e+00 - f1_29: 0.9499 - f1_31: 0.8601 - f1_32: 0.7467 - f1_33: 0.8977 - f1_34: 0.0000e+00 - f1_35: 0.8972 - f1_36: 0.0000e+00 - f1_37: 0.9645 - f1_38: 0.9491 - f1_39: 0.8451 - f1_41: 0.9578 - f1_42: 0.0000e+00 - f1_43: 0.9595 - f1_44: 0.0000e+00 - f1_45: 0.6671 - val_loss: 0.0494 - val_accuracy: 0.9865 - val_f1: 0.4778 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.6735 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.8130 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9930 - val_f1_11: 0.8344 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6017 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2348 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7885 - val_f1_19: 0.9428 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7637 - val_f1_25: 0.9161 - val_f1_26: 0.1507 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9473 - val_f1_31: 0.8059 - val_f1_32: 0.6706 - val_f1_33: 0.8582 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8903 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9647 - val_f1_38: 0.9411 - val_f1_39: 0.8022 - val_f1_41: 0.9274 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9492 - val_f1_44: 0.0000e+00 - val_f1_45: 0.6437\n",
            "Epoch 34/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0418 - accuracy: 0.9887 - f1: 0.4978 - f1_1: 0.9942 - f1_2: 0.0000e+00 - f1_3: 0.6933 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8560 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9915 - f1_11: 0.8411 - f1_12: 0.0000e+00 - f1_13: 0.6196 - f1_14: 0.0000e+00 - f1_15: 0.3844 - f1_16: 0.0000e+00 - f1_17: 0.7925 - f1_19: 0.9676 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.7779 - f1_25: 0.9280 - f1_26: 0.3379 - f1_27: 0.0000e+00 - f1_29: 0.9498 - f1_31: 0.8621 - f1_32: 0.7430 - f1_33: 0.8905 - f1_34: 0.0000e+00 - f1_35: 0.8987 - f1_36: 0.0000e+00 - f1_37: 0.9661 - f1_38: 0.9515 - f1_39: 0.8527 - f1_41: 0.9625 - f1_42: 0.0000e+00 - f1_43: 0.9623 - f1_44: 0.0000e+00 - f1_45: 0.6888 - val_loss: 0.0493 - val_accuracy: 0.9865 - val_f1: 0.4780 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.6619 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7690 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9920 - val_f1_11: 0.8294 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6095 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2290 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7391 - val_f1_19: 0.9474 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7846 - val_f1_25: 0.9138 - val_f1_26: 0.1407 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9481 - val_f1_31: 0.8266 - val_f1_32: 0.7240 - val_f1_33: 0.8599 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8904 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9655 - val_f1_38: 0.9505 - val_f1_39: 0.8204 - val_f1_41: 0.9126 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9678 - val_f1_44: 0.0000e+00 - val_f1_45: 0.6407\n",
            "Epoch 35/40\n",
            "16/16 [==============================] - 79s 5s/step - loss: 0.0408 - accuracy: 0.9890 - f1: 0.5023 - f1_1: 0.9920 - f1_2: 0.0000e+00 - f1_3: 0.6879 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8636 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9884 - f1_11: 0.8467 - f1_12: 0.0000e+00 - f1_13: 0.6411 - f1_14: 0.0000e+00 - f1_15: 0.5055 - f1_16: 0.0000e+00 - f1_17: 0.8079 - f1_19: 0.9663 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.7872 - f1_25: 0.9354 - f1_26: 0.2916 - f1_27: 0.0000e+00 - f1_29: 0.9513 - f1_31: 0.8659 - f1_32: 0.7565 - f1_33: 0.9018 - f1_34: 0.0000e+00 - f1_35: 0.9052 - f1_36: 0.0000e+00 - f1_37: 0.9680 - f1_38: 0.9625 - f1_39: 0.8582 - f1_41: 0.9619 - f1_42: 0.0000e+00 - f1_43: 0.9608 - f1_44: 0.0000e+00 - f1_45: 0.6862 - val_loss: 0.0478 - val_accuracy: 0.9867 - val_f1: 0.4840 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.6683 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7918 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9930 - val_f1_11: 0.8372 - val_f1_12: 0.0000e+00 - val_f1_13: 0.5870 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2567 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7726 - val_f1_19: 0.9494 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0057 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7472 - val_f1_25: 0.9120 - val_f1_26: 0.3118 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9495 - val_f1_31: 0.8306 - val_f1_32: 0.7142 - val_f1_33: 0.8645 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8919 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9681 - val_f1_38: 0.9261 - val_f1_39: 0.7982 - val_f1_41: 0.9307 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9701 - val_f1_44: 0.0000e+00 - val_f1_45: 0.6864\n",
            "Epoch 36/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0396 - accuracy: 0.9893 - f1: 0.5093 - f1_1: 0.9944 - f1_2: 0.0000e+00 - f1_3: 0.7061 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8661 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9866 - f1_11: 0.8521 - f1_12: 0.0000e+00 - f1_13: 0.6548 - f1_14: 0.0000e+00 - f1_15: 0.4861 - f1_16: 0.0000e+00 - f1_17: 0.7851 - f1_19: 0.9665 - f1_20: 0.0000e+00 - f1_21: 0.0089 - f1_22: 0.0000e+00 - f1_23: 0.9987 - f1_24: 0.7899 - f1_25: 0.9311 - f1_26: 0.5231 - f1_27: 0.0000e+00 - f1_29: 0.9535 - f1_31: 0.8710 - f1_32: 0.7660 - f1_33: 0.9027 - f1_34: 0.0000e+00 - f1_35: 0.9077 - f1_36: 0.0000e+00 - f1_37: 0.9665 - f1_38: 0.9613 - f1_39: 0.8580 - f1_41: 0.9652 - f1_42: 0.0000e+00 - f1_43: 0.9717 - f1_44: 0.0000e+00 - f1_45: 0.6996 - val_loss: 0.0484 - val_accuracy: 0.9864 - val_f1: 0.4885 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.6432 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.8078 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9908 - val_f1_11: 0.7973 - val_f1_12: 0.0000e+00 - val_f1_13: 0.5336 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2997 - val_f1_16: 0.0000e+00 - val_f1_17: 0.8376 - val_f1_19: 0.9631 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7738 - val_f1_25: 0.9178 - val_f1_26: 0.3774 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9492 - val_f1_31: 0.8288 - val_f1_32: 0.7202 - val_f1_33: 0.8764 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8864 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9651 - val_f1_38: 0.9569 - val_f1_39: 0.8351 - val_f1_41: 0.9677 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9648 - val_f1_44: 0.0000e+00 - val_f1_45: 0.6514\n",
            "Epoch 37/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0388 - accuracy: 0.9895 - f1: 0.5149 - f1_1: 0.9921 - f1_2: 0.0000e+00 - f1_3: 0.7057 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8711 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9827 - f1_11: 0.8522 - f1_12: 0.0000e+00 - f1_13: 0.6446 - f1_14: 0.0000e+00 - f1_15: 0.5434 - f1_16: 0.0000e+00 - f1_17: 0.8566 - f1_19: 0.9683 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.8034 - f1_25: 0.9305 - f1_26: 0.6071 - f1_27: 0.0000e+00 - f1_29: 0.9547 - f1_31: 0.8778 - f1_32: 0.7613 - f1_33: 0.9033 - f1_34: 0.0000e+00 - f1_35: 0.9053 - f1_36: 0.0000e+00 - f1_37: 0.9696 - f1_38: 0.9670 - f1_39: 0.8715 - f1_41: 0.9626 - f1_42: 0.0000e+00 - f1_43: 0.9632 - f1_44: 0.0000e+00 - f1_45: 0.7046 - val_loss: 0.0459 - val_accuracy: 0.9874 - val_f1: 0.4965 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.6865 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.8231 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9908 - val_f1_11: 0.8287 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6221 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2550 - val_f1_16: 0.0000e+00 - val_f1_17: 0.8323 - val_f1_19: 0.9669 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0057 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7772 - val_f1_25: 0.9249 - val_f1_26: 0.5303 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9499 - val_f1_31: 0.8353 - val_f1_32: 0.7308 - val_f1_33: 0.8639 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8996 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9698 - val_f1_38: 0.9576 - val_f1_39: 0.8212 - val_f1_41: 0.9421 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9754 - val_f1_44: 0.0000e+00 - val_f1_45: 0.6717\n",
            "Epoch 38/40\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.0376 - accuracy: 0.9898 - f1: 0.5196 - f1_1: 0.9948 - f1_2: 0.0000e+00 - f1_3: 0.7222 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8775 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9812 - f1_11: 0.8595 - f1_12: 0.0000e+00 - f1_13: 0.6504 - f1_14: 0.0000e+00 - f1_15: 0.4969 - f1_16: 0.0000e+00 - f1_17: 0.8655 - f1_19: 0.9735 - f1_20: 0.0417 - f1_21: 0.0156 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.8067 - f1_25: 0.9373 - f1_26: 0.6602 - f1_27: 0.0000e+00 - f1_29: 0.9575 - f1_31: 0.8799 - f1_32: 0.7692 - f1_33: 0.9034 - f1_34: 0.0000e+00 - f1_35: 0.9159 - f1_36: 0.0000e+00 - f1_37: 0.9694 - f1_38: 0.9750 - f1_39: 0.8733 - f1_41: 0.9718 - f1_42: 0.0000e+00 - f1_43: 0.9789 - f1_44: 0.0000e+00 - f1_45: 0.7098 - val_loss: 0.0464 - val_accuracy: 0.9871 - val_f1: 0.4969 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.7135 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.7881 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9912 - val_f1_11: 0.8377 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6533 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2694 - val_f1_16: 0.0000e+00 - val_f1_17: 0.8375 - val_f1_19: 0.9654 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7706 - val_f1_25: 0.9241 - val_f1_26: 0.5073 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9495 - val_f1_31: 0.8139 - val_f1_32: 0.7269 - val_f1_33: 0.8737 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8945 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9688 - val_f1_38: 0.9495 - val_f1_39: 0.8271 - val_f1_41: 0.9361 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9800 - val_f1_44: 0.0000e+00 - val_f1_45: 0.7009\n",
            "Epoch 39/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0369 - accuracy: 0.9901 - f1: 0.5238 - f1_1: 0.9926 - f1_2: 0.0000e+00 - f1_3: 0.7285 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8806 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9880 - f1_11: 0.8609 - f1_12: 0.0000e+00 - f1_13: 0.6814 - f1_14: 0.0000e+00 - f1_15: 0.5745 - f1_16: 0.0000e+00 - f1_17: 0.8644 - f1_19: 0.9678 - f1_20: 0.0417 - f1_21: 0.0096 - f1_22: 0.0000e+00 - f1_23: 0.9986 - f1_24: 0.8226 - f1_25: 0.9394 - f1_26: 0.6854 - f1_27: 0.0000e+00 - f1_29: 0.9565 - f1_31: 0.8801 - f1_32: 0.7784 - f1_33: 0.9166 - f1_34: 0.0000e+00 - f1_35: 0.9121 - f1_36: 0.0000e+00 - f1_37: 0.9714 - f1_38: 0.9743 - f1_39: 0.8721 - f1_41: 0.9658 - f1_42: 0.0000e+00 - f1_43: 0.9758 - f1_44: 0.0000e+00 - f1_45: 0.7122 - val_loss: 0.0453 - val_accuracy: 0.9873 - val_f1: 0.4992 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.7026 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.8198 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9939 - val_f1_11: 0.8387 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6329 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2694 - val_f1_16: 0.0000e+00 - val_f1_17: 0.8526 - val_f1_19: 0.9526 - val_f1_20: 0.0455 - val_f1_21: 0.0153 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7539 - val_f1_25: 0.9247 - val_f1_26: 0.5335 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9530 - val_f1_31: 0.8029 - val_f1_32: 0.7212 - val_f1_33: 0.8735 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8998 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9704 - val_f1_38: 0.9602 - val_f1_39: 0.8329 - val_f1_41: 0.9621 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9690 - val_f1_44: 0.0000e+00 - val_f1_45: 0.6890\n",
            "Epoch 40/40\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.0359 - accuracy: 0.9901 - f1: 0.5285 - f1_1: 0.9942 - f1_2: 0.0000e+00 - f1_3: 0.7428 - f1_4: 0.0000e+00 - f1_6: 0.0000e+00 - f1_7: 0.8851 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.9872 - f1_11: 0.8642 - f1_12: 0.0000e+00 - f1_13: 0.6805 - f1_14: 0.0000e+00 - f1_15: 0.5413 - f1_16: 0.0000e+00 - f1_17: 0.9057 - f1_19: 0.9710 - f1_20: 0.1042 - f1_21: 0.0096 - f1_22: 0.0000e+00 - f1_23: 0.9987 - f1_24: 0.8170 - f1_25: 0.9352 - f1_26: 0.7479 - f1_27: 0.0000e+00 - f1_29: 0.9582 - f1_31: 0.8824 - f1_32: 0.7810 - f1_33: 0.9130 - f1_34: 0.0000e+00 - f1_35: 0.9161 - f1_36: 0.0000e+00 - f1_37: 0.9704 - f1_38: 0.9748 - f1_39: 0.8794 - f1_41: 0.9723 - f1_42: 0.0000e+00 - f1_43: 0.9763 - f1_44: 0.0000e+00 - f1_45: 0.7317 - val_loss: 0.0444 - val_accuracy: 0.9876 - val_f1: 0.5040 - val_f1_1: 0.9975 - val_f1_2: 0.0000e+00 - val_f1_3: 0.7200 - val_f1_4: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_7: 0.8181 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.9912 - val_f1_11: 0.8343 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6478 - val_f1_14: 0.0000e+00 - val_f1_15: 0.3958 - val_f1_16: 0.0000e+00 - val_f1_17: 0.8211 - val_f1_19: 0.9669 - val_f1_20: 0.0455 - val_f1_21: 0.0228 - val_f1_22: 0.0000e+00 - val_f1_23: 1.0000 - val_f1_24: 0.7656 - val_f1_25: 0.9264 - val_f1_26: 0.5130 - val_f1_27: 0.0000e+00 - val_f1_29: 0.9518 - val_f1_31: 0.8365 - val_f1_32: 0.7367 - val_f1_33: 0.8803 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8985 - val_f1_36: 0.0000e+00 - val_f1_37: 0.9716 - val_f1_38: 0.9707 - val_f1_39: 0.8411 - val_f1_41: 0.9467 - val_f1_42: 0.0000e+00 - val_f1_43: 0.9797 - val_f1_44: 0.0000e+00 - val_f1_45: 0.6803\n"
          ]
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "history = model.fit(train_sentences_X, cat_train_tags_y, batch_size=128, epochs=40, validation_data=(valid_sentences_X, cat_val_tags_y), callbacks=[callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional LSTM + LSTM + Dense Layer"
      ],
      "metadata": {
        "id": "vQ-YIIK8p5OS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991f7934-7c67-4cec-fcdd-bae3ed3305a1",
        "id": "9iduOWs7qHzW"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        " \n",
        " \n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dense(len(tag2index)))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(0.001),\n",
        "             metrics=['accuracy', f1, [metric_wrapper(i) for i in no_punct_indexes]])\n",
        " \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 249, 100)          1094900   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 249, 512)         731136    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 249, 128)          328192    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 249, 46)           5934      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,160,162\n",
            "Trainable params: 1,065,262\n",
            "Non-trainable params: 1,094,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "history = model.fit(train_sentences_X, cat_train_tags_y, batch_size=128, epochs=40, validation_data=(valid_sentences_X, cat_val_tags_y), callbacks=[callback])"
      ],
      "metadata": {
        "id": "f4BHmKzMvUpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0530ddb2-381b-4ea0-f509-7240e230b020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "16/16 [==============================] - 125s 7s/step - loss: 0.8262 - accuracy: 0.8442 - f1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.3845 - val_accuracy: 0.9048 - val_f1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 2/40\n",
            "16/16 [==============================] - 103s 6s/step - loss: 0.3406 - accuracy: 0.9115 - f1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.3139 - val_accuracy: 0.9164 - val_f1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 3/40\n",
            "16/16 [==============================] - 105s 7s/step - loss: 0.3027 - accuracy: 0.9157 - f1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2937 - val_accuracy: 0.9199 - val_f1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 4/40\n",
            "16/16 [==============================] - 104s 7s/step - loss: 0.2884 - accuracy: 0.9195 - f1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2843 - val_accuracy: 0.9216 - val_f1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 5/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.2802 - accuracy: 0.9216 - f1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2782 - val_accuracy: 0.9226 - val_f1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 6/40\n",
            "16/16 [==============================] - 106s 7s/step - loss: 0.2733 - accuracy: 0.9237 - f1: 2.0139e-04 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0081 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2708 - val_accuracy: 0.9246 - val_f1: 3.0102e-05 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0012 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 7/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.2649 - accuracy: 0.9262 - f1: 8.0848e-04 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0323 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2644 - val_accuracy: 0.9262 - val_f1: 0.0011 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0460 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 8/40\n",
            "16/16 [==============================] - 101s 6s/step - loss: 0.2558 - accuracy: 0.9287 - f1: 0.0035 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.1388 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2512 - val_accuracy: 0.9308 - val_f1: 0.0022 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0889 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 9/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.2425 - accuracy: 0.9338 - f1: 0.0069 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.2754 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2369 - val_accuracy: 0.9359 - val_f1: 0.0065 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.2584 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 10/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.2266 - accuracy: 0.9397 - f1: 0.0104 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.4159 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2204 - val_accuracy: 0.9423 - val_f1: 0.0108 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.4305 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 11/40\n",
            "16/16 [==============================] - 101s 6s/step - loss: 0.2086 - accuracy: 0.9455 - f1: 0.0130 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0028 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0075 - f1_36: 0.0000e+00 - f1_37: 0.5053 - f1_38: 0.0033 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2011 - val_accuracy: 0.9475 - val_f1: 0.0142 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0104 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0448 - val_f1_36: 0.0000e+00 - val_f1_37: 0.4807 - val_f1_38: 0.0323 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 12/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.1893 - accuracy: 0.9508 - f1: 0.0234 - f1_2: 0.0354 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0494 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.1914 - f1_36: 0.0000e+00 - f1_37: 0.5783 - f1_38: 0.0811 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1836 - val_accuracy: 0.9531 - val_f1: 0.0323 - val_f1_2: 0.0986 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0722 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.4741 - val_f1_36: 0.0000e+00 - val_f1_37: 0.4471 - val_f1_38: 0.1984 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 13/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.1715 - accuracy: 0.9551 - f1: 0.0507 - f1_2: 0.3954 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.1761 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0051 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.5467 - f1_36: 0.0000e+00 - f1_37: 0.6223 - f1_38: 0.2835 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1658 - val_accuracy: 0.9562 - val_f1: 0.0663 - val_f1_2: 0.7305 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.2391 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0102 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.6408 - val_f1_36: 0.0000e+00 - val_f1_37: 0.6058 - val_f1_38: 0.4258 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 14/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.1555 - accuracy: 0.9589 - f1: 0.0732 - f1_2: 0.8172 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.2923 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0339 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.7192 - f1_36: 0.0000e+00 - f1_37: 0.6628 - f1_38: 0.4013 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1516 - val_accuracy: 0.9606 - val_f1: 0.0778 - val_f1_2: 0.8703 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0014 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.4257 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0377 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7590 - val_f1_36: 0.0000e+00 - val_f1_37: 0.5689 - val_f1_38: 0.4499 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 15/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.1420 - accuracy: 0.9629 - f1: 0.0860 - f1_2: 0.8964 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0160 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.4103 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.1390 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0251 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.7827 - f1_36: 0.0000e+00 - f1_37: 0.6895 - f1_38: 0.4803 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.9639 - val_f1: 0.0906 - val_f1_2: 0.9060 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0566 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.3902 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0876 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.1308 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7928 - val_f1_36: 0.0000e+00 - val_f1_37: 0.6834 - val_f1_38: 0.5755 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 9.6200e-04\n",
            "Epoch 16/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.1299 - accuracy: 0.9666 - f1: 0.1084 - f1_2: 0.9165 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.1585 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.4951 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.2353 - f1_14: 0.0000e+00 - f1_15: 0.0073 - f1_17: 0.0000e+00 - f1_18: 0.3941 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.8308 - f1_36: 0.0000e+00 - f1_37: 0.7179 - f1_38: 0.5682 - f1_39: 0.0024 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0089 - val_loss: 0.1290 - val_accuracy: 0.9660 - val_f1: 0.1154 - val_f1_2: 0.9233 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.1659 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.5550 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.1861 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0301 - val_f1_17: 0.0000e+00 - val_f1_18: 0.5035 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8213 - val_f1_36: 0.0000e+00 - val_f1_37: 0.6974 - val_f1_38: 0.6308 - val_f1_39: 0.0032 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0929 - val_f1_45: 0.0048\n",
            "Epoch 17/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.1195 - accuracy: 0.9695 - f1: 0.1416 - f1_2: 0.9211 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.3014 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.5569 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.3557 - f1_14: 0.0000e+00 - f1_15: 0.2604 - f1_17: 0.0000e+00 - f1_18: 0.7695 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.8516 - f1_36: 0.0000e+00 - f1_37: 0.7410 - f1_38: 0.6021 - f1_39: 0.0203 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.2389 - f1_45: 0.0445 - val_loss: 0.1195 - val_accuracy: 0.9684 - val_f1: 0.1556 - val_f1_2: 0.9295 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.3725 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0045 - val_f1_9: 0.0000e+00 - val_f1_10: 0.6343 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.2984 - val_f1_14: 0.0000e+00 - val_f1_15: 0.4649 - val_f1_17: 0.0000e+00 - val_f1_18: 0.8535 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8509 - val_f1_36: 0.0000e+00 - val_f1_37: 0.7060 - val_f1_38: 0.6574 - val_f1_39: 0.0781 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.3505 - val_f1_45: 0.0229\n",
            "Epoch 18/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.1107 - accuracy: 0.9719 - f1: 0.1786 - f1_2: 0.9278 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.4671 - f1_6: 0.0046 - f1_8: 0.0155 - f1_9: 0.0000e+00 - f1_10: 0.6152 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.4613 - f1_14: 0.0000e+00 - f1_15: 0.6258 - f1_17: 0.0000e+00 - f1_18: 0.9217 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0471 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.8631 - f1_36: 0.0000e+00 - f1_37: 0.7647 - f1_38: 0.6415 - f1_39: 0.1163 - f1_40: 0.0061 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.5427 - f1_45: 0.1229 - val_loss: 0.1113 - val_accuracy: 0.9713 - val_f1: 0.1917 - val_f1_2: 0.9306 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.5128 - val_f1_6: 0.0180 - val_f1_8: 0.0534 - val_f1_9: 0.0000e+00 - val_f1_10: 0.6277 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.4367 - val_f1_14: 0.0000e+00 - val_f1_15: 0.6741 - val_f1_17: 0.0000e+00 - val_f1_18: 0.9519 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0718 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8633 - val_f1_36: 0.0000e+00 - val_f1_37: 0.6886 - val_f1_38: 0.6926 - val_f1_39: 0.1958 - val_f1_40: 0.0174 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.8008 - val_f1_45: 0.1326\n",
            "Epoch 19/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.1676 - accuracy: 0.9550 - f1: 0.1404 - f1_2: 0.8806 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.3147 - f1_6: 0.0449 - f1_8: 0.0457 - f1_9: 0.0000e+00 - f1_10: 0.4518 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.3119 - f1_14: 0.0000e+00 - f1_15: 0.4252 - f1_17: 0.0000e+00 - f1_18: 0.6373 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.1308 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.7933 - f1_36: 0.0000e+00 - f1_37: 0.4338 - f1_38: 0.4241 - f1_39: 0.1481 - f1_40: 0.0219 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.4487 - f1_45: 0.1051 - val_loss: 0.1873 - val_accuracy: 0.9484 - val_f1: 0.0477 - val_f1_2: 0.8695 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.3875 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.6368 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0116 - val_f1_38: 0.0031 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 20/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.1550 - accuracy: 0.9612 - f1: 0.0685 - f1_2: 0.8081 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0044 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.2957 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0875 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.2392 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.7032 - f1_36: 0.0000e+00 - f1_37: 0.4543 - f1_38: 0.1458 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 5.7604e-04 - val_loss: 0.1345 - val_accuracy: 0.9659 - val_f1: 0.0981 - val_f1_2: 0.9172 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0452 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.4769 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.3309 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0024 - val_f1_17: 0.0000e+00 - val_f1_18: 0.3200 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8311 - val_f1_36: 0.0000e+00 - val_f1_37: 0.5569 - val_f1_38: 0.4422 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 21/40\n",
            "16/16 [==============================] - 101s 6s/step - loss: 0.1220 - accuracy: 0.9691 - f1: 0.1243 - f1_2: 0.9165 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.2580 - f1_6: 0.0000e+00 - f1_8: 0.0019 - f1_9: 0.0000e+00 - f1_10: 0.5563 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.3481 - f1_14: 0.0000e+00 - f1_15: 0.0115 - f1_17: 0.0000e+00 - f1_18: 0.7321 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.8443 - f1_36: 0.0000e+00 - f1_37: 0.6692 - f1_38: 0.5658 - f1_39: 0.0115 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0560 - val_loss: 0.1169 - val_accuracy: 0.9696 - val_f1: 0.1489 - val_f1_2: 0.9220 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.4627 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0079 - val_f1_9: 0.0000e+00 - val_f1_10: 0.6168 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.3245 - val_f1_14: 0.0000e+00 - val_f1_15: 0.2686 - val_f1_17: 0.0000e+00 - val_f1_18: 0.9749 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8481 - val_f1_36: 0.0000e+00 - val_f1_37: 0.6554 - val_f1_38: 0.6761 - val_f1_39: 0.0760 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.0254 - val_f1_45: 0.0964\n",
            "Epoch 22/40\n",
            "16/16 [==============================] - 101s 6s/step - loss: 0.1087 - accuracy: 0.9721 - f1: 0.1795 - f1_2: 0.9181 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.5305 - f1_6: 0.0179 - f1_8: 0.0758 - f1_9: 0.0000e+00 - f1_10: 0.6211 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.4707 - f1_14: 0.0000e+00 - f1_15: 0.6847 - f1_17: 0.0000e+00 - f1_18: 0.9844 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.8656 - f1_36: 0.0000e+00 - f1_37: 0.7350 - f1_38: 0.6729 - f1_39: 0.1833 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.2870 - f1_45: 0.1328 - val_loss: 0.1083 - val_accuracy: 0.9715 - val_f1: 0.1931 - val_f1_2: 0.9262 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.4838 - val_f1_6: 0.1057 - val_f1_8: 0.0424 - val_f1_9: 0.0000e+00 - val_f1_10: 0.6369 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.4478 - val_f1_14: 0.0000e+00 - val_f1_15: 0.7398 - val_f1_17: 0.0000e+00 - val_f1_18: 0.9816 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.0537 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8684 - val_f1_36: 0.0000e+00 - val_f1_37: 0.6975 - val_f1_38: 0.7245 - val_f1_39: 0.2176 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.5855 - val_f1_45: 0.2128\n",
            "Epoch 23/40\n",
            "16/16 [==============================] - 101s 6s/step - loss: 0.1007 - accuracy: 0.9742 - f1: 0.2305 - f1_2: 0.9208 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.5860 - f1_6: 0.2404 - f1_8: 0.2047 - f1_9: 0.0000e+00 - f1_10: 0.6688 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.5397 - f1_14: 0.0000e+00 - f1_15: 0.8052 - f1_17: 0.0000e+00 - f1_18: 0.9916 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.5456 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.8770 - f1_36: 0.0000e+00 - f1_37: 0.7498 - f1_38: 0.7116 - f1_39: 0.2820 - f1_40: 0.0127 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.8318 - f1_45: 0.2526 - val_loss: 0.1021 - val_accuracy: 0.9732 - val_f1: 0.2473 - val_f1_2: 0.9287 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.5926 - val_f1_6: 0.4879 - val_f1_8: 0.4334 - val_f1_9: 0.0000e+00 - val_f1_10: 0.6618 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.5026 - val_f1_14: 0.0000e+00 - val_f1_15: 0.7507 - val_f1_17: 0.0000e+00 - val_f1_18: 0.9880 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.7448 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8701 - val_f1_36: 0.0000e+00 - val_f1_37: 0.7052 - val_f1_38: 0.7439 - val_f1_39: 0.2920 - val_f1_40: 0.0243 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.8784 - val_f1_45: 0.2884\n",
            "Epoch 24/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.0946 - accuracy: 0.9757 - f1: 0.2604 - f1_2: 0.9253 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.6288 - f1_6: 0.5032 - f1_8: 0.4025 - f1_9: 0.0000e+00 - f1_10: 0.6899 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.5994 - f1_14: 0.0000e+00 - f1_15: 0.8067 - f1_17: 0.0000e+00 - f1_18: 0.9942 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.8295 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.8848 - f1_36: 0.0000e+00 - f1_37: 0.7759 - f1_38: 0.7376 - f1_39: 0.3602 - f1_40: 0.0372 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9452 - f1_45: 0.2965 - val_loss: 0.0968 - val_accuracy: 0.9747 - val_f1: 0.2670 - val_f1_2: 0.9325 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.6736 - val_f1_6: 0.5512 - val_f1_8: 0.4750 - val_f1_9: 0.0000e+00 - val_f1_10: 0.6699 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.5880 - val_f1_14: 0.0000e+00 - val_f1_15: 0.7559 - val_f1_17: 0.0000e+00 - val_f1_18: 0.9945 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9066 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8794 - val_f1_36: 0.0000e+00 - val_f1_37: 0.7267 - val_f1_38: 0.7673 - val_f1_39: 0.4049 - val_f1_40: 0.0548 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9449 - val_f1_45: 0.3531\n",
            "Epoch 25/40\n",
            "16/16 [==============================] - 104s 7s/step - loss: 0.0898 - accuracy: 0.9772 - f1: 0.2784 - f1_2: 0.9319 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.7110 - f1_6: 0.5948 - f1_8: 0.4871 - f1_9: 0.0000e+00 - f1_10: 0.7135 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.6461 - f1_14: 0.0000e+00 - f1_15: 0.8006 - f1_17: 0.0000e+00 - f1_18: 0.9973 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9114 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.8887 - f1_36: 0.0000e+00 - f1_37: 0.7819 - f1_38: 0.7501 - f1_39: 0.4504 - f1_40: 0.1032 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9866 - f1_45: 0.3805 - val_loss: 0.0924 - val_accuracy: 0.9757 - val_f1: 0.2762 - val_f1_2: 0.9369 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.6480 - val_f1_6: 0.6202 - val_f1_8: 0.5675 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7105 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6033 - val_f1_14: 0.0000e+00 - val_f1_15: 0.7606 - val_f1_17: 0.0000e+00 - val_f1_18: 0.9967 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9211 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8900 - val_f1_36: 0.0000e+00 - val_f1_37: 0.7441 - val_f1_38: 0.7809 - val_f1_39: 0.4310 - val_f1_40: 0.1039 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9578 - val_f1_45: 0.3761\n",
            "Epoch 26/40\n",
            "16/16 [==============================] - 104s 7s/step - loss: 0.0854 - accuracy: 0.9784 - f1: 0.2913 - f1_2: 0.9348 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.7174 - f1_6: 0.6474 - f1_8: 0.5779 - f1_9: 0.0000e+00 - f1_10: 0.7331 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.6853 - f1_14: 0.0000e+00 - f1_15: 0.8161 - f1_17: 0.0000e+00 - f1_18: 0.9985 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9303 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0266 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.8960 - f1_36: 0.0304 - f1_37: 0.7916 - f1_38: 0.7664 - f1_39: 0.5463 - f1_40: 0.1433 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9901 - f1_45: 0.4222 - val_loss: 0.0887 - val_accuracy: 0.9767 - val_f1: 0.2918 - val_f1_2: 0.9391 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.7199 - val_f1_6: 0.6669 - val_f1_8: 0.6923 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7134 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6191 - val_f1_14: 0.0000e+00 - val_f1_15: 0.7674 - val_f1_17: 0.0000e+00 - val_f1_18: 0.9994 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9424 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0412 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8924 - val_f1_36: 0.0187 - val_f1_37: 0.7535 - val_f1_38: 0.7953 - val_f1_39: 0.5221 - val_f1_40: 0.1980 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9768 - val_f1_45: 0.4140\n",
            "Epoch 27/40\n",
            "16/16 [==============================] - 104s 7s/step - loss: 0.0817 - accuracy: 0.9794 - f1: 0.3055 - f1_2: 0.9354 - f1_3: 0.0011 - f1_4: 0.0000e+00 - f1_5: 0.7450 - f1_6: 0.7033 - f1_8: 0.6683 - f1_9: 0.0000e+00 - f1_10: 0.7400 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.7075 - f1_14: 0.0000e+00 - f1_15: 0.8185 - f1_17: 0.0000e+00 - f1_18: 0.9987 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9351 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0046 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.1231 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9021 - f1_36: 0.0655 - f1_37: 0.8016 - f1_38: 0.7837 - f1_39: 0.5784 - f1_40: 0.2533 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9905 - f1_45: 0.4629 - val_loss: 0.0853 - val_accuracy: 0.9775 - val_f1: 0.3013 - val_f1_2: 0.9398 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.7252 - val_f1_6: 0.6755 - val_f1_8: 0.7434 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7375 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6429 - val_f1_14: 0.0000e+00 - val_f1_15: 0.7665 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9445 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.1406 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8989 - val_f1_36: 0.0623 - val_f1_37: 0.7545 - val_f1_38: 0.8152 - val_f1_39: 0.5598 - val_f1_40: 0.2346 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9768 - val_f1_45: 0.4341\n",
            "Epoch 28/40\n",
            "16/16 [==============================] - 103s 6s/step - loss: 0.0784 - accuracy: 0.9801 - f1: 0.3190 - f1_2: 0.9373 - f1_3: 0.0036 - f1_4: 0.0000e+00 - f1_5: 0.7505 - f1_6: 0.7273 - f1_8: 0.7439 - f1_9: 0.0000e+00 - f1_10: 0.7550 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.7298 - f1_14: 0.0000e+00 - f1_15: 0.8269 - f1_17: 0.0000e+00 - f1_18: 0.9986 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9321 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0111 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.3093 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9061 - f1_36: 0.1436 - f1_37: 0.8048 - f1_38: 0.8035 - f1_39: 0.6175 - f1_40: 0.2826 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9948 - f1_45: 0.4809 - val_loss: 0.0821 - val_accuracy: 0.9786 - val_f1: 0.3142 - val_f1_2: 0.9395 - val_f1_3: 0.0057 - val_f1_4: 0.0000e+00 - val_f1_5: 0.7450 - val_f1_6: 0.7153 - val_f1_8: 0.7698 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7411 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6659 - val_f1_14: 0.0087 - val_f1_15: 0.7645 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9445 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.2991 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9012 - val_f1_36: 0.1634 - val_f1_37: 0.7561 - val_f1_38: 0.8165 - val_f1_39: 0.5857 - val_f1_40: 0.2695 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9923 - val_f1_45: 0.4825\n",
            "Epoch 29/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.0756 - accuracy: 0.9808 - f1: 0.3319 - f1_2: 0.9374 - f1_3: 0.0194 - f1_4: 0.0000e+00 - f1_5: 0.7791 - f1_6: 0.7507 - f1_8: 0.7821 - f1_9: 0.0000e+00 - f1_10: 0.7614 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.7379 - f1_14: 0.0521 - f1_15: 0.8207 - f1_17: 0.0000e+00 - f1_18: 0.9987 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9458 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0102 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.4136 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9107 - f1_36: 0.2658 - f1_37: 0.8083 - f1_38: 0.8118 - f1_39: 0.6570 - f1_40: 0.3117 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9941 - f1_45: 0.5092 - val_loss: 0.0796 - val_accuracy: 0.9791 - val_f1: 0.3295 - val_f1_2: 0.9396 - val_f1_3: 0.0160 - val_f1_4: 0.0000e+00 - val_f1_5: 0.7676 - val_f1_6: 0.7356 - val_f1_8: 0.7960 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7643 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6805 - val_f1_14: 0.0542 - val_f1_15: 0.7670 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9477 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0312 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.4253 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9052 - val_f1_36: 0.3492 - val_f1_37: 0.7364 - val_f1_38: 0.8310 - val_f1_39: 0.5826 - val_f1_40: 0.3589 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.4923\n",
            "Epoch 30/40\n",
            "16/16 [==============================] - 101s 6s/step - loss: 0.0728 - accuracy: 0.9815 - f1: 0.3466 - f1_2: 0.9379 - f1_3: 0.0323 - f1_4: 0.0000e+00 - f1_5: 0.7917 - f1_6: 0.7772 - f1_8: 0.8142 - f1_9: 0.0000e+00 - f1_10: 0.7728 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.7549 - f1_14: 0.2111 - f1_15: 0.8261 - f1_17: 0.0000e+00 - f1_18: 0.9986 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9435 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0228 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.5202 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9120 - f1_36: 0.3703 - f1_37: 0.8111 - f1_38: 0.8232 - f1_39: 0.6458 - f1_40: 0.3783 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9934 - f1_45: 0.5269 - val_loss: 0.0772 - val_accuracy: 0.9800 - val_f1: 0.3437 - val_f1_2: 0.9412 - val_f1_3: 0.0259 - val_f1_4: 0.0000e+00 - val_f1_5: 0.7846 - val_f1_6: 0.7568 - val_f1_8: 0.7977 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7486 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6877 - val_f1_14: 0.2300 - val_f1_15: 0.7821 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9477 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0609 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.5044 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9050 - val_f1_36: 0.3923 - val_f1_37: 0.7597 - val_f1_38: 0.8328 - val_f1_39: 0.6471 - val_f1_40: 0.4190 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.5251\n",
            "Epoch 31/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.0703 - accuracy: 0.9822 - f1: 0.3591 - f1_2: 0.9410 - f1_3: 0.0409 - f1_4: 0.0000e+00 - f1_5: 0.8043 - f1_6: 0.7998 - f1_8: 0.8316 - f1_9: 0.0000e+00 - f1_10: 0.7751 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.7616 - f1_14: 0.3652 - f1_15: 0.8394 - f1_17: 0.0000e+00 - f1_18: 0.9987 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9466 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0556 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.5951 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9156 - f1_36: 0.4148 - f1_37: 0.8198 - f1_38: 0.8304 - f1_39: 0.6809 - f1_40: 0.3969 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9935 - f1_45: 0.5579 - val_loss: 0.0747 - val_accuracy: 0.9805 - val_f1: 0.3549 - val_f1_2: 0.9447 - val_f1_3: 0.0679 - val_f1_4: 0.0000e+00 - val_f1_5: 0.7890 - val_f1_6: 0.7877 - val_f1_8: 0.8024 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7607 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.7244 - val_f1_14: 0.3997 - val_f1_15: 0.8019 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9495 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0818 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.5402 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9115 - val_f1_36: 0.4490 - val_f1_37: 0.7727 - val_f1_38: 0.8315 - val_f1_39: 0.6468 - val_f1_40: 0.3947 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.5428\n",
            "Epoch 32/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.0679 - accuracy: 0.9828 - f1: 0.3689 - f1_2: 0.9429 - f1_3: 0.0692 - f1_4: 0.0000e+00 - f1_5: 0.8151 - f1_6: 0.8233 - f1_8: 0.8444 - f1_9: 0.0000e+00 - f1_10: 0.7869 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.7688 - f1_14: 0.4709 - f1_15: 0.8496 - f1_17: 0.0000e+00 - f1_18: 0.9975 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9409 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.0825 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.6553 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9182 - f1_36: 0.4230 - f1_37: 0.8262 - f1_38: 0.8322 - f1_39: 0.7092 - f1_40: 0.4288 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9929 - f1_45: 0.5779 - val_loss: 0.0724 - val_accuracy: 0.9810 - val_f1: 0.3661 - val_f1_2: 0.9445 - val_f1_3: 0.0787 - val_f1_4: 0.0000e+00 - val_f1_5: 0.8033 - val_f1_6: 0.8264 - val_f1_8: 0.8438 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7685 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.7131 - val_f1_14: 0.5689 - val_f1_15: 0.8132 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9495 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.0890 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.6111 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9145 - val_f1_36: 0.4507 - val_f1_37: 0.7751 - val_f1_38: 0.8485 - val_f1_39: 0.6590 - val_f1_40: 0.4272 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.5596\n",
            "Epoch 33/40\n",
            "16/16 [==============================] - 104s 7s/step - loss: 0.0658 - accuracy: 0.9832 - f1: 0.3805 - f1_2: 0.9444 - f1_3: 0.0871 - f1_4: 0.0000e+00 - f1_5: 0.8193 - f1_6: 0.8395 - f1_8: 0.8646 - f1_9: 0.0000e+00 - f1_10: 0.7908 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.7862 - f1_14: 0.6698 - f1_15: 0.8522 - f1_17: 0.0000e+00 - f1_18: 0.9987 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9414 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.1201 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.6809 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9214 - f1_36: 0.4697 - f1_37: 0.8279 - f1_38: 0.8419 - f1_39: 0.7267 - f1_40: 0.4520 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9933 - f1_45: 0.5922 - val_loss: 0.0706 - val_accuracy: 0.9814 - val_f1: 0.3737 - val_f1_2: 0.9509 - val_f1_3: 0.0984 - val_f1_4: 0.0000e+00 - val_f1_5: 0.8022 - val_f1_6: 0.8503 - val_f1_8: 0.8555 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7807 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.7038 - val_f1_14: 0.6427 - val_f1_15: 0.8274 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9634 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.1170 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.6787 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9158 - val_f1_36: 0.4453 - val_f1_37: 0.7854 - val_f1_38: 0.8451 - val_f1_39: 0.7057 - val_f1_40: 0.4808 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.5005\n",
            "Epoch 34/40\n",
            "16/16 [==============================] - 106s 7s/step - loss: 0.0638 - accuracy: 0.9838 - f1: 0.3900 - f1_2: 0.9438 - f1_3: 0.1407 - f1_4: 0.0000e+00 - f1_5: 0.8243 - f1_6: 0.8508 - f1_8: 0.8670 - f1_9: 0.0000e+00 - f1_10: 0.7978 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.7909 - f1_14: 0.7203 - f1_15: 0.8676 - f1_17: 0.0000e+00 - f1_18: 0.9987 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9447 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.1640 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.7436 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9231 - f1_36: 0.4896 - f1_37: 0.8361 - f1_38: 0.8601 - f1_39: 0.7444 - f1_40: 0.4907 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9919 - f1_45: 0.6118 - val_loss: 0.0695 - val_accuracy: 0.9814 - val_f1: 0.3784 - val_f1_2: 0.9514 - val_f1_3: 0.1221 - val_f1_4: 0.0000e+00 - val_f1_5: 0.8185 - val_f1_6: 0.8710 - val_f1_8: 0.8785 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7696 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6998 - val_f1_14: 0.6780 - val_f1_15: 0.8393 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9670 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.1185 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.7134 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9171 - val_f1_36: 0.4598 - val_f1_37: 0.7880 - val_f1_38: 0.8469 - val_f1_39: 0.7285 - val_f1_40: 0.4538 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.5175\n",
            "Epoch 35/40\n",
            "16/16 [==============================] - 104s 7s/step - loss: 0.0620 - accuracy: 0.9840 - f1: 0.3957 - f1_2: 0.9464 - f1_3: 0.1620 - f1_4: 0.0000e+00 - f1_5: 0.8369 - f1_6: 0.8671 - f1_8: 0.8828 - f1_9: 0.0000e+00 - f1_10: 0.8017 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.7985 - f1_14: 0.7801 - f1_15: 0.8714 - f1_17: 0.0000e+00 - f1_18: 0.9984 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9481 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.1648 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.7896 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9278 - f1_36: 0.5081 - f1_37: 0.8285 - f1_38: 0.8641 - f1_39: 0.7544 - f1_40: 0.4847 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9944 - f1_45: 0.6179 - val_loss: 0.0673 - val_accuracy: 0.9823 - val_f1: 0.3885 - val_f1_2: 0.9523 - val_f1_3: 0.2291 - val_f1_4: 0.0000e+00 - val_f1_5: 0.8061 - val_f1_6: 0.8777 - val_f1_8: 0.9017 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7947 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.7011 - val_f1_14: 0.7250 - val_f1_15: 0.8409 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9682 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.1704 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.7519 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9194 - val_f1_36: 0.5205 - val_f1_37: 0.7880 - val_f1_38: 0.8406 - val_f1_39: 0.7267 - val_f1_40: 0.4688 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.5601\n",
            "Epoch 36/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.0600 - accuracy: 0.9846 - f1: 0.4036 - f1_2: 0.9485 - f1_3: 0.2139 - f1_4: 0.0000e+00 - f1_5: 0.8437 - f1_6: 0.8702 - f1_8: 0.8982 - f1_9: 0.0000e+00 - f1_10: 0.8080 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.8075 - f1_14: 0.7864 - f1_15: 0.8784 - f1_17: 0.0000e+00 - f1_18: 0.9986 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9450 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.2272 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.8039 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9274 - f1_36: 0.5545 - f1_37: 0.8392 - f1_38: 0.8701 - f1_39: 0.7663 - f1_40: 0.5258 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9944 - f1_45: 0.6350 - val_loss: 0.0654 - val_accuracy: 0.9827 - val_f1: 0.3957 - val_f1_2: 0.9530 - val_f1_3: 0.2269 - val_f1_4: 0.0000e+00 - val_f1_5: 0.8224 - val_f1_6: 0.8809 - val_f1_8: 0.8899 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7926 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.7226 - val_f1_14: 0.7639 - val_f1_15: 0.8472 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9682 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.2225 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.7688 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9225 - val_f1_36: 0.5583 - val_f1_37: 0.7914 - val_f1_38: 0.8627 - val_f1_39: 0.7506 - val_f1_40: 0.5202 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.5678\n",
            "Epoch 37/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.0583 - accuracy: 0.9850 - f1: 0.4087 - f1_2: 0.9489 - f1_3: 0.2521 - f1_4: 0.0000e+00 - f1_5: 0.8455 - f1_6: 0.8761 - f1_8: 0.9113 - f1_9: 0.0000e+00 - f1_10: 0.8113 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.8111 - f1_14: 0.8082 - f1_15: 0.8817 - f1_17: 0.0000e+00 - f1_18: 0.9986 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9455 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.2591 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.8338 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9303 - f1_36: 0.5715 - f1_37: 0.8404 - f1_38: 0.8740 - f1_39: 0.7711 - f1_40: 0.5356 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9947 - f1_45: 0.6467 - val_loss: 0.0635 - val_accuracy: 0.9832 - val_f1: 0.4015 - val_f1_2: 0.9523 - val_f1_3: 0.2598 - val_f1_4: 0.0000e+00 - val_f1_5: 0.8320 - val_f1_6: 0.8779 - val_f1_8: 0.8849 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7985 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.7443 - val_f1_14: 0.7723 - val_f1_15: 0.8582 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9682 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.2480 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.7939 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9247 - val_f1_36: 0.6098 - val_f1_37: 0.7882 - val_f1_38: 0.8647 - val_f1_39: 0.7388 - val_f1_40: 0.5175 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.6266\n",
            "Epoch 38/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.0567 - accuracy: 0.9853 - f1: 0.4128 - f1_2: 0.9512 - f1_3: 0.2714 - f1_4: 0.0000e+00 - f1_5: 0.8424 - f1_6: 0.8802 - f1_8: 0.9190 - f1_9: 0.0000e+00 - f1_10: 0.8128 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.8158 - f1_14: 0.8154 - f1_15: 0.8982 - f1_17: 0.0000e+00 - f1_18: 0.9985 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9458 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.3000 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.8246 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9342 - f1_36: 0.5860 - f1_37: 0.8484 - f1_38: 0.8844 - f1_39: 0.7770 - f1_40: 0.5539 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9940 - f1_45: 0.6607 - val_loss: 0.0626 - val_accuracy: 0.9833 - val_f1: 0.4068 - val_f1_2: 0.9540 - val_f1_3: 0.2773 - val_f1_4: 0.0000e+00 - val_f1_5: 0.8180 - val_f1_6: 0.8747 - val_f1_8: 0.8911 - val_f1_9: 0.0000e+00 - val_f1_10: 0.8114 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.7277 - val_f1_14: 0.7912 - val_f1_15: 0.8646 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9682 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.3301 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.8100 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9308 - val_f1_36: 0.6286 - val_f1_37: 0.7787 - val_f1_38: 0.8644 - val_f1_39: 0.7541 - val_f1_40: 0.5560 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.6433\n",
            "Epoch 39/40\n",
            "16/16 [==============================] - 102s 6s/step - loss: 0.0554 - accuracy: 0.9855 - f1: 0.4190 - f1_2: 0.9522 - f1_3: 0.3131 - f1_4: 0.0052 - f1_5: 0.8501 - f1_6: 0.8822 - f1_8: 0.9264 - f1_9: 0.0000e+00 - f1_10: 0.8163 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.8238 - f1_14: 0.8322 - f1_15: 0.8993 - f1_17: 0.0000e+00 - f1_18: 0.9986 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9566 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.3591 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.8608 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9338 - f1_36: 0.6105 - f1_37: 0.8478 - f1_38: 0.8815 - f1_39: 0.7888 - f1_40: 0.5700 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9940 - f1_45: 0.6588 - val_loss: 0.0610 - val_accuracy: 0.9836 - val_f1: 0.4115 - val_f1_2: 0.9549 - val_f1_3: 0.3055 - val_f1_4: 0.0000e+00 - val_f1_5: 0.8346 - val_f1_6: 0.8772 - val_f1_8: 0.8978 - val_f1_9: 0.0000e+00 - val_f1_10: 0.7860 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.7639 - val_f1_14: 0.8155 - val_f1_15: 0.8858 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9782 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.3350 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.8161 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9333 - val_f1_36: 0.6296 - val_f1_37: 0.7980 - val_f1_38: 0.8795 - val_f1_39: 0.7654 - val_f1_40: 0.5549 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.6530\n",
            "Epoch 40/40\n",
            "16/16 [==============================] - 104s 7s/step - loss: 0.0541 - accuracy: 0.9859 - f1: 0.4262 - f1_2: 0.9534 - f1_3: 0.3649 - f1_4: 0.1039 - f1_5: 0.8528 - f1_6: 0.8858 - f1_8: 0.9220 - f1_9: 0.0000e+00 - f1_10: 0.8136 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.8243 - f1_14: 0.8462 - f1_15: 0.9178 - f1_17: 0.0000e+00 - f1_18: 0.9987 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_23: 0.9636 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_28: 0.3797 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.8626 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.9363 - f1_36: 0.6214 - f1_37: 0.8477 - f1_38: 0.8901 - f1_39: 0.7935 - f1_40: 0.5949 - f1_41: 0.0000e+00 - f1_42: 0.0000e+00 - f1_43: 0.0000e+00 - f1_44: 0.9953 - f1_45: 0.6781 - val_loss: 0.0604 - val_accuracy: 0.9835 - val_f1: 0.4170 - val_f1_2: 0.9570 - val_f1_3: 0.3008 - val_f1_4: 0.2167 - val_f1_5: 0.8366 - val_f1_6: 0.8827 - val_f1_8: 0.9237 - val_f1_9: 0.0000e+00 - val_f1_10: 0.8188 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.7207 - val_f1_14: 0.8400 - val_f1_15: 0.8861 - val_f1_17: 0.0000e+00 - val_f1_18: 1.0000 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_23: 0.9831 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_28: 0.3558 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.8425 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9307 - val_f1_36: 0.6421 - val_f1_37: 0.7973 - val_f1_38: 0.8584 - val_f1_39: 0.7675 - val_f1_40: 0.5347 - val_f1_41: 0.0000e+00 - val_f1_42: 0.0000e+00 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9975 - val_f1_45: 0.5885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional LSTM Single\n",
        "(One of the Best)"
      ],
      "metadata": {
        "id": "CGqAO48bqWLF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77531f82-b739-48ae-dfe9-9659d5142ced",
        "id": "UM7oKq1Gqoq_"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        " \n",
        " \n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(Dense(len(tag2index)))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.001),\n",
        "              metrics=['accuracy', f1, [metric_wrapper(i) for i in no_punct_indexes]])\n",
        " \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 249, 100)          1094900   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 249, 512)         731136    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 249, 46)           23598     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,849,634\n",
            "Trainable params: 754,734\n",
            "Non-trainable params: 1,094,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "history = model.fit(train_sentences_X, cat_train_tags_y, batch_size=128, epochs=40, validation_data=(valid_sentences_X, cat_val_tags_y), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n45419-PZSR7",
        "outputId": "3166ea19-55c0-4298-b8cb-0eae1f8c5290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "16/16 [==============================] - 67s 4s/step - loss: 0.0760 - accuracy: 0.9804 - f1: 0.3471 - f1_1: 0.5390 - f1_3: 0.0186 - f1_4: 0.9387 - f1_5: 0.7822 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0888 - f1_10: 0.9014 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.5267 - f1_15: 0.9952 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.7802 - f1_25: 0.7566 - f1_27: 0.0000e+00 - f1_28: 0.6406 - f1_29: 0.8020 - f1_30: 0.7830 - f1_31: 0.2106 - f1_32: 0.9985 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.7118 - f1_36: 0.0000e+00 - f1_37: 0.8256 - f1_38: 0.0000e+00 - f1_39: 0.6637 - f1_40: 0.7427 - f1_41: 0.0000e+00 - f1_42: 0.2485 - f1_43: 0.0000e+00 - f1_44: 0.9315 - val_loss: 0.0799 - val_accuracy: 0.9792 - val_f1: 0.3519 - val_f1_1: 0.4951 - val_f1_3: 0.0412 - val_f1_4: 0.9394 - val_f1_5: 0.8169 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.1015 - val_f1_10: 0.9121 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.4984 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7319 - val_f1_25: 0.7938 - val_f1_27: 0.0000e+00 - val_f1_28: 0.6278 - val_f1_29: 0.8135 - val_f1_30: 0.8126 - val_f1_31: 0.3081 - val_f1_32: 1.0000 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.6849 - val_f1_36: 0.0000e+00 - val_f1_37: 0.7662 - val_f1_38: 0.0000e+00 - val_f1_39: 0.6476 - val_f1_40: 0.7555 - val_f1_41: 0.0000e+00 - val_f1_42: 0.4030 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9313\n",
            "Epoch 2/40\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.0720 - accuracy: 0.9813 - f1: 0.3632 - f1_1: 0.6119 - f1_3: 0.0410 - f1_4: 0.9407 - f1_5: 0.8165 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.1434 - f1_10: 0.9116 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.5456 - f1_15: 0.9940 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.7844 - f1_25: 0.8079 - f1_27: 0.0000e+00 - f1_28: 0.6802 - f1_29: 0.8197 - f1_30: 0.8344 - f1_31: 0.3121 - f1_32: 0.9987 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.7254 - f1_36: 0.0000e+00 - f1_37: 0.8203 - f1_38: 0.0000e+00 - f1_39: 0.7000 - f1_40: 0.7708 - f1_41: 0.0000e+00 - f1_42: 0.3543 - f1_43: 0.0000e+00 - f1_44: 0.9160 - val_loss: 0.0762 - val_accuracy: 0.9798 - val_f1: 0.3595 - val_f1_1: 0.5825 - val_f1_3: 0.0991 - val_f1_4: 0.9429 - val_f1_5: 0.8211 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.1472 - val_f1_10: 0.9144 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.5470 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7481 - val_f1_25: 0.8064 - val_f1_27: 0.0000e+00 - val_f1_28: 0.6319 - val_f1_29: 0.8220 - val_f1_30: 0.8178 - val_f1_31: 0.2742 - val_f1_32: 1.0000 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7452 - val_f1_36: 0.0000e+00 - val_f1_37: 0.7652 - val_f1_38: 0.0000e+00 - val_f1_39: 0.5626 - val_f1_40: 0.7609 - val_f1_41: 0.0000e+00 - val_f1_42: 0.4662 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9300\n",
            "Epoch 3/40\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.0682 - accuracy: 0.9823 - f1: 0.3772 - f1_1: 0.6861 - f1_3: 0.0943 - f1_4: 0.9441 - f1_5: 0.8371 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.1756 - f1_10: 0.9100 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.5760 - f1_15: 0.9941 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.7966 - f1_25: 0.8416 - f1_27: 0.0000e+00 - f1_28: 0.7102 - f1_29: 0.8284 - f1_30: 0.8554 - f1_31: 0.3872 - f1_32: 0.9986 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.7418 - f1_36: 0.0000e+00 - f1_37: 0.8261 - f1_38: 0.0000e+00 - f1_39: 0.7204 - f1_40: 0.7928 - f1_41: 0.0000e+00 - f1_42: 0.4259 - f1_43: 0.0000e+00 - f1_44: 0.9445 - val_loss: 0.0728 - val_accuracy: 0.9807 - val_f1: 0.3750 - val_f1_1: 0.6601 - val_f1_3: 0.1943 - val_f1_4: 0.9435 - val_f1_5: 0.8233 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.1929 - val_f1_10: 0.9178 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.5526 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7578 - val_f1_25: 0.8779 - val_f1_27: 0.0000e+00 - val_f1_28: 0.7076 - val_f1_29: 0.8261 - val_f1_30: 0.8566 - val_f1_31: 0.2789 - val_f1_32: 1.0000 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7524 - val_f1_36: 0.0000e+00 - val_f1_37: 0.7741 - val_f1_38: 0.0000e+00 - val_f1_39: 0.6499 - val_f1_40: 0.7677 - val_f1_41: 0.0000e+00 - val_f1_42: 0.5368 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9314\n",
            "Epoch 4/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0652 - accuracy: 0.9831 - f1: 0.3877 - f1_1: 0.7577 - f1_3: 0.1842 - f1_4: 0.9456 - f1_5: 0.8371 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.2186 - f1_10: 0.9142 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.5835 - f1_15: 0.9949 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8002 - f1_25: 0.8775 - f1_27: 0.0000e+00 - f1_28: 0.7367 - f1_29: 0.8448 - f1_30: 0.8961 - f1_31: 0.3921 - f1_32: 0.9986 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.7513 - f1_36: 0.0000e+00 - f1_37: 0.8324 - f1_38: 0.0000e+00 - f1_39: 0.7402 - f1_40: 0.8046 - f1_41: 0.0000e+00 - f1_42: 0.4668 - f1_43: 0.0000e+00 - f1_44: 0.9326 - val_loss: 0.0701 - val_accuracy: 0.9813 - val_f1: 0.3842 - val_f1_1: 0.6921 - val_f1_3: 0.2658 - val_f1_4: 0.9475 - val_f1_5: 0.8337 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.2462 - val_f1_10: 0.9227 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.5774 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7347 - val_f1_25: 0.9024 - val_f1_27: 0.0000e+00 - val_f1_28: 0.6934 - val_f1_29: 0.8451 - val_f1_30: 0.8805 - val_f1_31: 0.3097 - val_f1_32: 1.0000 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7582 - val_f1_36: 0.0000e+00 - val_f1_37: 0.7780 - val_f1_38: 0.0000e+00 - val_f1_39: 0.6941 - val_f1_40: 0.8113 - val_f1_41: 0.0000e+00 - val_f1_42: 0.5450 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9314\n",
            "Epoch 5/40\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.0624 - accuracy: 0.9838 - f1: 0.3989 - f1_1: 0.7966 - f1_3: 0.2305 - f1_4: 0.9452 - f1_5: 0.8629 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.2819 - f1_10: 0.9171 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.6154 - f1_15: 0.9879 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8058 - f1_25: 0.9112 - f1_27: 0.0000e+00 - f1_28: 0.7521 - f1_29: 0.8470 - f1_30: 0.9122 - f1_31: 0.4805 - f1_32: 0.9986 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.7615 - f1_36: 0.0000e+00 - f1_37: 0.8344 - f1_38: 0.0000e+00 - f1_39: 0.7591 - f1_40: 0.8194 - f1_41: 0.0000e+00 - f1_42: 0.5038 - f1_43: 0.0000e+00 - f1_44: 0.9324 - val_loss: 0.0673 - val_accuracy: 0.9818 - val_f1: 0.3952 - val_f1_1: 0.8041 - val_f1_3: 0.2793 - val_f1_4: 0.9486 - val_f1_5: 0.8541 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.2525 - val_f1_10: 0.9236 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.5624 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7747 - val_f1_25: 0.9168 - val_f1_27: 0.0000e+00 - val_f1_28: 0.7288 - val_f1_29: 0.8563 - val_f1_30: 0.8977 - val_f1_31: 0.4535 - val_f1_32: 1.0000 - val_f1_33: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7573 - val_f1_36: 0.0000e+00 - val_f1_37: 0.7815 - val_f1_38: 0.0000e+00 - val_f1_39: 0.6851 - val_f1_40: 0.8145 - val_f1_41: 0.0000e+00 - val_f1_42: 0.5883 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9314\n",
            "Epoch 6/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0599 - accuracy: 0.9844 - f1: 0.4066 - f1_1: 0.8421 - f1_3: 0.3062 - f1_4: 0.9453 - f1_5: 0.8799 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.3073 - f1_10: 0.9214 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.6180 - f1_15: 0.9939 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8117 - f1_25: 0.9195 - f1_27: 0.0000e+00 - f1_28: 0.7696 - f1_29: 0.8594 - f1_30: 0.9253 - f1_31: 0.5085 - f1_32: 0.9987 - f1_33: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.7700 - f1_36: 0.0000e+00 - f1_37: 0.8385 - f1_38: 0.0000e+00 - f1_39: 0.7651 - f1_40: 0.8336 - f1_41: 0.0000e+00 - f1_42: 0.5100 - f1_43: 0.0000e+00 - f1_44: 0.9413 - val_loss: 0.0651 - val_accuracy: 0.9825 - val_f1: 0.4027 - val_f1_1: 0.8500 - val_f1_3: 0.3021 - val_f1_4: 0.9487 - val_f1_5: 0.8613 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.2560 - val_f1_10: 0.9250 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.5541 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7444 - val_f1_25: 0.9200 - val_f1_27: 0.0000e+00 - val_f1_28: 0.7470 - val_f1_29: 0.8735 - val_f1_30: 0.9002 - val_f1_31: 0.5473 - val_f1_32: 1.0000 - val_f1_33: 0.0222 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7809 - val_f1_36: 0.0000e+00 - val_f1_37: 0.7890 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7317 - val_f1_40: 0.8256 - val_f1_41: 0.0000e+00 - val_f1_42: 0.6006 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9327\n",
            "Epoch 7/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0577 - accuracy: 0.9849 - f1: 0.4157 - f1_1: 0.8681 - f1_3: 0.3558 - f1_4: 0.9485 - f1_5: 0.8873 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.3373 - f1_10: 0.9222 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.6374 - f1_15: 0.9946 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8115 - f1_25: 0.9218 - f1_27: 0.0000e+00 - f1_28: 0.7851 - f1_29: 0.8737 - f1_30: 0.9305 - f1_31: 0.5510 - f1_32: 0.9985 - f1_33: 0.0717 - f1_34: 0.0000e+00 - f1_35: 0.7770 - f1_36: 0.0000e+00 - f1_37: 0.8507 - f1_38: 0.0000e+00 - f1_39: 0.7799 - f1_40: 0.8431 - f1_41: 0.0000e+00 - f1_42: 0.5466 - f1_43: 0.0000e+00 - f1_44: 0.9354 - val_loss: 0.0632 - val_accuracy: 0.9830 - val_f1: 0.4107 - val_f1_1: 0.8629 - val_f1_3: 0.3113 - val_f1_4: 0.9500 - val_f1_5: 0.8752 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.3821 - val_f1_10: 0.9281 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.5910 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7876 - val_f1_25: 0.9438 - val_f1_27: 0.0000e+00 - val_f1_28: 0.7452 - val_f1_29: 0.8654 - val_f1_30: 0.8993 - val_f1_31: 0.5903 - val_f1_32: 1.0000 - val_f1_33: 0.0425 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7479 - val_f1_36: 0.0000e+00 - val_f1_37: 0.8058 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7282 - val_f1_40: 0.8281 - val_f1_41: 0.0000e+00 - val_f1_42: 0.6089 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9355\n",
            "Epoch 8/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0554 - accuracy: 0.9856 - f1: 0.4246 - f1_1: 0.8825 - f1_3: 0.3991 - f1_4: 0.9484 - f1_5: 0.8949 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.4094 - f1_10: 0.9225 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.6416 - f1_15: 0.9920 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8271 - f1_25: 0.9369 - f1_27: 0.0000e+00 - f1_28: 0.7846 - f1_29: 0.8773 - f1_30: 0.9334 - f1_31: 0.5895 - f1_32: 0.9976 - f1_33: 0.1416 - f1_34: 0.0000e+00 - f1_35: 0.7804 - f1_36: 0.0000e+00 - f1_37: 0.8661 - f1_38: 0.0000e+00 - f1_39: 0.7885 - f1_40: 0.8496 - f1_41: 0.0000e+00 - f1_42: 0.5792 - f1_43: 0.0000e+00 - f1_44: 0.9419 - val_loss: 0.0612 - val_accuracy: 0.9838 - val_f1: 0.4226 - val_f1_1: 0.8986 - val_f1_3: 0.3625 - val_f1_4: 0.9509 - val_f1_5: 0.8800 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.4363 - val_f1_10: 0.9302 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6195 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7620 - val_f1_25: 0.9393 - val_f1_27: 0.0000e+00 - val_f1_28: 0.7761 - val_f1_29: 0.8735 - val_f1_30: 0.9109 - val_f1_31: 0.4518 - val_f1_32: 1.0000 - val_f1_33: 0.3745 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7850 - val_f1_36: 0.0000e+00 - val_f1_37: 0.8104 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7510 - val_f1_40: 0.8201 - val_f1_41: 0.0000e+00 - val_f1_42: 0.6190 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9562\n",
            "Epoch 9/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0537 - accuracy: 0.9859 - f1: 0.4361 - f1_1: 0.9014 - f1_3: 0.4332 - f1_4: 0.9515 - f1_5: 0.9007 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.4528 - f1_10: 0.9268 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.6622 - f1_15: 0.9946 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8221 - f1_25: 0.9477 - f1_27: 0.0000e+00 - f1_28: 0.7958 - f1_29: 0.8875 - f1_30: 0.9461 - f1_31: 0.5771 - f1_32: 0.9986 - f1_33: 0.3469 - f1_34: 0.0000e+00 - f1_35: 0.7991 - f1_36: 0.0000e+00 - f1_37: 0.8685 - f1_38: 0.0000e+00 - f1_39: 0.7971 - f1_40: 0.8622 - f1_41: 0.0000e+00 - f1_42: 0.6198 - f1_43: 0.0000e+00 - f1_44: 0.9537 - val_loss: 0.0596 - val_accuracy: 0.9840 - val_f1: 0.4287 - val_f1_1: 0.9002 - val_f1_3: 0.3883 - val_f1_4: 0.9509 - val_f1_5: 0.8813 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.4857 - val_f1_10: 0.9330 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6357 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7907 - val_f1_25: 0.9565 - val_f1_27: 0.0000e+00 - val_f1_28: 0.7717 - val_f1_29: 0.8717 - val_f1_30: 0.9099 - val_f1_31: 0.5271 - val_f1_32: 1.0000 - val_f1_33: 0.3720 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7840 - val_f1_36: 0.0000e+00 - val_f1_37: 0.8337 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7376 - val_f1_40: 0.8373 - val_f1_41: 0.0000e+00 - val_f1_42: 0.6228 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9611\n",
            "Epoch 10/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0518 - accuracy: 0.9863 - f1: 0.4438 - f1_1: 0.9086 - f1_3: 0.4719 - f1_4: 0.9508 - f1_5: 0.9013 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.5010 - f1_10: 0.9284 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.6733 - f1_15: 0.9954 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8349 - f1_25: 0.9547 - f1_27: 0.0000e+00 - f1_28: 0.8015 - f1_29: 0.8923 - f1_30: 0.9504 - f1_31: 0.6189 - f1_32: 0.9984 - f1_33: 0.4583 - f1_34: 0.0000e+00 - f1_35: 0.8001 - f1_36: 0.0000e+00 - f1_37: 0.8886 - f1_38: 0.0000e+00 - f1_39: 0.7996 - f1_40: 0.8604 - f1_41: 0.0000e+00 - f1_42: 0.6079 - f1_43: 0.0000e+00 - f1_44: 0.9564 - val_loss: 0.0579 - val_accuracy: 0.9845 - val_f1: 0.4388 - val_f1_1: 0.9120 - val_f1_3: 0.4238 - val_f1_4: 0.9512 - val_f1_5: 0.8875 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.4970 - val_f1_10: 0.9349 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6293 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7871 - val_f1_25: 0.9595 - val_f1_27: 0.0000e+00 - val_f1_28: 0.7965 - val_f1_29: 0.8857 - val_f1_30: 0.9199 - val_f1_31: 0.5421 - val_f1_32: 1.0000 - val_f1_33: 0.5672 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7819 - val_f1_36: 0.0000e+00 - val_f1_37: 0.8398 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7550 - val_f1_40: 0.8413 - val_f1_41: 0.0000e+00 - val_f1_42: 0.6773 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9669\n",
            "Epoch 11/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0502 - accuracy: 0.9867 - f1: 0.4533 - f1_1: 0.9130 - f1_3: 0.4925 - f1_4: 0.9525 - f1_5: 0.9116 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.5155 - f1_10: 0.9321 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.6747 - f1_15: 0.9944 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8373 - f1_25: 0.9586 - f1_27: 0.0417 - f1_28: 0.8135 - f1_29: 0.8982 - f1_30: 0.9557 - f1_31: 0.6321 - f1_32: 0.9987 - f1_33: 0.6178 - f1_34: 0.0000e+00 - f1_35: 0.8065 - f1_36: 0.0000e+00 - f1_37: 0.8944 - f1_38: 0.0000e+00 - f1_39: 0.8148 - f1_40: 0.8690 - f1_41: 0.0000e+00 - f1_42: 0.6454 - f1_43: 0.0000e+00 - f1_44: 0.9618 - val_loss: 0.0567 - val_accuracy: 0.9846 - val_f1: 0.4446 - val_f1_1: 0.9373 - val_f1_3: 0.5134 - val_f1_4: 0.9553 - val_f1_5: 0.8903 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.5280 - val_f1_10: 0.9293 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6182 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7962 - val_f1_25: 0.9618 - val_f1_27: 0.0139 - val_f1_28: 0.7925 - val_f1_29: 0.8820 - val_f1_30: 0.9547 - val_f1_31: 0.5806 - val_f1_32: 1.0000 - val_f1_33: 0.5665 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7917 - val_f1_36: 0.0000e+00 - val_f1_37: 0.8555 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7390 - val_f1_40: 0.8460 - val_f1_41: 0.0000e+00 - val_f1_42: 0.6638 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9703\n",
            "Epoch 12/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0487 - accuracy: 0.9871 - f1: 0.4607 - f1_1: 0.9379 - f1_3: 0.5385 - f1_4: 0.9536 - f1_5: 0.9130 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.5388 - f1_10: 0.9345 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.6886 - f1_15: 0.9956 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8414 - f1_25: 0.9689 - f1_27: 0.1714 - f1_28: 0.8208 - f1_29: 0.8991 - f1_30: 0.9558 - f1_31: 0.6315 - f1_32: 0.9987 - f1_33: 0.6090 - f1_34: 0.0000e+00 - f1_35: 0.8086 - f1_36: 0.0000e+00 - f1_37: 0.9047 - f1_38: 0.0000e+00 - f1_39: 0.8153 - f1_40: 0.8738 - f1_41: 0.0000e+00 - f1_42: 0.6511 - f1_43: 0.0000e+00 - f1_44: 0.9756 - val_loss: 0.0555 - val_accuracy: 0.9850 - val_f1: 0.4523 - val_f1_1: 0.9311 - val_f1_3: 0.5287 - val_f1_4: 0.9554 - val_f1_5: 0.8932 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.5394 - val_f1_10: 0.9374 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6307 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8001 - val_f1_25: 0.9646 - val_f1_27: 0.0298 - val_f1_28: 0.8082 - val_f1_29: 0.8904 - val_f1_30: 0.9590 - val_f1_31: 0.6064 - val_f1_32: 1.0000 - val_f1_33: 0.6912 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7664 - val_f1_36: 0.0000e+00 - val_f1_37: 0.8866 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7717 - val_f1_40: 0.8526 - val_f1_41: 0.0000e+00 - val_f1_42: 0.6813 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9725\n",
            "Epoch 13/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0475 - accuracy: 0.9874 - f1: 0.4674 - f1_1: 0.9337 - f1_3: 0.5288 - f1_4: 0.9536 - f1_5: 0.9142 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.5657 - f1_10: 0.9392 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.6905 - f1_15: 0.9940 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8454 - f1_25: 0.9718 - f1_27: 0.1830 - f1_28: 0.8247 - f1_29: 0.9029 - f1_30: 0.9632 - f1_31: 0.6611 - f1_32: 0.9986 - f1_33: 0.7273 - f1_34: 0.0000e+00 - f1_35: 0.8130 - f1_36: 0.0000e+00 - f1_37: 0.9244 - f1_38: 0.0000e+00 - f1_39: 0.8214 - f1_40: 0.8747 - f1_41: 0.0000e+00 - f1_42: 0.6853 - f1_43: 0.0000e+00 - f1_44: 0.9778 - val_loss: 0.0545 - val_accuracy: 0.9851 - val_f1: 0.4553 - val_f1_1: 0.9400 - val_f1_3: 0.5318 - val_f1_4: 0.9576 - val_f1_5: 0.9003 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.5931 - val_f1_10: 0.9360 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6413 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8016 - val_f1_25: 0.9654 - val_f1_27: 0.0473 - val_f1_28: 0.8096 - val_f1_29: 0.8916 - val_f1_30: 0.9628 - val_f1_31: 0.6015 - val_f1_32: 1.0000 - val_f1_33: 0.7196 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7576 - val_f1_36: 0.0000e+00 - val_f1_37: 0.8686 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7740 - val_f1_40: 0.8522 - val_f1_41: 0.0000e+00 - val_f1_42: 0.6902 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9713\n",
            "Epoch 14/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0463 - accuracy: 0.9875 - f1: 0.4755 - f1_1: 0.9390 - f1_3: 0.5607 - f1_4: 0.9550 - f1_5: 0.9219 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.5903 - f1_10: 0.9409 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7048 - f1_15: 0.9934 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8478 - f1_25: 0.9679 - f1_27: 0.3287 - f1_28: 0.8322 - f1_29: 0.8995 - f1_30: 0.9647 - f1_31: 0.6756 - f1_32: 0.9986 - f1_33: 0.7170 - f1_34: 0.0000e+00 - f1_35: 0.8076 - f1_36: 0.0431 - f1_37: 0.9385 - f1_38: 0.0000e+00 - f1_39: 0.8240 - f1_40: 0.8862 - f1_41: 0.0000e+00 - f1_42: 0.7004 - f1_43: 0.0000e+00 - f1_44: 0.9821 - val_loss: 0.0532 - val_accuracy: 0.9853 - val_f1: 0.4603 - val_f1_1: 0.9438 - val_f1_3: 0.5491 - val_f1_4: 0.9576 - val_f1_5: 0.8949 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6042 - val_f1_10: 0.9371 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.5793 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8024 - val_f1_25: 0.9688 - val_f1_27: 0.0711 - val_f1_28: 0.8257 - val_f1_29: 0.8919 - val_f1_30: 0.9541 - val_f1_31: 0.6258 - val_f1_32: 1.0000 - val_f1_33: 0.8223 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8018 - val_f1_36: 0.0333 - val_f1_37: 0.8812 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7803 - val_f1_40: 0.8448 - val_f1_41: 0.0000e+00 - val_f1_42: 0.6710 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9739\n",
            "Epoch 15/40\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.0451 - accuracy: 0.9879 - f1: 0.4825 - f1_1: 0.9432 - f1_3: 0.5745 - f1_4: 0.9565 - f1_5: 0.9237 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.6004 - f1_10: 0.9415 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.6984 - f1_15: 0.9944 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8501 - f1_25: 0.9747 - f1_27: 0.3872 - f1_28: 0.8341 - f1_29: 0.9097 - f1_30: 0.9648 - f1_31: 0.6763 - f1_32: 0.9985 - f1_33: 0.7722 - f1_34: 0.0000e+00 - f1_35: 0.8207 - f1_36: 0.1470 - f1_37: 0.9328 - f1_38: 0.0000e+00 - f1_39: 0.8344 - f1_40: 0.8851 - f1_41: 0.0000e+00 - f1_42: 0.6903 - f1_43: 0.0000e+00 - f1_44: 0.9893 - val_loss: 0.0519 - val_accuracy: 0.9858 - val_f1: 0.4699 - val_f1_1: 0.9503 - val_f1_3: 0.5722 - val_f1_4: 0.9592 - val_f1_5: 0.8971 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.5733 - val_f1_10: 0.9433 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6161 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8117 - val_f1_25: 0.9688 - val_f1_27: 0.3102 - val_f1_28: 0.8248 - val_f1_29: 0.8956 - val_f1_30: 0.9630 - val_f1_31: 0.6207 - val_f1_32: 1.0000 - val_f1_33: 0.8029 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7907 - val_f1_36: 0.0333 - val_f1_37: 0.9480 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7876 - val_f1_40: 0.8535 - val_f1_41: 0.0000e+00 - val_f1_42: 0.7007 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9739\n",
            "Epoch 16/40\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.0440 - accuracy: 0.9881 - f1: 0.4890 - f1_1: 0.9558 - f1_3: 0.6018 - f1_4: 0.9586 - f1_5: 0.9221 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.6403 - f1_10: 0.9442 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7065 - f1_15: 0.9940 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8497 - f1_25: 0.9766 - f1_27: 0.5011 - f1_28: 0.8455 - f1_29: 0.9082 - f1_30: 0.9675 - f1_31: 0.6883 - f1_32: 0.9985 - f1_33: 0.7884 - f1_34: 0.0000e+00 - f1_35: 0.8245 - f1_36: 0.1094 - f1_37: 0.9513 - f1_38: 0.0000e+00 - f1_39: 0.8383 - f1_40: 0.8889 - f1_41: 0.0000e+00 - f1_42: 0.7086 - f1_43: 0.0000e+00 - f1_44: 0.9908 - val_loss: 0.0510 - val_accuracy: 0.9859 - val_f1: 0.4737 - val_f1_1: 0.9455 - val_f1_3: 0.5895 - val_f1_4: 0.9602 - val_f1_5: 0.8952 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6092 - val_f1_10: 0.9444 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6612 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8126 - val_f1_25: 0.9758 - val_f1_27: 0.3380 - val_f1_28: 0.8170 - val_f1_29: 0.8986 - val_f1_30: 0.9662 - val_f1_31: 0.6227 - val_f1_32: 1.0000 - val_f1_33: 0.8029 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7911 - val_f1_36: 0.0590 - val_f1_37: 0.9213 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7797 - val_f1_40: 0.8524 - val_f1_41: 0.0000e+00 - val_f1_42: 0.7157 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9930\n",
            "Epoch 17/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0426 - accuracy: 0.9885 - f1: 0.4969 - f1_1: 0.9574 - f1_3: 0.6129 - f1_4: 0.9597 - f1_5: 0.9255 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.6534 - f1_10: 0.9454 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7099 - f1_15: 0.9936 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8583 - f1_25: 0.9776 - f1_27: 0.5611 - f1_28: 0.8526 - f1_29: 0.9102 - f1_30: 0.9726 - f1_31: 0.7034 - f1_32: 0.9984 - f1_33: 0.8241 - f1_34: 0.0000e+00 - f1_35: 0.8298 - f1_36: 0.2071 - f1_37: 0.9601 - f1_38: 0.0000e+00 - f1_39: 0.8425 - f1_40: 0.8921 - f1_41: 0.0000e+00 - f1_42: 0.7379 - f1_43: 0.0000e+00 - f1_44: 0.9910 - val_loss: 0.0503 - val_accuracy: 0.9860 - val_f1: 0.4776 - val_f1_1: 0.9492 - val_f1_3: 0.5283 - val_f1_4: 0.9614 - val_f1_5: 0.9033 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6566 - val_f1_10: 0.9411 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6607 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8090 - val_f1_25: 0.9812 - val_f1_27: 0.3776 - val_f1_28: 0.8219 - val_f1_29: 0.9047 - val_f1_30: 0.9658 - val_f1_31: 0.6591 - val_f1_32: 1.0000 - val_f1_33: 0.8343 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8192 - val_f1_36: 0.1000 - val_f1_37: 0.9267 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7772 - val_f1_40: 0.8507 - val_f1_41: 0.0000e+00 - val_f1_42: 0.6912 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9891\n",
            "Epoch 18/40\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.0419 - accuracy: 0.9886 - f1: 0.5003 - f1_1: 0.9597 - f1_3: 0.5919 - f1_4: 0.9611 - f1_5: 0.9252 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.6518 - f1_10: 0.9496 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7227 - f1_15: 0.9937 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8575 - f1_25: 0.9777 - f1_27: 0.6637 - f1_28: 0.8522 - f1_29: 0.9141 - f1_30: 0.9715 - f1_31: 0.7053 - f1_32: 0.9987 - f1_33: 0.8235 - f1_34: 0.0000e+00 - f1_35: 0.8321 - f1_36: 0.2257 - f1_37: 0.9607 - f1_38: 0.0000e+00 - f1_39: 0.8420 - f1_40: 0.8977 - f1_41: 0.0000e+00 - f1_42: 0.7418 - f1_43: 0.0000e+00 - f1_44: 0.9909 - val_loss: 0.0502 - val_accuracy: 0.9859 - val_f1: 0.4838 - val_f1_1: 0.9555 - val_f1_3: 0.6206 - val_f1_4: 0.9648 - val_f1_5: 0.9177 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6110 - val_f1_10: 0.9472 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6380 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8141 - val_f1_25: 0.9778 - val_f1_27: 0.4589 - val_f1_28: 0.8423 - val_f1_29: 0.8996 - val_f1_30: 0.9632 - val_f1_31: 0.6451 - val_f1_32: 1.0000 - val_f1_33: 0.8773 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7688 - val_f1_36: 0.1418 - val_f1_37: 0.9531 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7909 - val_f1_40: 0.8581 - val_f1_41: 0.0000e+00 - val_f1_42: 0.7154 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9945\n",
            "Epoch 19/40\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.0411 - accuracy: 0.9888 - f1: 0.5031 - f1_1: 0.9662 - f1_3: 0.6269 - f1_4: 0.9621 - f1_5: 0.9316 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.6763 - f1_10: 0.9493 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7265 - f1_15: 0.9918 - f1_16: 0.0000e+00 - f1_17: 0.0282 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.8527 - f1_25: 0.9807 - f1_27: 0.5626 - f1_28: 0.8566 - f1_29: 0.9161 - f1_30: 0.9744 - f1_31: 0.7062 - f1_32: 0.9985 - f1_33: 0.8532 - f1_34: 0.0000e+00 - f1_35: 0.8322 - f1_36: 0.2686 - f1_37: 0.9675 - f1_38: 0.0000e+00 - f1_39: 0.8540 - f1_40: 0.9035 - f1_41: 0.0000e+00 - f1_42: 0.7440 - f1_43: 0.0000e+00 - f1_44: 0.9939 - val_loss: 0.0486 - val_accuracy: 0.9864 - val_f1: 0.4883 - val_f1_1: 0.9555 - val_f1_3: 0.6022 - val_f1_4: 0.9642 - val_f1_5: 0.9191 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6619 - val_f1_10: 0.9494 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6855 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0284 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8107 - val_f1_25: 0.9826 - val_f1_27: 0.4421 - val_f1_28: 0.8185 - val_f1_29: 0.9077 - val_f1_30: 0.9658 - val_f1_31: 0.6602 - val_f1_32: 1.0000 - val_f1_33: 0.8758 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8135 - val_f1_36: 0.1976 - val_f1_37: 0.9551 - val_f1_38: 0.0000e+00 - val_f1_39: 0.7773 - val_f1_40: 0.8553 - val_f1_41: 0.0000e+00 - val_f1_42: 0.7118 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9945\n",
            "Epoch 20/40\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.0399 - accuracy: 0.9892 - f1: 0.5139 - f1_1: 0.9660 - f1_3: 0.6413 - f1_4: 0.9629 - f1_5: 0.9340 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.6957 - f1_10: 0.9508 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7297 - f1_15: 0.9944 - f1_16: 0.0000e+00 - f1_17: 0.0396 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0312 - f1_24: 0.8615 - f1_25: 0.9761 - f1_27: 0.7494 - f1_28: 0.8586 - f1_29: 0.9165 - f1_30: 0.9724 - f1_31: 0.7295 - f1_32: 0.9984 - f1_33: 0.8482 - f1_34: 0.0000e+00 - f1_35: 0.8393 - f1_36: 0.3946 - f1_37: 0.9691 - f1_38: 0.0000e+00 - f1_39: 0.8496 - f1_40: 0.9043 - f1_41: 0.0000e+00 - f1_42: 0.7506 - f1_43: 0.0000e+00 - f1_44: 0.9917 - val_loss: 0.0477 - val_accuracy: 0.9867 - val_f1: 0.4933 - val_f1_1: 0.9613 - val_f1_3: 0.5782 - val_f1_4: 0.9664 - val_f1_5: 0.9258 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6463 - val_f1_10: 0.9493 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.7017 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0139 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8161 - val_f1_25: 0.9826 - val_f1_27: 0.5937 - val_f1_28: 0.8213 - val_f1_29: 0.9092 - val_f1_30: 0.9685 - val_f1_31: 0.6606 - val_f1_32: 1.0000 - val_f1_33: 0.8999 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8082 - val_f1_36: 0.1865 - val_f1_37: 0.9596 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8019 - val_f1_40: 0.8598 - val_f1_41: 0.0000e+00 - val_f1_42: 0.7302 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9945\n",
            "Epoch 21/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0391 - accuracy: 0.9893 - f1: 0.5191 - f1_1: 0.9644 - f1_3: 0.6566 - f1_4: 0.9647 - f1_5: 0.9357 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.6950 - f1_10: 0.9545 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7382 - f1_15: 0.9946 - f1_16: 0.0000e+00 - f1_17: 0.0710 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0942 - f1_24: 0.8625 - f1_25: 0.9851 - f1_27: 0.7423 - f1_28: 0.8649 - f1_29: 0.9230 - f1_30: 0.9740 - f1_31: 0.7312 - f1_32: 0.9986 - f1_33: 0.8501 - f1_34: 0.0000e+00 - f1_35: 0.8382 - f1_36: 0.4167 - f1_37: 0.9725 - f1_38: 0.0000e+00 - f1_39: 0.8540 - f1_40: 0.9078 - f1_41: 0.0179 - f1_42: 0.7646 - f1_43: 0.0000e+00 - f1_44: 0.9938 - val_loss: 0.0480 - val_accuracy: 0.9863 - val_f1: 0.4950 - val_f1_1: 0.9666 - val_f1_3: 0.6014 - val_f1_4: 0.9662 - val_f1_5: 0.9088 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6118 - val_f1_10: 0.9499 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6844 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0139 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0417 - val_f1_24: 0.8088 - val_f1_25: 0.9796 - val_f1_27: 0.5988 - val_f1_28: 0.8254 - val_f1_29: 0.8979 - val_f1_30: 0.9688 - val_f1_31: 0.6765 - val_f1_32: 1.0000 - val_f1_33: 0.9076 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7908 - val_f1_36: 0.2256 - val_f1_37: 0.9579 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8023 - val_f1_40: 0.8600 - val_f1_41: 0.0372 - val_f1_42: 0.7254 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 22/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0387 - accuracy: 0.9894 - f1: 0.5271 - f1_1: 0.9750 - f1_3: 0.6483 - f1_4: 0.9655 - f1_5: 0.9351 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.7041 - f1_10: 0.9557 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7468 - f1_15: 0.9954 - f1_16: 0.0000e+00 - f1_17: 0.0526 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.2604 - f1_24: 0.8582 - f1_25: 0.9782 - f1_27: 0.7675 - f1_28: 0.8682 - f1_29: 0.9222 - f1_30: 0.9754 - f1_31: 0.7306 - f1_32: 0.9985 - f1_33: 0.8906 - f1_34: 0.0000e+00 - f1_35: 0.8399 - f1_36: 0.4538 - f1_37: 0.9735 - f1_38: 0.0000e+00 - f1_39: 0.8604 - f1_40: 0.9052 - f1_41: 0.0647 - f1_42: 0.7643 - f1_43: 0.0000e+00 - f1_44: 0.9948 - val_loss: 0.0468 - val_accuracy: 0.9866 - val_f1: 0.5065 - val_f1_1: 0.9677 - val_f1_3: 0.6185 - val_f1_4: 0.9664 - val_f1_5: 0.9114 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6799 - val_f1_10: 0.9474 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6565 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0284 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.2467 - val_f1_24: 0.8191 - val_f1_25: 0.9812 - val_f1_27: 0.5988 - val_f1_28: 0.8332 - val_f1_29: 0.9052 - val_f1_30: 0.9692 - val_f1_31: 0.6442 - val_f1_32: 1.0000 - val_f1_33: 0.9210 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8209 - val_f1_36: 0.3613 - val_f1_37: 0.9607 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8045 - val_f1_40: 0.8623 - val_f1_41: 0.0372 - val_f1_42: 0.7242 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 23/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0375 - accuracy: 0.9898 - f1: 0.5318 - f1_1: 0.9763 - f1_3: 0.6692 - f1_4: 0.9659 - f1_5: 0.9405 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.7135 - f1_10: 0.9564 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7465 - f1_15: 0.9851 - f1_16: 0.0000e+00 - f1_17: 0.0609 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.2586 - f1_24: 0.8702 - f1_25: 0.9823 - f1_27: 0.7875 - f1_28: 0.8793 - f1_29: 0.9257 - f1_30: 0.9770 - f1_31: 0.7271 - f1_32: 0.9985 - f1_33: 0.9007 - f1_34: 0.0000e+00 - f1_35: 0.8450 - f1_36: 0.4809 - f1_37: 0.9756 - f1_38: 0.0000e+00 - f1_39: 0.8615 - f1_40: 0.9137 - f1_41: 0.0887 - f1_42: 0.7902 - f1_43: 0.0000e+00 - f1_44: 0.9960 - val_loss: 0.0459 - val_accuracy: 0.9870 - val_f1: 0.5095 - val_f1_1: 0.9643 - val_f1_3: 0.6275 - val_f1_4: 0.9682 - val_f1_5: 0.9132 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6548 - val_f1_10: 0.9526 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6796 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0284 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.2967 - val_f1_24: 0.8167 - val_f1_25: 0.9812 - val_f1_27: 0.6178 - val_f1_28: 0.8567 - val_f1_29: 0.9060 - val_f1_30: 0.9710 - val_f1_31: 0.6304 - val_f1_32: 1.0000 - val_f1_33: 0.8966 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8162 - val_f1_36: 0.3921 - val_f1_37: 0.9613 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8079 - val_f1_40: 0.8657 - val_f1_41: 0.0372 - val_f1_42: 0.7444 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 24/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0368 - accuracy: 0.9900 - f1: 0.5386 - f1_1: 0.9761 - f1_3: 0.6746 - f1_4: 0.9690 - f1_5: 0.9380 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.7187 - f1_10: 0.9578 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7540 - f1_15: 0.9954 - f1_16: 0.0000e+00 - f1_17: 0.0908 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.2973 - f1_24: 0.8663 - f1_25: 0.9824 - f1_27: 0.7840 - f1_28: 0.8694 - f1_29: 0.9246 - f1_30: 0.9770 - f1_31: 0.7395 - f1_32: 0.9988 - f1_33: 0.9031 - f1_34: 0.0000e+00 - f1_35: 0.8520 - f1_36: 0.4936 - f1_37: 0.9794 - f1_38: 0.0000e+00 - f1_39: 0.8668 - f1_40: 0.9147 - f1_41: 0.2562 - f1_42: 0.7656 - f1_43: 0.0000e+00 - f1_44: 0.9973 - val_loss: 0.0455 - val_accuracy: 0.9869 - val_f1: 0.5180 - val_f1_1: 0.9720 - val_f1_3: 0.6202 - val_f1_4: 0.9681 - val_f1_5: 0.9303 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6853 - val_f1_10: 0.9505 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6778 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0363 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.4463 - val_f1_24: 0.8240 - val_f1_25: 0.9826 - val_f1_27: 0.6131 - val_f1_28: 0.8364 - val_f1_29: 0.9075 - val_f1_30: 0.9715 - val_f1_31: 0.6751 - val_f1_32: 1.0000 - val_f1_33: 0.9163 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8223 - val_f1_36: 0.4058 - val_f1_37: 0.9596 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8043 - val_f1_40: 0.8641 - val_f1_41: 0.1006 - val_f1_42: 0.7581 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9945\n",
            "Epoch 25/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0359 - accuracy: 0.9903 - f1: 0.5502 - f1_1: 0.9766 - f1_3: 0.6761 - f1_4: 0.9682 - f1_5: 0.9429 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0208 - f1_9: 0.7326 - f1_10: 0.9582 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7578 - f1_15: 0.9931 - f1_16: 0.0000e+00 - f1_17: 0.0981 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.5113 - f1_24: 0.8747 - f1_25: 0.9865 - f1_27: 0.8000 - f1_28: 0.8763 - f1_29: 0.9368 - f1_30: 0.9778 - f1_31: 0.7344 - f1_32: 0.9985 - f1_33: 0.9309 - f1_34: 0.0000e+00 - f1_35: 0.8547 - f1_36: 0.5618 - f1_37: 0.9784 - f1_38: 0.0000e+00 - f1_39: 0.8641 - f1_40: 0.9134 - f1_41: 0.2943 - f1_42: 0.7911 - f1_43: 0.0000e+00 - f1_44: 0.9979 - val_loss: 0.0447 - val_accuracy: 0.9872 - val_f1: 0.5199 - val_f1_1: 0.9602 - val_f1_3: 0.6613 - val_f1_4: 0.9680 - val_f1_5: 0.9320 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.6756 - val_f1_10: 0.9576 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6890 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0363 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.4463 - val_f1_24: 0.8194 - val_f1_25: 0.9796 - val_f1_27: 0.6610 - val_f1_28: 0.8412 - val_f1_29: 0.9123 - val_f1_30: 0.9688 - val_f1_31: 0.6892 - val_f1_32: 1.0000 - val_f1_33: 0.8723 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8185 - val_f1_36: 0.3892 - val_f1_37: 0.9625 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8359 - val_f1_40: 0.8632 - val_f1_41: 0.0848 - val_f1_42: 0.7788 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9945\n",
            "Epoch 26/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0355 - accuracy: 0.9903 - f1: 0.5559 - f1_1: 0.9791 - f1_3: 0.6814 - f1_4: 0.9676 - f1_5: 0.9430 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0681 - f1_9: 0.7251 - f1_10: 0.9599 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7584 - f1_15: 0.9950 - f1_16: 0.0000e+00 - f1_17: 0.1044 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.6689 - f1_24: 0.8771 - f1_25: 0.9806 - f1_27: 0.7613 - f1_28: 0.8746 - f1_29: 0.9270 - f1_30: 0.9736 - f1_31: 0.7416 - f1_32: 0.9987 - f1_33: 0.8962 - f1_34: 0.0497 - f1_35: 0.8529 - f1_36: 0.5504 - f1_37: 0.9792 - f1_38: 0.0000e+00 - f1_39: 0.8709 - f1_40: 0.9104 - f1_41: 0.3363 - f1_42: 0.7942 - f1_43: 0.0156 - f1_44: 0.9958 - val_loss: 0.0459 - val_accuracy: 0.9868 - val_f1: 0.5229 - val_f1_1: 0.9613 - val_f1_3: 0.6794 - val_f1_4: 0.9744 - val_f1_5: 0.9270 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0238 - val_f1_9: 0.7241 - val_f1_10: 0.9515 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.7282 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0501 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.5243 - val_f1_24: 0.8227 - val_f1_25: 0.9916 - val_f1_27: 0.5524 - val_f1_28: 0.8577 - val_f1_29: 0.9069 - val_f1_30: 0.9728 - val_f1_31: 0.6642 - val_f1_32: 1.0000 - val_f1_33: 0.9129 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7775 - val_f1_36: 0.3915 - val_f1_37: 0.9633 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8186 - val_f1_40: 0.8711 - val_f1_41: 0.1006 - val_f1_42: 0.7746 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 27/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0349 - accuracy: 0.9905 - f1: 0.5610 - f1_1: 0.9780 - f1_3: 0.6795 - f1_4: 0.9710 - f1_5: 0.9425 - f1_6: 0.0000e+00 - f1_7: 0.0000e+00 - f1_8: 0.0991 - f1_9: 0.7339 - f1_10: 0.9611 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7671 - f1_15: 0.9925 - f1_16: 0.0000e+00 - f1_17: 0.0970 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.6692 - f1_24: 0.8748 - f1_25: 0.9818 - f1_27: 0.8097 - f1_28: 0.8768 - f1_29: 0.9363 - f1_30: 0.9730 - f1_31: 0.7566 - f1_32: 0.9985 - f1_33: 0.9322 - f1_34: 0.0000e+00 - f1_35: 0.8570 - f1_36: 0.5853 - f1_37: 0.9768 - f1_38: 0.0000e+00 - f1_39: 0.8734 - f1_40: 0.9238 - f1_41: 0.3959 - f1_42: 0.8020 - f1_43: 0.0000e+00 - f1_44: 0.9964 - val_loss: 0.0446 - val_accuracy: 0.9871 - val_f1: 0.5249 - val_f1_1: 0.9733 - val_f1_3: 0.6258 - val_f1_4: 0.9753 - val_f1_5: 0.9295 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0405 - val_f1_9: 0.6914 - val_f1_10: 0.9492 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6877 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0679 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.4698 - val_f1_24: 0.8172 - val_f1_25: 0.9857 - val_f1_27: 0.6287 - val_f1_28: 0.8565 - val_f1_29: 0.9031 - val_f1_30: 0.9725 - val_f1_31: 0.6609 - val_f1_32: 1.0000 - val_f1_33: 0.9092 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8236 - val_f1_36: 0.4213 - val_f1_37: 0.9660 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8035 - val_f1_40: 0.8657 - val_f1_41: 0.2328 - val_f1_42: 0.7465 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 28/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0341 - accuracy: 0.9907 - f1: 0.5664 - f1_1: 0.9774 - f1_3: 0.6970 - f1_4: 0.9715 - f1_5: 0.9453 - f1_6: 0.0312 - f1_7: 0.0000e+00 - f1_8: 0.1081 - f1_9: 0.7413 - f1_10: 0.9596 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7685 - f1_15: 0.9943 - f1_16: 0.0000e+00 - f1_17: 0.1240 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.7404 - f1_24: 0.8812 - f1_25: 0.9865 - f1_27: 0.7185 - f1_28: 0.8828 - f1_29: 0.9335 - f1_30: 0.9780 - f1_31: 0.7599 - f1_32: 0.9985 - f1_33: 0.9267 - f1_34: 0.0417 - f1_35: 0.8605 - f1_36: 0.6046 - f1_37: 0.9792 - f1_38: 0.0000e+00 - f1_39: 0.8726 - f1_40: 0.9190 - f1_41: 0.4371 - f1_42: 0.8080 - f1_43: 0.0096 - f1_44: 0.9976 - val_loss: 0.0438 - val_accuracy: 0.9874 - val_f1: 0.5295 - val_f1_1: 0.9696 - val_f1_3: 0.6803 - val_f1_4: 0.9709 - val_f1_5: 0.9337 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0714 - val_f1_9: 0.6941 - val_f1_10: 0.9609 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.7182 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0720 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.6466 - val_f1_24: 0.8133 - val_f1_25: 0.9868 - val_f1_27: 0.6610 - val_f1_28: 0.8455 - val_f1_29: 0.9177 - val_f1_30: 0.9689 - val_f1_31: 0.7148 - val_f1_32: 1.0000 - val_f1_33: 0.8743 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8229 - val_f1_36: 0.3589 - val_f1_37: 0.9557 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8333 - val_f1_40: 0.8601 - val_f1_41: 0.0848 - val_f1_42: 0.7716 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 29/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0336 - accuracy: 0.9908 - f1: 0.5755 - f1_1: 0.9814 - f1_3: 0.6825 - f1_4: 0.9725 - f1_5: 0.9461 - f1_6: 0.0125 - f1_7: 0.0000e+00 - f1_8: 0.2139 - f1_9: 0.7559 - f1_10: 0.9607 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7721 - f1_15: 0.9926 - f1_16: 0.0000e+00 - f1_17: 0.1669 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.8216 - f1_24: 0.8760 - f1_25: 0.9846 - f1_27: 0.8002 - f1_28: 0.8870 - f1_29: 0.9345 - f1_30: 0.9777 - f1_31: 0.7520 - f1_32: 0.9984 - f1_33: 0.9271 - f1_34: 0.0937 - f1_35: 0.8623 - f1_36: 0.5545 - f1_37: 0.9789 - f1_38: 0.0000e+00 - f1_39: 0.8766 - f1_40: 0.9193 - f1_41: 0.4792 - f1_42: 0.8207 - f1_43: 0.0208 - f1_44: 0.9981 - val_loss: 0.0428 - val_accuracy: 0.9877 - val_f1: 0.5347 - val_f1_1: 0.9720 - val_f1_3: 0.6715 - val_f1_4: 0.9745 - val_f1_5: 0.9353 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.0775 - val_f1_9: 0.7015 - val_f1_10: 0.9594 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.7181 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0671 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.6902 - val_f1_24: 0.8298 - val_f1_25: 0.9857 - val_f1_27: 0.6610 - val_f1_28: 0.8529 - val_f1_29: 0.9114 - val_f1_30: 0.9733 - val_f1_31: 0.6658 - val_f1_32: 1.0000 - val_f1_33: 0.9064 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8155 - val_f1_36: 0.4523 - val_f1_37: 0.9651 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8447 - val_f1_40: 0.8675 - val_f1_41: 0.1323 - val_f1_42: 0.7635 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 30/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0331 - accuracy: 0.9909 - f1: 0.5792 - f1_1: 0.9770 - f1_3: 0.6947 - f1_4: 0.9726 - f1_5: 0.9438 - f1_6: 0.0281 - f1_7: 0.0000e+00 - f1_8: 0.1515 - f1_9: 0.7577 - f1_10: 0.9635 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7803 - f1_15: 0.9953 - f1_16: 0.0000e+00 - f1_17: 0.1796 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.7995 - f1_24: 0.8833 - f1_25: 0.9877 - f1_27: 0.7922 - f1_28: 0.8901 - f1_29: 0.9444 - f1_30: 0.9776 - f1_31: 0.7707 - f1_32: 0.9987 - f1_33: 0.9389 - f1_34: 0.0687 - f1_35: 0.8631 - f1_36: 0.6264 - f1_37: 0.9833 - f1_38: 0.0000e+00 - f1_39: 0.8770 - f1_40: 0.9213 - f1_41: 0.5609 - f1_42: 0.8245 - f1_43: 0.0179 - f1_44: 0.9960 - val_loss: 0.0433 - val_accuracy: 0.9875 - val_f1: 0.5413 - val_f1_1: 0.9686 - val_f1_3: 0.6838 - val_f1_4: 0.9756 - val_f1_5: 0.9317 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.2010 - val_f1_9: 0.7280 - val_f1_10: 0.9547 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6941 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0673 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.6783 - val_f1_24: 0.8267 - val_f1_25: 0.9840 - val_f1_27: 0.5949 - val_f1_28: 0.8633 - val_f1_29: 0.9118 - val_f1_30: 0.9738 - val_f1_31: 0.6561 - val_f1_32: 1.0000 - val_f1_33: 0.9126 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8183 - val_f1_36: 0.4127 - val_f1_37: 0.9633 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8319 - val_f1_40: 0.8698 - val_f1_41: 0.3715 - val_f1_42: 0.7825 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 31/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0322 - accuracy: 0.9913 - f1: 0.5869 - f1_1: 0.9787 - f1_3: 0.6935 - f1_4: 0.9731 - f1_5: 0.9474 - f1_6: 0.0640 - f1_7: 0.0000e+00 - f1_8: 0.2228 - f1_9: 0.7614 - f1_10: 0.9628 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7815 - f1_15: 0.9934 - f1_16: 0.0000e+00 - f1_17: 0.2277 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.8134 - f1_24: 0.8900 - f1_25: 0.9867 - f1_27: 0.7998 - f1_28: 0.8911 - f1_29: 0.9420 - f1_30: 0.9781 - f1_31: 0.7697 - f1_32: 0.9976 - f1_33: 0.9458 - f1_34: 0.0969 - f1_35: 0.8681 - f1_36: 0.6617 - f1_37: 0.9820 - f1_38: 0.0000e+00 - f1_39: 0.8834 - f1_40: 0.9239 - f1_41: 0.5681 - f1_42: 0.8315 - f1_43: 0.0429 - f1_44: 0.9957 - val_loss: 0.0430 - val_accuracy: 0.9874 - val_f1: 0.5350 - val_f1_1: 0.9762 - val_f1_3: 0.6701 - val_f1_4: 0.9744 - val_f1_5: 0.9347 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.1238 - val_f1_9: 0.7150 - val_f1_10: 0.9610 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6766 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0673 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.6902 - val_f1_24: 0.8282 - val_f1_25: 0.9857 - val_f1_27: 0.6510 - val_f1_28: 0.8633 - val_f1_29: 0.9085 - val_f1_30: 0.9727 - val_f1_31: 0.6453 - val_f1_32: 1.0000 - val_f1_33: 0.9143 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8038 - val_f1_36: 0.4272 - val_f1_37: 0.9638 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8405 - val_f1_40: 0.8686 - val_f1_41: 0.1559 - val_f1_42: 0.7892 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 32/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0315 - accuracy: 0.9914 - f1: 0.5899 - f1_1: 0.9831 - f1_3: 0.6972 - f1_4: 0.9742 - f1_5: 0.9486 - f1_6: 0.0396 - f1_7: 0.0000e+00 - f1_8: 0.2825 - f1_9: 0.7682 - f1_10: 0.9647 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.7825 - f1_15: 0.9909 - f1_16: 0.0000e+00 - f1_17: 0.1710 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.8579 - f1_24: 0.8936 - f1_25: 0.9912 - f1_27: 0.7777 - f1_28: 0.8972 - f1_29: 0.9456 - f1_30: 0.9742 - f1_31: 0.7670 - f1_32: 0.9984 - f1_33: 0.9481 - f1_34: 0.0644 - f1_35: 0.8653 - f1_36: 0.6583 - f1_37: 0.9839 - f1_38: 0.0000e+00 - f1_39: 0.8847 - f1_40: 0.9310 - f1_41: 0.6586 - f1_42: 0.8335 - f1_43: 0.0651 - f1_44: 0.9980 - val_loss: 0.0434 - val_accuracy: 0.9871 - val_f1: 0.5468 - val_f1_1: 0.9686 - val_f1_3: 0.6810 - val_f1_4: 0.9754 - val_f1_5: 0.9343 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.2162 - val_f1_9: 0.6859 - val_f1_10: 0.9602 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.6786 - val_f1_15: 1.0000 - val_f1_16: 0.0000e+00 - val_f1_17: 0.1002 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.7513 - val_f1_24: 0.8161 - val_f1_25: 0.9825 - val_f1_27: 0.6610 - val_f1_28: 0.8447 - val_f1_29: 0.9011 - val_f1_30: 0.9730 - val_f1_31: 0.7007 - val_f1_32: 1.0000 - val_f1_33: 0.9223 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7882 - val_f1_36: 0.4485 - val_f1_37: 0.9641 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8431 - val_f1_40: 0.8658 - val_f1_41: 0.4134 - val_f1_42: 0.8014 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 33/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0315 - accuracy: 0.9914 - f1: 0.5957 - f1_1: 0.9833 - f1_3: 0.7102 - f1_4: 0.9745 - f1_5: 0.9491 - f1_6: 0.0645 - f1_7: 0.0000e+00 - f1_8: 0.2558 - f1_9: 0.7724 - f1_10: 0.9650 - f1_12: 0.0000e+00 - f1_13: 0.0729 - f1_14: 0.7930 - f1_15: 0.9940 - f1_16: 0.0000e+00 - f1_17: 0.1803 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9341 - f1_24: 0.8850 - f1_25: 0.9872 - f1_27: 0.8040 - f1_28: 0.8924 - f1_29: 0.9465 - f1_30: 0.9798 - f1_31: 0.7816 - f1_32: 0.9987 - f1_33: 0.9413 - f1_34: 0.0729 - f1_35: 0.8633 - f1_36: 0.6341 - f1_37: 0.9838 - f1_38: 0.0000e+00 - f1_39: 0.8870 - f1_40: 0.9333 - f1_41: 0.6526 - f1_42: 0.8414 - f1_43: 0.0982 - f1_44: 0.9971 - val_loss: 0.0425 - val_accuracy: 0.9877 - val_f1: 0.5464 - val_f1_1: 0.9791 - val_f1_3: 0.6342 - val_f1_4: 0.9768 - val_f1_5: 0.9331 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.1934 - val_f1_9: 0.7384 - val_f1_10: 0.9522 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.7407 - val_f1_15: 0.9971 - val_f1_16: 0.0000e+00 - val_f1_17: 0.1318 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.7079 - val_f1_24: 0.7957 - val_f1_25: 0.9886 - val_f1_27: 0.6458 - val_f1_28: 0.8620 - val_f1_29: 0.9204 - val_f1_30: 0.9726 - val_f1_31: 0.6790 - val_f1_32: 1.0000 - val_f1_33: 0.9168 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8349 - val_f1_36: 0.4309 - val_f1_37: 0.9695 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8381 - val_f1_40: 0.8728 - val_f1_41: 0.3856 - val_f1_42: 0.7608 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 34/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0306 - accuracy: 0.9917 - f1: 0.6026 - f1_1: 0.9850 - f1_3: 0.7089 - f1_4: 0.9744 - f1_5: 0.9481 - f1_6: 0.0833 - f1_7: 0.0000e+00 - f1_8: 0.2963 - f1_9: 0.7722 - f1_10: 0.9653 - f1_12: 0.0000e+00 - f1_13: 0.0253 - f1_14: 0.7944 - f1_15: 0.9935 - f1_16: 0.0000e+00 - f1_17: 0.3049 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9482 - f1_24: 0.8917 - f1_25: 0.9898 - f1_27: 0.8256 - f1_28: 0.9029 - f1_29: 0.9508 - f1_30: 0.9780 - f1_31: 0.7769 - f1_32: 0.9987 - f1_33: 0.9535 - f1_34: 0.0875 - f1_35: 0.8721 - f1_36: 0.6565 - f1_37: 0.9833 - f1_38: 0.0000e+00 - f1_39: 0.8917 - f1_40: 0.9339 - f1_41: 0.6125 - f1_42: 0.8409 - f1_43: 0.1627 - f1_44: 0.9961 - val_loss: 0.0413 - val_accuracy: 0.9878 - val_f1: 0.5480 - val_f1_1: 0.9749 - val_f1_3: 0.6726 - val_f1_4: 0.9757 - val_f1_5: 0.9395 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.1421 - val_f1_9: 0.6895 - val_f1_10: 0.9640 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.7143 - val_f1_15: 1.0000 - val_f1_16: 0.0000e+00 - val_f1_17: 0.1137 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.7590 - val_f1_24: 0.8294 - val_f1_25: 0.9857 - val_f1_27: 0.6610 - val_f1_28: 0.8616 - val_f1_29: 0.9095 - val_f1_30: 0.9727 - val_f1_31: 0.6975 - val_f1_32: 1.0000 - val_f1_33: 0.8950 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8348 - val_f1_36: 0.4459 - val_f1_37: 0.9651 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8289 - val_f1_40: 0.8719 - val_f1_41: 0.4239 - val_f1_42: 0.7938 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 35/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0298 - accuracy: 0.9920 - f1: 0.6105 - f1_1: 0.9848 - f1_3: 0.7194 - f1_4: 0.9765 - f1_5: 0.9535 - f1_6: 0.0721 - f1_7: 0.0000e+00 - f1_8: 0.3200 - f1_9: 0.7870 - f1_10: 0.9680 - f1_12: 0.0000e+00 - f1_13: 0.0387 - f1_14: 0.8011 - f1_15: 0.9946 - f1_16: 0.0000e+00 - f1_17: 0.2859 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9559 - f1_24: 0.9022 - f1_25: 0.9884 - f1_27: 0.7791 - f1_28: 0.9092 - f1_29: 0.9480 - f1_30: 0.9792 - f1_31: 0.7912 - f1_32: 0.9986 - f1_33: 0.9375 - f1_34: 0.1698 - f1_35: 0.8799 - f1_36: 0.6573 - f1_37: 0.9848 - f1_38: 0.0000e+00 - f1_39: 0.8958 - f1_40: 0.9341 - f1_41: 0.7766 - f1_42: 0.8360 - f1_43: 0.1969 - f1_44: 0.9980 - val_loss: 0.0413 - val_accuracy: 0.9878 - val_f1: 0.5509 - val_f1_1: 0.9775 - val_f1_3: 0.6643 - val_f1_4: 0.9761 - val_f1_5: 0.9396 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.1238 - val_f1_9: 0.7256 - val_f1_10: 0.9648 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.7154 - val_f1_15: 1.0000 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0976 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.8077 - val_f1_24: 0.8317 - val_f1_25: 0.9857 - val_f1_27: 0.6510 - val_f1_28: 0.8405 - val_f1_29: 0.9102 - val_f1_30: 0.9716 - val_f1_31: 0.7003 - val_f1_32: 1.0000 - val_f1_33: 0.9207 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8402 - val_f1_36: 0.4459 - val_f1_37: 0.9643 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8358 - val_f1_40: 0.8698 - val_f1_41: 0.4239 - val_f1_42: 0.8130 - val_f1_43: 0.0417 - val_f1_44: 0.9966\n",
            "Epoch 36/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0292 - accuracy: 0.9921 - f1: 0.6128 - f1_1: 0.9844 - f1_3: 0.7188 - f1_4: 0.9774 - f1_5: 0.9518 - f1_6: 0.0742 - f1_7: 0.0000e+00 - f1_8: 0.3460 - f1_9: 0.7905 - f1_10: 0.9676 - f1_12: 0.0000e+00 - f1_13: 0.0863 - f1_14: 0.8092 - f1_15: 0.9935 - f1_16: 0.0000e+00 - f1_17: 0.3680 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.8500 - f1_24: 0.9021 - f1_25: 0.9885 - f1_27: 0.7695 - f1_28: 0.9043 - f1_29: 0.9558 - f1_30: 0.9791 - f1_31: 0.7925 - f1_32: 0.9973 - f1_33: 0.9594 - f1_34: 0.1994 - f1_35: 0.8791 - f1_36: 0.6915 - f1_37: 0.9847 - f1_38: 0.0000e+00 - f1_39: 0.8939 - f1_40: 0.9371 - f1_41: 0.7398 - f1_42: 0.8456 - f1_43: 0.1771 - f1_44: 0.9970 - val_loss: 0.0415 - val_accuracy: 0.9878 - val_f1: 0.5518 - val_f1_1: 0.9683 - val_f1_3: 0.6690 - val_f1_4: 0.9766 - val_f1_5: 0.9408 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.1238 - val_f1_9: 0.7262 - val_f1_10: 0.9643 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.7287 - val_f1_15: 1.0000 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0907 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.7759 - val_f1_24: 0.8339 - val_f1_25: 0.9904 - val_f1_27: 0.6510 - val_f1_28: 0.8659 - val_f1_29: 0.9146 - val_f1_30: 0.9733 - val_f1_31: 0.6812 - val_f1_32: 1.0000 - val_f1_33: 0.9035 - val_f1_34: 0.0333 - val_f1_35: 0.8178 - val_f1_36: 0.4402 - val_f1_37: 0.9653 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8143 - val_f1_40: 0.8708 - val_f1_41: 0.4693 - val_f1_42: 0.8117 - val_f1_43: 0.0750 - val_f1_44: 0.9966\n",
            "Epoch 37/40\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.0287 - accuracy: 0.9922 - f1: 0.6088 - f1_1: 0.9840 - f1_3: 0.7419 - f1_4: 0.9789 - f1_5: 0.9527 - f1_6: 0.1533 - f1_7: 0.0000e+00 - f1_8: 0.2485 - f1_9: 0.7964 - f1_10: 0.9676 - f1_12: 0.0000e+00 - f1_13: 0.1104 - f1_14: 0.8128 - f1_15: 0.9942 - f1_16: 0.0000e+00 - f1_17: 0.2465 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.8522 - f1_24: 0.9056 - f1_25: 0.9879 - f1_27: 0.7936 - f1_28: 0.9111 - f1_29: 0.9494 - f1_30: 0.9807 - f1_31: 0.7848 - f1_32: 0.9984 - f1_33: 0.9553 - f1_34: 0.1284 - f1_35: 0.8821 - f1_36: 0.6780 - f1_37: 0.9848 - f1_38: 0.0000e+00 - f1_39: 0.8935 - f1_40: 0.9370 - f1_41: 0.7241 - f1_42: 0.8572 - f1_43: 0.1646 - f1_44: 0.9975 - val_loss: 0.0405 - val_accuracy: 0.9882 - val_f1: 0.5663 - val_f1_1: 0.9788 - val_f1_3: 0.6727 - val_f1_4: 0.9771 - val_f1_5: 0.9383 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.2457 - val_f1_9: 0.7285 - val_f1_10: 0.9623 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.7311 - val_f1_15: 1.0000 - val_f1_16: 0.0000e+00 - val_f1_17: 0.2675 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.7910 - val_f1_24: 0.8323 - val_f1_25: 0.9857 - val_f1_27: 0.6438 - val_f1_28: 0.8541 - val_f1_29: 0.9144 - val_f1_30: 0.9754 - val_f1_31: 0.7109 - val_f1_32: 1.0000 - val_f1_33: 0.9207 - val_f1_34: 0.0750 - val_f1_35: 0.8224 - val_f1_36: 0.4627 - val_f1_37: 0.9672 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8462 - val_f1_40: 0.8729 - val_f1_41: 0.5542 - val_f1_42: 0.7999 - val_f1_43: 0.1250 - val_f1_44: 0.9966\n",
            "Epoch 38/40\n",
            "16/16 [==============================] - 67s 4s/step - loss: 0.0283 - accuracy: 0.9923 - f1: 0.6149 - f1_1: 0.9794 - f1_3: 0.7230 - f1_4: 0.9781 - f1_5: 0.9544 - f1_6: 0.1079 - f1_7: 0.0000e+00 - f1_8: 0.3267 - f1_9: 0.7982 - f1_10: 0.9689 - f1_12: 0.0000e+00 - f1_13: 0.1117 - f1_14: 0.8094 - f1_15: 0.9947 - f1_16: 0.0000e+00 - f1_17: 0.3541 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.8883 - f1_24: 0.9009 - f1_25: 0.9920 - f1_27: 0.8073 - f1_28: 0.9119 - f1_29: 0.9589 - f1_30: 0.9820 - f1_31: 0.7941 - f1_32: 0.9986 - f1_33: 0.9332 - f1_34: 0.1642 - f1_35: 0.8814 - f1_36: 0.6507 - f1_37: 0.9842 - f1_38: 0.0000e+00 - f1_39: 0.8980 - f1_40: 0.9402 - f1_41: 0.7871 - f1_42: 0.8543 - f1_43: 0.1637 - f1_44: 0.9966 - val_loss: 0.0411 - val_accuracy: 0.9877 - val_f1: 0.5540 - val_f1_1: 0.9763 - val_f1_3: 0.6774 - val_f1_4: 0.9764 - val_f1_5: 0.9362 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.2306 - val_f1_9: 0.7330 - val_f1_10: 0.9644 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0667 - val_f1_14: 0.6981 - val_f1_15: 1.0000 - val_f1_16: 0.0000e+00 - val_f1_17: 0.1331 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.7888 - val_f1_24: 0.8202 - val_f1_25: 0.9857 - val_f1_27: 0.6438 - val_f1_28: 0.8663 - val_f1_29: 0.9132 - val_f1_30: 0.9737 - val_f1_31: 0.6713 - val_f1_32: 1.0000 - val_f1_33: 0.9069 - val_f1_34: 0.0333 - val_f1_35: 0.8362 - val_f1_36: 0.4522 - val_f1_37: 0.9666 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8216 - val_f1_40: 0.8719 - val_f1_41: 0.4466 - val_f1_42: 0.7725 - val_f1_43: 0.0000e+00 - val_f1_44: 0.9966\n",
            "Epoch 39/40\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.0278 - accuracy: 0.9925 - f1: 0.6235 - f1_1: 0.9869 - f1_3: 0.7624 - f1_4: 0.9784 - f1_5: 0.9567 - f1_6: 0.1593 - f1_7: 0.0000e+00 - f1_8: 0.3248 - f1_9: 0.7963 - f1_10: 0.9696 - f1_12: 0.0000e+00 - f1_13: 0.1719 - f1_14: 0.8097 - f1_15: 0.9964 - f1_16: 0.0000e+00 - f1_17: 0.3592 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.9077 - f1_24: 0.9096 - f1_25: 0.9940 - f1_27: 0.8054 - f1_28: 0.9149 - f1_29: 0.9590 - f1_30: 0.9839 - f1_31: 0.7958 - f1_32: 0.9987 - f1_33: 0.9547 - f1_34: 0.1924 - f1_35: 0.8826 - f1_36: 0.6748 - f1_37: 0.9861 - f1_38: 0.0000e+00 - f1_39: 0.9002 - f1_40: 0.9395 - f1_41: 0.7077 - f1_42: 0.8602 - f1_43: 0.3047 - f1_44: 0.9979 - val_loss: 0.0409 - val_accuracy: 0.9879 - val_f1: 0.5609 - val_f1_1: 0.9817 - val_f1_3: 0.6750 - val_f1_4: 0.9779 - val_f1_5: 0.9212 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.2306 - val_f1_9: 0.7168 - val_f1_10: 0.9649 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.7229 - val_f1_15: 1.0000 - val_f1_16: 0.0000e+00 - val_f1_17: 0.2956 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.7872 - val_f1_24: 0.8287 - val_f1_25: 0.9857 - val_f1_27: 0.6610 - val_f1_28: 0.8674 - val_f1_29: 0.9066 - val_f1_30: 0.9732 - val_f1_31: 0.6548 - val_f1_32: 1.0000 - val_f1_33: 0.9198 - val_f1_34: 0.0333 - val_f1_35: 0.8447 - val_f1_36: 0.4297 - val_f1_37: 0.9648 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8130 - val_f1_40: 0.8688 - val_f1_41: 0.5138 - val_f1_42: 0.8094 - val_f1_43: 0.0895 - val_f1_44: 0.9966\n",
            "Epoch 40/40\n",
            "16/16 [==============================] - 67s 4s/step - loss: 0.0274 - accuracy: 0.9926 - f1: 0.6256 - f1_1: 0.9861 - f1_3: 0.7493 - f1_4: 0.9789 - f1_5: 0.9588 - f1_6: 0.1175 - f1_7: 0.0000e+00 - f1_8: 0.3466 - f1_9: 0.8053 - f1_10: 0.9688 - f1_12: 0.0000e+00 - f1_13: 0.1223 - f1_14: 0.8204 - f1_15: 0.9958 - f1_16: 0.0000e+00 - f1_17: 0.4027 - f1_18: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.8568 - f1_24: 0.9108 - f1_25: 0.9917 - f1_27: 0.8087 - f1_28: 0.9111 - f1_29: 0.9593 - f1_30: 0.9826 - f1_31: 0.8008 - f1_32: 0.9987 - f1_33: 0.9528 - f1_34: 0.2149 - f1_35: 0.8850 - f1_36: 0.6825 - f1_37: 0.9842 - f1_38: 0.0000e+00 - f1_39: 0.9016 - f1_40: 0.9372 - f1_41: 0.8199 - f1_42: 0.8664 - f1_43: 0.3077 - f1_44: 0.9972 - val_loss: 0.0400 - val_accuracy: 0.9882 - val_f1: 0.5704 - val_f1_1: 0.9788 - val_f1_3: 0.6658 - val_f1_4: 0.9766 - val_f1_5: 0.9402 - val_f1_6: 0.0000e+00 - val_f1_7: 0.0000e+00 - val_f1_8: 0.2786 - val_f1_9: 0.7403 - val_f1_10: 0.9640 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0667 - val_f1_14: 0.6956 - val_f1_15: 1.0000 - val_f1_16: 0.0000e+00 - val_f1_17: 0.1783 - val_f1_18: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.7788 - val_f1_24: 0.8304 - val_f1_25: 0.9857 - val_f1_27: 0.6510 - val_f1_28: 0.8635 - val_f1_29: 0.9146 - val_f1_30: 0.9754 - val_f1_31: 0.7211 - val_f1_32: 1.0000 - val_f1_33: 0.9215 - val_f1_34: 0.0750 - val_f1_35: 0.8356 - val_f1_36: 0.4931 - val_f1_37: 0.9667 - val_f1_38: 0.0000e+00 - val_f1_39: 0.8382 - val_f1_40: 0.8715 - val_f1_41: 0.6150 - val_f1_42: 0.8142 - val_f1_43: 0.1830 - val_f1_44: 0.9966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FqoJ74QgrtCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU"
      ],
      "metadata": {
        "id": "bI0aK0FusnW-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47dd17c0-5511-4873-8e1e-7f561fa56ba4",
        "id": "6FE0Xq6Osqza"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Lambda, Dense, GRU, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "gru = tf.keras.layers.GRU(256, return_sequences=True)\n",
        "\n",
        "model_gru = Sequential()\n",
        "model_gru.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model_gru.add(embedding_layer)\n",
        "model_gru.add(gru)\n",
        "model_gru.add(TimeDistributed(Dense(num_tags, activation='softmax')))\n",
        " \n",
        "model_gru.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(0.001),\n",
        "             metrics=['accuracy', f1, [metric_wrapper(i) for i in no_punct_indexes]])\n",
        " \n",
        "model_gru.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 249, 100)          1094900   \n",
            "                                                                 \n",
            " gru_22 (GRU)                (None, 249, 256)          274944    \n",
            "                                                                 \n",
            " time_distributed_21 (TimeDi  (None, 249, 46)          11822     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,381,666\n",
            "Trainable params: 286,766\n",
            "Non-trainable params: 1,094,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYKlazz3zr9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0588e4-73c6-4ab0-f26f-d5d8ddbc63bf"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "history_gru = model_gru.fit(train_sentences_X, cat_train_tags_y, batch_size=128, epochs=40, validation_data=(valid_sentences_X, cat_val_tags_y), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "16/16 [==============================] - 51s 3s/step - loss: 0.8021 - accuracy: 0.8442 - f1: 0.0000e+00 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.3269 - val_accuracy: 0.9097 - val_f1: 0.0000e+00 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 2/40\n",
            "16/16 [==============================] - 33s 2s/step - loss: 0.3115 - accuracy: 0.9193 - f1: 0.0000e+00 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2889 - val_accuracy: 0.9293 - val_f1: 0.0000e+00 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 3/40\n",
            "16/16 [==============================] - 33s 2s/step - loss: 0.2760 - accuracy: 0.9326 - f1: 0.0000e+00 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2652 - val_accuracy: 0.9378 - val_f1: 0.0000e+00 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 4/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.2558 - accuracy: 0.9387 - f1: 0.0000e+00 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0000e+00 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2474 - val_accuracy: 0.9421 - val_f1: 0.0000e+00 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.0000e+00 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0000e+00 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0000e+00 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 5/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.2360 - accuracy: 0.9437 - f1: 2.2921e-04 - f1_1: 0.0000e+00 - f1_2: 0.0000e+00 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0000e+00 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0092 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.0000e+00 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2272 - val_accuracy: 0.9455 - val_f1: 4.4227e-04 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0000e+00 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 6.0606e-04 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0149 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.0022 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 6/40\n",
            "16/16 [==============================] - 34s 2s/step - loss: 0.2150 - accuracy: 0.9475 - f1: 0.0075 - f1_1: 0.0000e+00 - f1_2: 0.0076 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.0896 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.0756 - f1_18: 0.0000e+00 - f1_19: 0.0000e+00 - f1_20: 0.1269 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.2063 - val_accuracy: 0.9510 - val_f1: 0.0189 - val_f1_1: 0.0000e+00 - val_f1_2: 0.0224 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.3733 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.0880 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0000e+00 - val_f1_20: 0.2734 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0000e+00 - val_f1_32: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 7/40\n",
            "16/16 [==============================] - 34s 2s/step - loss: 0.1937 - accuracy: 0.9525 - f1: 0.0345 - f1_1: 0.0000e+00 - f1_2: 0.0850 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.6683 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.2134 - f1_18: 0.0000e+00 - f1_19: 0.0132 - f1_20: 0.3984 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0000e+00 - f1_31: 0.0000e+00 - f1_32: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1858 - val_accuracy: 0.9558 - val_f1: 0.0432 - val_f1_1: 0.0000e+00 - val_f1_2: 0.1201 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0000e+00 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.8502 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.2208 - val_f1_18: 0.0000e+00 - val_f1_19: 0.0541 - val_f1_20: 0.4767 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0000e+00 - val_f1_31: 0.0045 - val_f1_32: 0.0000e+00 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 8/40\n",
            "16/16 [==============================] - 34s 2s/step - loss: 0.1733 - accuracy: 0.9575 - f1: 0.0569 - f1_1: 0.0000e+00 - f1_2: 0.2444 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0000e+00 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.8803 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.3805 - f1_18: 0.0000e+00 - f1_19: 0.1938 - f1_20: 0.5586 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0019 - f1_31: 0.0152 - f1_32: 0.0000e+00 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1672 - val_accuracy: 0.9597 - val_f1: 0.0647 - val_f1_1: 0.0000e+00 - val_f1_2: 0.3353 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.0018 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9070 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.3183 - val_f1_18: 0.0000e+00 - val_f1_19: 0.3739 - val_f1_20: 0.6002 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 9.6200e-04 - val_f1_31: 0.0368 - val_f1_32: 0.0120 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 9/40\n",
            "16/16 [==============================] - 34s 2s/step - loss: 0.1554 - accuracy: 0.9622 - f1: 0.0893 - f1_1: 0.0000e+00 - f1_2: 0.3697 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.0214 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9098 - f1_12: 0.0000e+00 - f1_13: 0.0000e+00 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.4720 - f1_18: 0.0000e+00 - f1_19: 0.4220 - f1_20: 0.6902 - f1_21: 0.0000e+00 - f1_22: 0.0000e+00 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0196 - f1_31: 0.0772 - f1_32: 0.5918 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0000e+00 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1515 - val_accuracy: 0.9636 - val_f1: 0.1023 - val_f1_1: 0.0000e+00 - val_f1_2: 0.3845 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.1143 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9123 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0000e+00 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.4306 - val_f1_18: 0.0000e+00 - val_f1_19: 0.4454 - val_f1_20: 0.7461 - val_f1_21: 0.0000e+00 - val_f1_22: 0.0000e+00 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0000e+00 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0207 - val_f1_31: 0.1186 - val_f1_32: 0.9175 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.0000e+00 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 10/40\n",
            "16/16 [==============================] - 35s 2s/step - loss: 0.1401 - accuracy: 0.9658 - f1: 0.1218 - f1_1: 0.0000e+00 - f1_2: 0.4487 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.2696 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9142 - f1_12: 0.0000e+00 - f1_13: 0.0197 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.5484 - f1_18: 0.0000e+00 - f1_19: 0.5116 - f1_20: 0.7834 - f1_21: 0.0000e+00 - f1_22: 0.1089 - f1_23: 0.0000e+00 - f1_24: 0.0000e+00 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0000e+00 - f1_29: 0.0000e+00 - f1_30: 0.0704 - f1_31: 0.1944 - f1_32: 0.9764 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.0252 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.9663 - val_f1: 0.1304 - val_f1_1: 0.0000e+00 - val_f1_2: 0.4586 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.3498 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9112 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0672 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.4654 - val_f1_18: 0.0000e+00 - val_f1_19: 0.5236 - val_f1_20: 0.8057 - val_f1_21: 0.0000e+00 - val_f1_22: 0.2180 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0087 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.0000e+00 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0646 - val_f1_31: 0.2357 - val_f1_32: 0.9895 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.1173 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 11/40\n",
            "16/16 [==============================] - 36s 2s/step - loss: 0.1269 - accuracy: 0.9692 - f1: 0.1662 - f1_1: 0.0000e+00 - f1_2: 0.5122 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.4858 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9156 - f1_12: 0.0000e+00 - f1_13: 0.0560 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.5954 - f1_18: 0.0000e+00 - f1_19: 0.5730 - f1_20: 0.8305 - f1_21: 0.0000e+00 - f1_22: 0.5907 - f1_23: 0.0000e+00 - f1_24: 0.0332 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.0146 - f1_29: 0.0000e+00 - f1_30: 0.1317 - f1_31: 0.3115 - f1_32: 0.9952 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.6010 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1264 - val_accuracy: 0.9696 - val_f1: 0.1774 - val_f1_1: 0.0000e+00 - val_f1_2: 0.4906 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.5242 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9107 - val_f1_12: 0.0000e+00 - val_f1_13: 0.0880 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.5301 - val_f1_18: 0.0000e+00 - val_f1_19: 0.5724 - val_f1_20: 0.8310 - val_f1_21: 0.0000e+00 - val_f1_22: 0.7327 - val_f1_23: 0.0000e+00 - val_f1_24: 0.0383 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.1659 - val_f1_29: 0.0000e+00 - val_f1_30: 0.0921 - val_f1_31: 0.3753 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0000e+00 - val_f1_41: 0.7514 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 12/40\n",
            "16/16 [==============================] - 35s 2s/step - loss: 0.1157 - accuracy: 0.9723 - f1: 0.2071 - f1_1: 0.0000e+00 - f1_2: 0.5560 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.6348 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9148 - f1_12: 0.0000e+00 - f1_13: 0.1176 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.6544 - f1_18: 0.0000e+00 - f1_19: 0.6370 - f1_20: 0.8484 - f1_21: 0.0000e+00 - f1_22: 0.8029 - f1_23: 0.0000e+00 - f1_24: 0.2704 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.3185 - f1_29: 0.0000e+00 - f1_30: 0.2098 - f1_31: 0.4223 - f1_32: 0.9968 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0000e+00 - f1_41: 0.9000 - f1_44: 0.0000e+00 - f1_45: 0.0000e+00 - val_loss: 0.1165 - val_accuracy: 0.9720 - val_f1: 0.2071 - val_f1_1: 0.0000e+00 - val_f1_2: 0.5503 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.6348 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9131 - val_f1_12: 0.0000e+00 - val_f1_13: 0.1724 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.5653 - val_f1_18: 0.0000e+00 - val_f1_19: 0.6232 - val_f1_20: 0.8445 - val_f1_21: 0.0000e+00 - val_f1_22: 0.7619 - val_f1_23: 0.0000e+00 - val_f1_24: 0.2797 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.4336 - val_f1_29: 0.0000e+00 - val_f1_30: 0.1915 - val_f1_31: 0.4242 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0000e+00 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0014 - val_f1_41: 0.8941 - val_f1_44: 0.0000e+00 - val_f1_45: 0.0000e+00\n",
            "Epoch 13/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.1062 - accuracy: 0.9744 - f1: 0.2292 - f1_1: 0.0027 - f1_2: 0.5851 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.6673 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9181 - f1_12: 0.0000e+00 - f1_13: 0.3285 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.6829 - f1_18: 0.0000e+00 - f1_19: 0.6819 - f1_20: 0.8587 - f1_21: 0.0000e+00 - f1_22: 0.8186 - f1_23: 0.0000e+00 - f1_24: 0.4212 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.4890 - f1_29: 0.0000e+00 - f1_30: 0.2792 - f1_31: 0.4943 - f1_32: 0.9969 - f1_34: 0.0000e+00 - f1_35: 0.0000e+00 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0074 - f1_41: 0.9360 - f1_44: 0.0017 - f1_45: 0.0000e+00 - val_loss: 0.1083 - val_accuracy: 0.9738 - val_f1: 0.2345 - val_f1_1: 0.0202 - val_f1_2: 0.5823 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.6913 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9177 - val_f1_12: 0.0000e+00 - val_f1_13: 0.4893 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.6048 - val_f1_18: 0.0000e+00 - val_f1_19: 0.6784 - val_f1_20: 0.8523 - val_f1_21: 0.0000e+00 - val_f1_22: 0.7936 - val_f1_23: 0.0000e+00 - val_f1_24: 0.4824 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.5418 - val_f1_29: 0.0000e+00 - val_f1_30: 0.2146 - val_f1_31: 0.4690 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.0649 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0241 - val_f1_41: 0.9417 - val_f1_44: 0.0175 - val_f1_45: 0.0000e+00\n",
            "Epoch 14/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0981 - accuracy: 0.9762 - f1: 0.2610 - f1_1: 0.0758 - f1_2: 0.6227 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.7127 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9228 - f1_12: 0.0000e+00 - f1_13: 0.5252 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.7027 - f1_18: 0.0000e+00 - f1_19: 0.7239 - f1_20: 0.8698 - f1_21: 0.0000e+00 - f1_22: 0.8461 - f1_23: 0.0000e+00 - f1_24: 0.5535 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.5744 - f1_29: 0.0000e+00 - f1_30: 0.3462 - f1_31: 0.5722 - f1_32: 0.9968 - f1_34: 0.0000e+00 - f1_35: 0.2465 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.0341 - f1_41: 0.9610 - f1_44: 0.0277 - f1_45: 0.1253 - val_loss: 0.1009 - val_accuracy: 0.9754 - val_f1: 0.2662 - val_f1_1: 0.1035 - val_f1_2: 0.6239 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.7235 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9257 - val_f1_12: 0.0000e+00 - val_f1_13: 0.5599 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.6182 - val_f1_18: 0.0000e+00 - val_f1_19: 0.7083 - val_f1_20: 0.8715 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8104 - val_f1_23: 0.0000e+00 - val_f1_24: 0.5351 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.6579 - val_f1_29: 0.0000e+00 - val_f1_30: 0.3122 - val_f1_31: 0.5152 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.3076 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0421 - val_f1_41: 0.9543 - val_f1_44: 0.0453 - val_f1_45: 0.3378\n",
            "Epoch 15/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0911 - accuracy: 0.9776 - f1: 0.3004 - f1_1: 0.2325 - f1_2: 0.6540 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.7479 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9286 - f1_12: 0.0000e+00 - f1_13: 0.6124 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.7276 - f1_18: 0.0000e+00 - f1_19: 0.7576 - f1_20: 0.8810 - f1_21: 0.0000e+00 - f1_22: 0.8563 - f1_23: 0.0000e+00 - f1_24: 0.6053 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.6673 - f1_29: 0.0000e+00 - f1_30: 0.4088 - f1_31: 0.6110 - f1_32: 0.9968 - f1_34: 0.0000e+00 - f1_35: 0.4837 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.1023 - f1_41: 0.9822 - f1_44: 0.0835 - f1_45: 0.6765 - val_loss: 0.0950 - val_accuracy: 0.9766 - val_f1: 0.3037 - val_f1_1: 0.3879 - val_f1_2: 0.6618 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.7244 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9331 - val_f1_12: 0.0000e+00 - val_f1_13: 0.6719 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.6221 - val_f1_18: 0.0000e+00 - val_f1_19: 0.7188 - val_f1_20: 0.8748 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8241 - val_f1_23: 0.0000e+00 - val_f1_24: 0.5701 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.7269 - val_f1_29: 0.0000e+00 - val_f1_30: 0.3294 - val_f1_31: 0.5660 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.4292 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.0904 - val_f1_41: 0.9728 - val_f1_44: 0.1798 - val_f1_45: 0.8683\n",
            "Epoch 16/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0852 - accuracy: 0.9788 - f1: 0.3272 - f1_1: 0.3976 - f1_2: 0.6819 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.7564 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9305 - f1_12: 0.0132 - f1_13: 0.7241 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.7422 - f1_18: 0.0000e+00 - f1_19: 0.7765 - f1_20: 0.8890 - f1_21: 0.0000e+00 - f1_22: 0.8615 - f1_23: 0.0000e+00 - f1_24: 0.6326 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.7280 - f1_29: 0.0000e+00 - f1_30: 0.4476 - f1_31: 0.6542 - f1_32: 0.9968 - f1_34: 0.0000e+00 - f1_35: 0.5634 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.1483 - f1_41: 0.9885 - f1_44: 0.2543 - f1_45: 0.9003 - val_loss: 0.0902 - val_accuracy: 0.9777 - val_f1: 0.3217 - val_f1_1: 0.4896 - val_f1_2: 0.6363 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.7488 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9353 - val_f1_12: 0.0203 - val_f1_13: 0.7396 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.6507 - val_f1_18: 0.0000e+00 - val_f1_19: 0.7322 - val_f1_20: 0.8909 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8385 - val_f1_23: 0.0000e+00 - val_f1_24: 0.5964 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.7478 - val_f1_29: 0.0000e+00 - val_f1_30: 0.3996 - val_f1_31: 0.6290 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.4911 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.1353 - val_f1_41: 0.9846 - val_f1_44: 0.3076 - val_f1_45: 0.8990\n",
            "Epoch 17/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0801 - accuracy: 0.9800 - f1: 0.3427 - f1_1: 0.4367 - f1_2: 0.7025 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0000e+00 - f1_6: 0.7833 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9336 - f1_12: 0.1093 - f1_13: 0.7516 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.7527 - f1_18: 0.0000e+00 - f1_19: 0.7901 - f1_20: 0.8996 - f1_21: 0.0000e+00 - f1_22: 0.8716 - f1_23: 0.0000e+00 - f1_24: 0.6669 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.7546 - f1_29: 0.0000e+00 - f1_30: 0.4749 - f1_31: 0.6828 - f1_32: 0.9967 - f1_34: 0.0000e+00 - f1_35: 0.6300 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.1952 - f1_41: 0.9925 - f1_44: 0.3627 - f1_45: 0.9199 - val_loss: 0.0852 - val_accuracy: 0.9785 - val_f1: 0.3379 - val_f1_1: 0.5494 - val_f1_2: 0.6809 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0000e+00 - val_f1_6: 0.7754 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9373 - val_f1_12: 0.2243 - val_f1_13: 0.7887 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.6824 - val_f1_18: 0.0000e+00 - val_f1_19: 0.7659 - val_f1_20: 0.8999 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8498 - val_f1_23: 0.0000e+00 - val_f1_24: 0.6329 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.7924 - val_f1_29: 0.0000e+00 - val_f1_30: 0.3977 - val_f1_31: 0.6106 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.5310 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.1431 - val_f1_41: 0.9846 - val_f1_44: 0.3594 - val_f1_45: 0.9168\n",
            "Epoch 18/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0757 - accuracy: 0.9810 - f1: 0.3627 - f1_1: 0.5514 - f1_2: 0.7179 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0122 - f1_6: 0.7926 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9371 - f1_12: 0.4646 - f1_13: 0.7982 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.7667 - f1_18: 0.0000e+00 - f1_19: 0.8183 - f1_20: 0.9055 - f1_21: 0.0000e+00 - f1_22: 0.8824 - f1_23: 0.0000e+00 - f1_24: 0.6951 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.8003 - f1_29: 0.0000e+00 - f1_30: 0.5087 - f1_31: 0.6989 - f1_32: 0.9966 - f1_34: 0.0000e+00 - f1_35: 0.5958 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.2182 - f1_41: 0.9921 - f1_44: 0.4337 - f1_45: 0.9231 - val_loss: 0.0815 - val_accuracy: 0.9794 - val_f1: 0.3566 - val_f1_1: 0.5751 - val_f1_2: 0.6732 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0025 - val_f1_6: 0.7902 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9384 - val_f1_12: 0.5604 - val_f1_13: 0.7823 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.6972 - val_f1_18: 0.0000e+00 - val_f1_19: 0.7731 - val_f1_20: 0.9113 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8545 - val_f1_23: 0.0000e+00 - val_f1_24: 0.6557 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.8039 - val_f1_29: 0.0000e+00 - val_f1_30: 0.4405 - val_f1_31: 0.6752 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.5392 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.2503 - val_f1_41: 0.9846 - val_f1_44: 0.4417 - val_f1_45: 0.9187\n",
            "Epoch 19/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0720 - accuracy: 0.9817 - f1: 0.3763 - f1_1: 0.5699 - f1_2: 0.7293 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0239 - f1_6: 0.8084 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9369 - f1_12: 0.6139 - f1_13: 0.8239 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.7721 - f1_18: 0.0000e+00 - f1_19: 0.8223 - f1_20: 0.9093 - f1_21: 0.0000e+00 - f1_22: 0.8822 - f1_23: 0.0000e+00 - f1_24: 0.7221 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.8054 - f1_29: 0.0000e+00 - f1_30: 0.5411 - f1_31: 0.7261 - f1_32: 0.9960 - f1_34: 0.0000e+00 - f1_35: 0.6516 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.3044 - f1_41: 0.9934 - f1_44: 0.4887 - f1_45: 0.9319 - val_loss: 0.0785 - val_accuracy: 0.9798 - val_f1: 0.3659 - val_f1_1: 0.5756 - val_f1_2: 0.6859 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0373 - val_f1_6: 0.8066 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9400 - val_f1_12: 0.6266 - val_f1_13: 0.8510 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7239 - val_f1_18: 0.0000e+00 - val_f1_19: 0.7802 - val_f1_20: 0.9112 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8591 - val_f1_23: 0.0000e+00 - val_f1_24: 0.6985 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.8190 - val_f1_29: 0.0000e+00 - val_f1_30: 0.4441 - val_f1_31: 0.6735 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.5583 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.3089 - val_f1_41: 0.9846 - val_f1_44: 0.4423 - val_f1_45: 0.9167\n",
            "Epoch 20/40\n",
            "16/16 [==============================] - 31s 2s/step - loss: 0.0684 - accuracy: 0.9827 - f1: 0.3884 - f1_1: 0.5990 - f1_2: 0.7431 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.0617 - f1_6: 0.8281 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9409 - f1_12: 0.7257 - f1_13: 0.8586 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.7793 - f1_18: 0.0000e+00 - f1_19: 0.8333 - f1_20: 0.9166 - f1_21: 0.0000e+00 - f1_22: 0.8821 - f1_23: 0.0000e+00 - f1_24: 0.7348 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.8369 - f1_29: 0.0000e+00 - f1_30: 0.5545 - f1_31: 0.7434 - f1_32: 0.9967 - f1_34: 0.0000e+00 - f1_35: 0.6835 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.3579 - f1_41: 0.9910 - f1_44: 0.5305 - f1_45: 0.9376 - val_loss: 0.0748 - val_accuracy: 0.9809 - val_f1: 0.3788 - val_f1_1: 0.6454 - val_f1_2: 0.7362 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.0738 - val_f1_6: 0.8063 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9411 - val_f1_12: 0.7473 - val_f1_13: 0.8695 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7038 - val_f1_18: 0.0000e+00 - val_f1_19: 0.7998 - val_f1_20: 0.9148 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8651 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7164 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.8349 - val_f1_29: 0.0000e+00 - val_f1_30: 0.4737 - val_f1_31: 0.6945 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.6249 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.3382 - val_f1_41: 0.9846 - val_f1_44: 0.4694 - val_f1_45: 0.9167\n",
            "Epoch 21/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0653 - accuracy: 0.9835 - f1: 0.4007 - f1_1: 0.6508 - f1_2: 0.7517 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.1141 - f1_6: 0.8345 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9418 - f1_12: 0.8349 - f1_13: 0.8673 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.7879 - f1_18: 0.0000e+00 - f1_19: 0.8594 - f1_20: 0.9223 - f1_21: 0.0000e+00 - f1_22: 0.8850 - f1_23: 0.0000e+00 - f1_24: 0.7664 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.8481 - f1_29: 0.0000e+00 - f1_30: 0.5789 - f1_31: 0.7627 - f1_32: 0.9967 - f1_34: 0.0000e+00 - f1_35: 0.7412 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.3919 - f1_41: 0.9938 - f1_44: 0.5619 - f1_45: 0.9365 - val_loss: 0.0722 - val_accuracy: 0.9816 - val_f1: 0.3855 - val_f1_1: 0.6352 - val_f1_2: 0.7527 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.1089 - val_f1_6: 0.8117 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9416 - val_f1_12: 0.7530 - val_f1_13: 0.8845 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.6945 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8043 - val_f1_20: 0.9213 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8688 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7239 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0000e+00 - val_f1_27: 0.8471 - val_f1_29: 0.0000e+00 - val_f1_30: 0.5565 - val_f1_31: 0.6700 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.6544 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.3646 - val_f1_41: 0.9846 - val_f1_44: 0.5278 - val_f1_45: 0.9190\n",
            "Epoch 22/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0628 - accuracy: 0.9842 - f1: 0.4088 - f1_1: 0.6630 - f1_2: 0.7635 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.1949 - f1_6: 0.8399 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9412 - f1_12: 0.8718 - f1_13: 0.8756 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.7950 - f1_18: 0.0000e+00 - f1_19: 0.8670 - f1_20: 0.9275 - f1_21: 0.0000e+00 - f1_22: 0.8844 - f1_23: 0.0000e+00 - f1_24: 0.7783 - f1_25: 0.0000e+00 - f1_26: 0.0000e+00 - f1_27: 0.8705 - f1_29: 0.0000e+00 - f1_30: 0.6051 - f1_31: 0.7681 - f1_32: 0.9968 - f1_34: 0.0000e+00 - f1_35: 0.7863 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.4170 - f1_41: 0.9943 - f1_44: 0.5827 - f1_45: 0.9309 - val_loss: 0.0703 - val_accuracy: 0.9820 - val_f1: 0.3983 - val_f1_1: 0.6711 - val_f1_2: 0.7399 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.1854 - val_f1_6: 0.8146 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9427 - val_f1_12: 0.8439 - val_f1_13: 0.9057 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.6719 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8175 - val_f1_20: 0.9230 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8708 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7300 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0455 - val_f1_27: 0.8676 - val_f1_29: 0.0000e+00 - val_f1_30: 0.5717 - val_f1_31: 0.7515 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7113 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.4379 - val_f1_41: 0.9846 - val_f1_44: 0.5278 - val_f1_45: 0.9230\n",
            "Epoch 23/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0602 - accuracy: 0.9848 - f1: 0.4168 - f1_1: 0.6983 - f1_2: 0.7801 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.2328 - f1_6: 0.8523 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9451 - f1_12: 0.8958 - f1_13: 0.8914 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.7987 - f1_18: 0.0000e+00 - f1_19: 0.8632 - f1_20: 0.9263 - f1_21: 0.0000e+00 - f1_22: 0.8829 - f1_23: 0.0000e+00 - f1_24: 0.7843 - f1_25: 0.0000e+00 - f1_26: 0.0317 - f1_27: 0.8779 - f1_29: 0.0000e+00 - f1_30: 0.6229 - f1_31: 0.7852 - f1_32: 0.9968 - f1_34: 0.0000e+00 - f1_35: 0.8118 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.4708 - f1_41: 0.9930 - f1_44: 0.5957 - f1_45: 0.9347 - val_loss: 0.0677 - val_accuracy: 0.9827 - val_f1: 0.4067 - val_f1_1: 0.6769 - val_f1_2: 0.7445 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.2130 - val_f1_6: 0.8204 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9436 - val_f1_12: 0.8785 - val_f1_13: 0.9085 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7163 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8216 - val_f1_20: 0.9267 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8708 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7570 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0974 - val_f1_27: 0.8917 - val_f1_29: 0.0000e+00 - val_f1_30: 0.5322 - val_f1_31: 0.7540 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.7901 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.4635 - val_f1_41: 0.9846 - val_f1_44: 0.5603 - val_f1_45: 0.9230\n",
            "Epoch 24/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0579 - accuracy: 0.9854 - f1: 0.4266 - f1_1: 0.7213 - f1_2: 0.7827 - f1_3: 0.0000e+00 - f1_4: 0.0000e+00 - f1_5: 0.2697 - f1_6: 0.8580 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9450 - f1_12: 0.9028 - f1_13: 0.9232 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.8079 - f1_18: 0.0000e+00 - f1_19: 0.8776 - f1_20: 0.9305 - f1_21: 0.0000e+00 - f1_22: 0.8865 - f1_23: 0.0000e+00 - f1_24: 0.8000 - f1_25: 0.0000e+00 - f1_26: 0.1204 - f1_27: 0.8845 - f1_29: 0.0000e+00 - f1_30: 0.6430 - f1_31: 0.8010 - f1_32: 0.9958 - f1_34: 0.0000e+00 - f1_35: 0.8679 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.5087 - f1_41: 0.9931 - f1_44: 0.6234 - f1_45: 0.9229 - val_loss: 0.0659 - val_accuracy: 0.9827 - val_f1: 0.4101 - val_f1_1: 0.6574 - val_f1_2: 0.7765 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0000e+00 - val_f1_5: 0.2643 - val_f1_6: 0.8263 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9450 - val_f1_12: 0.8869 - val_f1_13: 0.9339 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7208 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8228 - val_f1_20: 0.9288 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8708 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7393 - val_f1_25: 0.0000e+00 - val_f1_26: 0.0974 - val_f1_27: 0.8922 - val_f1_29: 0.0000e+00 - val_f1_30: 0.5202 - val_f1_31: 0.7351 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8161 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.5149 - val_f1_41: 0.9846 - val_f1_44: 0.5524 - val_f1_45: 0.9230\n",
            "Epoch 25/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0560 - accuracy: 0.9857 - f1: 0.4381 - f1_1: 0.7102 - f1_2: 0.7883 - f1_3: 0.0000e+00 - f1_4: 0.1020 - f1_5: 0.3379 - f1_6: 0.8698 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9496 - f1_12: 0.9281 - f1_13: 0.9320 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.8115 - f1_18: 0.0000e+00 - f1_19: 0.8824 - f1_20: 0.9344 - f1_21: 0.0000e+00 - f1_22: 0.9030 - f1_23: 0.0000e+00 - f1_24: 0.8125 - f1_25: 0.0000e+00 - f1_26: 0.2113 - f1_27: 0.8983 - f1_29: 0.0000e+00 - f1_30: 0.6407 - f1_31: 0.8063 - f1_32: 0.9968 - f1_34: 0.0000e+00 - f1_35: 0.8915 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.5455 - f1_41: 0.9938 - f1_44: 0.6452 - f1_45: 0.9310 - val_loss: 0.0642 - val_accuracy: 0.9833 - val_f1: 0.4178 - val_f1_1: 0.6657 - val_f1_2: 0.7677 - val_f1_3: 0.0000e+00 - val_f1_4: 0.0289 - val_f1_5: 0.2950 - val_f1_6: 0.8299 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9465 - val_f1_12: 0.8970 - val_f1_13: 0.9325 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7173 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8397 - val_f1_20: 0.9341 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8756 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7549 - val_f1_25: 0.0000e+00 - val_f1_26: 0.1176 - val_f1_27: 0.8815 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6154 - val_f1_31: 0.7450 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8152 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.5709 - val_f1_41: 0.9846 - val_f1_44: 0.5631 - val_f1_45: 0.9375\n",
            "Epoch 26/40\n",
            "16/16 [==============================] - 33s 2s/step - loss: 0.0542 - accuracy: 0.9860 - f1: 0.4483 - f1_1: 0.7295 - f1_2: 0.7938 - f1_3: 0.0000e+00 - f1_4: 0.2343 - f1_5: 0.3698 - f1_6: 0.8731 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9505 - f1_12: 0.9390 - f1_13: 0.9369 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.8183 - f1_18: 0.0000e+00 - f1_19: 0.8846 - f1_20: 0.9365 - f1_21: 0.0000e+00 - f1_22: 0.9106 - f1_23: 0.0000e+00 - f1_24: 0.8195 - f1_25: 0.0000e+00 - f1_26: 0.3376 - f1_27: 0.8993 - f1_29: 0.0000e+00 - f1_30: 0.6546 - f1_31: 0.8120 - f1_32: 0.9971 - f1_34: 0.0000e+00 - f1_35: 0.8887 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.5781 - f1_41: 0.9949 - f1_44: 0.6416 - f1_45: 0.9328 - val_loss: 0.0623 - val_accuracy: 0.9837 - val_f1: 0.4289 - val_f1_1: 0.6869 - val_f1_2: 0.7768 - val_f1_3: 0.0000e+00 - val_f1_4: 0.1779 - val_f1_5: 0.3089 - val_f1_6: 0.8390 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9466 - val_f1_12: 0.9045 - val_f1_13: 0.9410 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7384 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8348 - val_f1_20: 0.9376 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8887 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7694 - val_f1_25: 0.0000e+00 - val_f1_26: 0.2288 - val_f1_27: 0.8959 - val_f1_29: 0.0000e+00 - val_f1_30: 0.5671 - val_f1_31: 0.7769 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8724 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.5657 - val_f1_41: 0.9846 - val_f1_44: 0.5821 - val_f1_45: 0.9375\n",
            "Epoch 27/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0526 - accuracy: 0.9864 - f1: 0.4638 - f1_1: 0.7435 - f1_2: 0.7972 - f1_3: 0.0000e+00 - f1_4: 0.6015 - f1_5: 0.4406 - f1_6: 0.8758 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9535 - f1_12: 0.9452 - f1_13: 0.9427 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0000e+00 - f1_17: 0.8194 - f1_18: 0.0000e+00 - f1_19: 0.8865 - f1_20: 0.9374 - f1_21: 0.0000e+00 - f1_22: 0.9232 - f1_23: 0.0000e+00 - f1_24: 0.8259 - f1_25: 0.0000e+00 - f1_26: 0.3574 - f1_27: 0.9085 - f1_29: 0.0000e+00 - f1_30: 0.6712 - f1_31: 0.8231 - f1_32: 0.9969 - f1_34: 0.0000e+00 - f1_35: 0.9183 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.6048 - f1_41: 0.9946 - f1_44: 0.6487 - f1_45: 0.9378 - val_loss: 0.0609 - val_accuracy: 0.9841 - val_f1: 0.4454 - val_f1_1: 0.6972 - val_f1_2: 0.7714 - val_f1_3: 0.0000e+00 - val_f1_4: 0.5759 - val_f1_5: 0.3669 - val_f1_6: 0.8399 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9520 - val_f1_12: 0.9096 - val_f1_13: 0.9434 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0000e+00 - val_f1_17: 0.7497 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8435 - val_f1_20: 0.9378 - val_f1_21: 0.0000e+00 - val_f1_22: 0.8996 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7745 - val_f1_25: 0.0000e+00 - val_f1_26: 0.3123 - val_f1_27: 0.9054 - val_f1_29: 0.0000e+00 - val_f1_30: 0.5750 - val_f1_31: 0.7672 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8941 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.5694 - val_f1_41: 0.9846 - val_f1_44: 0.6145 - val_f1_45: 0.9375\n",
            "Epoch 28/40\n",
            "16/16 [==============================] - 37s 2s/step - loss: 0.0510 - accuracy: 0.9867 - f1: 0.4730 - f1_1: 0.7501 - f1_2: 0.8017 - f1_3: 0.0000e+00 - f1_4: 0.7257 - f1_5: 0.4412 - f1_6: 0.8849 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9569 - f1_12: 0.9546 - f1_13: 0.9433 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.0621 - f1_17: 0.8254 - f1_18: 0.0000e+00 - f1_19: 0.8954 - f1_20: 0.9401 - f1_21: 0.0000e+00 - f1_22: 0.9236 - f1_23: 0.0000e+00 - f1_24: 0.8385 - f1_25: 0.0000e+00 - f1_26: 0.4254 - f1_27: 0.9102 - f1_29: 0.0000e+00 - f1_30: 0.6763 - f1_31: 0.8338 - f1_32: 0.9949 - f1_34: 0.0000e+00 - f1_35: 0.9337 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.6011 - f1_41: 0.9951 - f1_44: 0.6665 - f1_45: 0.9398 - val_loss: 0.0597 - val_accuracy: 0.9841 - val_f1: 0.4557 - val_f1_1: 0.7146 - val_f1_2: 0.7809 - val_f1_3: 0.0000e+00 - val_f1_4: 0.5883 - val_f1_5: 0.4227 - val_f1_6: 0.8451 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9560 - val_f1_12: 0.9234 - val_f1_13: 0.9466 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.0974 - val_f1_17: 0.7295 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8419 - val_f1_20: 0.9388 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9028 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7720 - val_f1_25: 0.0000e+00 - val_f1_26: 0.4481 - val_f1_27: 0.9033 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6167 - val_f1_31: 0.7774 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.8912 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.5924 - val_f1_41: 0.9846 - val_f1_44: 0.6201 - val_f1_45: 0.9392\n",
            "Epoch 29/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0495 - accuracy: 0.9870 - f1: 0.4823 - f1_1: 0.7536 - f1_2: 0.8119 - f1_3: 0.0000e+00 - f1_4: 0.7175 - f1_5: 0.4839 - f1_6: 0.8823 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9597 - f1_12: 0.9517 - f1_13: 0.9574 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.1741 - f1_17: 0.8292 - f1_18: 0.0000e+00 - f1_19: 0.8962 - f1_20: 0.9418 - f1_21: 0.0000e+00 - f1_22: 0.9241 - f1_23: 0.0000e+00 - f1_24: 0.8446 - f1_25: 0.0000e+00 - f1_26: 0.5452 - f1_27: 0.9142 - f1_29: 0.0000e+00 - f1_30: 0.6842 - f1_31: 0.8385 - f1_32: 0.9967 - f1_34: 0.0000e+00 - f1_35: 0.9338 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.6276 - f1_41: 0.9946 - f1_44: 0.6847 - f1_45: 0.9440 - val_loss: 0.0583 - val_accuracy: 0.9845 - val_f1: 0.4640 - val_f1_1: 0.7386 - val_f1_2: 0.7911 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6210 - val_f1_5: 0.4141 - val_f1_6: 0.8469 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9540 - val_f1_12: 0.9360 - val_f1_13: 0.9522 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.2609 - val_f1_17: 0.7484 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8460 - val_f1_20: 0.9374 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9048 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7742 - val_f1_25: 0.0000e+00 - val_f1_26: 0.4529 - val_f1_27: 0.9107 - val_f1_29: 0.0000e+00 - val_f1_30: 0.5971 - val_f1_31: 0.7838 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9094 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6439 - val_f1_41: 0.9846 - val_f1_44: 0.6162 - val_f1_45: 0.9401\n",
            "Epoch 30/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0480 - accuracy: 0.9874 - f1: 0.4916 - f1_1: 0.7698 - f1_2: 0.8196 - f1_3: 0.0000e+00 - f1_4: 0.7811 - f1_5: 0.4965 - f1_6: 0.8949 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9616 - f1_12: 0.9579 - f1_13: 0.9508 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.3125 - f1_17: 0.8343 - f1_18: 0.0000e+00 - f1_19: 0.8988 - f1_20: 0.9419 - f1_21: 0.0000e+00 - f1_22: 0.9322 - f1_23: 0.0000e+00 - f1_24: 0.8523 - f1_25: 0.0000e+00 - f1_26: 0.5759 - f1_27: 0.9178 - f1_29: 0.0000e+00 - f1_30: 0.6982 - f1_31: 0.8422 - f1_32: 0.9968 - f1_34: 0.0000e+00 - f1_35: 0.9440 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.6504 - f1_41: 0.9938 - f1_44: 0.6879 - f1_45: 0.9527 - val_loss: 0.0571 - val_accuracy: 0.9848 - val_f1: 0.4724 - val_f1_1: 0.7389 - val_f1_2: 0.7836 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6252 - val_f1_5: 0.4305 - val_f1_6: 0.8517 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9571 - val_f1_12: 0.9360 - val_f1_13: 0.9606 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.4192 - val_f1_17: 0.7571 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8540 - val_f1_20: 0.9398 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9063 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7723 - val_f1_25: 0.0000e+00 - val_f1_26: 0.4949 - val_f1_27: 0.9087 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6329 - val_f1_31: 0.7991 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9226 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6507 - val_f1_41: 0.9846 - val_f1_44: 0.6282 - val_f1_45: 0.9463\n",
            "Epoch 31/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0467 - accuracy: 0.9877 - f1: 0.4977 - f1_1: 0.8002 - f1_2: 0.8202 - f1_3: 0.0000e+00 - f1_4: 0.7727 - f1_5: 0.5253 - f1_6: 0.8992 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9625 - f1_12: 0.9613 - f1_13: 0.9684 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.4369 - f1_17: 0.8360 - f1_18: 0.0000e+00 - f1_19: 0.8990 - f1_20: 0.9433 - f1_21: 0.0000e+00 - f1_22: 0.9361 - f1_23: 0.0000e+00 - f1_24: 0.8499 - f1_25: 0.0000e+00 - f1_26: 0.5832 - f1_27: 0.9226 - f1_29: 0.0000e+00 - f1_30: 0.7040 - f1_31: 0.8420 - f1_32: 0.9967 - f1_34: 0.0000e+00 - f1_35: 0.9484 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.6659 - f1_41: 0.9948 - f1_44: 0.6852 - f1_45: 0.9548 - val_loss: 0.0565 - val_accuracy: 0.9849 - val_f1: 0.4751 - val_f1_1: 0.7369 - val_f1_2: 0.7802 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6326 - val_f1_5: 0.4521 - val_f1_6: 0.8516 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9597 - val_f1_12: 0.9377 - val_f1_13: 0.9656 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.4284 - val_f1_17: 0.7349 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8552 - val_f1_20: 0.9426 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9223 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7845 - val_f1_25: 0.0000e+00 - val_f1_26: 0.4949 - val_f1_27: 0.9176 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6631 - val_f1_31: 0.8037 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9226 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6541 - val_f1_41: 0.9846 - val_f1_44: 0.6289 - val_f1_45: 0.9543\n",
            "Epoch 32/40\n",
            "16/16 [==============================] - 33s 2s/step - loss: 0.0457 - accuracy: 0.9880 - f1: 0.5004 - f1_1: 0.8075 - f1_2: 0.8242 - f1_3: 0.0000e+00 - f1_4: 0.7217 - f1_5: 0.5326 - f1_6: 0.9026 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9635 - f1_12: 0.9680 - f1_13: 0.9664 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.4815 - f1_17: 0.8301 - f1_18: 0.0000e+00 - f1_19: 0.9058 - f1_20: 0.9449 - f1_21: 0.0000e+00 - f1_22: 0.9382 - f1_23: 0.0000e+00 - f1_24: 0.8564 - f1_25: 0.0000e+00 - f1_26: 0.6145 - f1_27: 0.9248 - f1_29: 0.0000e+00 - f1_30: 0.7139 - f1_31: 0.8520 - f1_32: 0.9966 - f1_34: 0.0000e+00 - f1_35: 0.9567 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.6665 - f1_41: 0.9912 - f1_44: 0.7021 - f1_45: 0.9550 - val_loss: 0.0552 - val_accuracy: 0.9850 - val_f1: 0.4770 - val_f1_1: 0.7393 - val_f1_2: 0.7939 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6477 - val_f1_5: 0.4473 - val_f1_6: 0.8618 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9609 - val_f1_12: 0.9389 - val_f1_13: 0.9649 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.4284 - val_f1_17: 0.7546 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8532 - val_f1_20: 0.9414 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9242 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7779 - val_f1_25: 0.0000e+00 - val_f1_26: 0.5065 - val_f1_27: 0.9167 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6452 - val_f1_31: 0.8019 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9241 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6781 - val_f1_41: 0.9846 - val_f1_44: 0.6377 - val_f1_45: 0.9568\n",
            "Epoch 33/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0444 - accuracy: 0.9882 - f1: 0.5024 - f1_1: 0.8092 - f1_2: 0.8296 - f1_3: 0.0000e+00 - f1_4: 0.7444 - f1_5: 0.5624 - f1_6: 0.9030 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9644 - f1_12: 0.9657 - f1_13: 0.9682 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.4732 - f1_17: 0.8410 - f1_18: 0.0000e+00 - f1_19: 0.9051 - f1_20: 0.9464 - f1_21: 0.0000e+00 - f1_22: 0.9404 - f1_23: 0.0000e+00 - f1_24: 0.8642 - f1_25: 0.0000e+00 - f1_26: 0.5883 - f1_27: 0.9248 - f1_29: 0.0000e+00 - f1_30: 0.7204 - f1_31: 0.8566 - f1_32: 0.9967 - f1_34: 0.0000e+00 - f1_35: 0.9477 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.6840 - f1_41: 0.9942 - f1_44: 0.7083 - f1_45: 0.9569 - val_loss: 0.0544 - val_accuracy: 0.9851 - val_f1: 0.4806 - val_f1_1: 0.7545 - val_f1_2: 0.7858 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6477 - val_f1_5: 0.4855 - val_f1_6: 0.8590 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9622 - val_f1_12: 0.9406 - val_f1_13: 0.9673 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.4768 - val_f1_17: 0.7720 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8558 - val_f1_20: 0.9448 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9117 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7931 - val_f1_25: 0.0000e+00 - val_f1_26: 0.5566 - val_f1_27: 0.9214 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6031 - val_f1_31: 0.8027 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9348 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6575 - val_f1_41: 0.9846 - val_f1_44: 0.6484 - val_f1_45: 0.9635\n",
            "Epoch 34/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0434 - accuracy: 0.9884 - f1: 0.5073 - f1_1: 0.8075 - f1_2: 0.8298 - f1_3: 0.0000e+00 - f1_4: 0.7273 - f1_5: 0.5635 - f1_6: 0.9012 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9653 - f1_12: 0.9734 - f1_13: 0.9707 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.5545 - f1_17: 0.8457 - f1_18: 0.0000e+00 - f1_19: 0.9061 - f1_20: 0.9496 - f1_21: 0.0000e+00 - f1_22: 0.9399 - f1_23: 0.0000e+00 - f1_24: 0.8660 - f1_25: 0.0000e+00 - f1_26: 0.6395 - f1_27: 0.9319 - f1_29: 0.0000e+00 - f1_30: 0.7241 - f1_31: 0.8594 - f1_32: 0.9968 - f1_34: 0.0000e+00 - f1_35: 0.9523 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.6950 - f1_41: 0.9934 - f1_44: 0.7229 - f1_45: 0.9769 - val_loss: 0.0538 - val_accuracy: 0.9852 - val_f1: 0.4833 - val_f1_1: 0.7612 - val_f1_2: 0.8020 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6477 - val_f1_5: 0.4910 - val_f1_6: 0.8572 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9629 - val_f1_12: 0.9423 - val_f1_13: 0.9726 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.5121 - val_f1_17: 0.7378 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8633 - val_f1_20: 0.9454 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9246 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7893 - val_f1_25: 0.0000e+00 - val_f1_26: 0.5040 - val_f1_27: 0.9257 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6520 - val_f1_31: 0.8072 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9388 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6904 - val_f1_41: 0.9846 - val_f1_44: 0.6555 - val_f1_45: 0.9683\n",
            "Epoch 35/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0423 - accuracy: 0.9887 - f1: 0.5137 - f1_1: 0.8176 - f1_2: 0.8376 - f1_3: 0.0000e+00 - f1_4: 0.7978 - f1_5: 0.5905 - f1_6: 0.9065 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9654 - f1_12: 0.9693 - f1_13: 0.9687 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.5759 - f1_17: 0.8471 - f1_18: 0.0000e+00 - f1_19: 0.9091 - f1_20: 0.9484 - f1_21: 0.0000e+00 - f1_22: 0.9777 - f1_23: 0.0000e+00 - f1_24: 0.8744 - f1_25: 0.0000e+00 - f1_26: 0.6730 - f1_27: 0.9370 - f1_29: 0.0000e+00 - f1_30: 0.7344 - f1_31: 0.8652 - f1_32: 0.9969 - f1_34: 0.0000e+00 - f1_35: 0.9631 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.7028 - f1_41: 0.9949 - f1_44: 0.7162 - f1_45: 0.9783 - val_loss: 0.0528 - val_accuracy: 0.9855 - val_f1: 0.4881 - val_f1_1: 0.7607 - val_f1_2: 0.7962 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6477 - val_f1_5: 0.5171 - val_f1_6: 0.8645 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9636 - val_f1_12: 0.9457 - val_f1_13: 0.9668 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.5449 - val_f1_17: 0.7579 - val_f1_18: 0.0000e+00 - val_f1_19: 0.8642 - val_f1_20: 0.9446 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9697 - val_f1_23: 0.0000e+00 - val_f1_24: 0.7955 - val_f1_25: 0.0000e+00 - val_f1_26: 0.5562 - val_f1_27: 0.9241 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6690 - val_f1_31: 0.8058 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9445 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6842 - val_f1_41: 0.9846 - val_f1_44: 0.6561 - val_f1_45: 0.9665\n",
            "Epoch 36/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0413 - accuracy: 0.9889 - f1: 0.5159 - f1_1: 0.8202 - f1_2: 0.8386 - f1_3: 0.0000e+00 - f1_4: 0.7831 - f1_5: 0.5857 - f1_6: 0.9101 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9689 - f1_12: 0.9669 - f1_13: 0.9683 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.6235 - f1_17: 0.8487 - f1_18: 0.0000e+00 - f1_19: 0.9094 - f1_20: 0.9493 - f1_21: 0.0000e+00 - f1_22: 0.9805 - f1_23: 0.0000e+00 - f1_24: 0.8747 - f1_25: 0.0000e+00 - f1_26: 0.6877 - f1_27: 0.9318 - f1_29: 0.0000e+00 - f1_30: 0.7378 - f1_31: 0.8718 - f1_32: 0.9966 - f1_34: 0.0000e+00 - f1_35: 0.9652 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.7134 - f1_41: 0.9938 - f1_44: 0.7289 - f1_45: 0.9811 - val_loss: 0.0520 - val_accuracy: 0.9855 - val_f1: 0.4909 - val_f1_1: 0.7859 - val_f1_2: 0.7932 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6599 - val_f1_5: 0.5133 - val_f1_6: 0.8679 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9632 - val_f1_12: 0.9468 - val_f1_13: 0.9671 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.5375 - val_f1_17: 0.7729 - val_f1_18: 0.0455 - val_f1_19: 0.8643 - val_f1_20: 0.9467 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9774 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8059 - val_f1_25: 0.0000e+00 - val_f1_26: 0.5712 - val_f1_27: 0.9241 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6733 - val_f1_31: 0.8158 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9423 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6573 - val_f1_41: 0.9846 - val_f1_44: 0.6575 - val_f1_45: 0.9675\n",
            "Epoch 37/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0404 - accuracy: 0.9890 - f1: 0.5171 - f1_1: 0.8252 - f1_2: 0.8411 - f1_3: 0.0000e+00 - f1_4: 0.7726 - f1_5: 0.6020 - f1_6: 0.9185 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9691 - f1_12: 0.9720 - f1_13: 0.9717 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.5899 - f1_17: 0.8510 - f1_18: 0.0312 - f1_19: 0.9146 - f1_20: 0.9506 - f1_21: 0.0000e+00 - f1_22: 0.9824 - f1_23: 0.0000e+00 - f1_24: 0.8818 - f1_25: 0.0000e+00 - f1_26: 0.6651 - f1_27: 0.9375 - f1_29: 0.0000e+00 - f1_30: 0.7480 - f1_31: 0.8734 - f1_32: 0.9966 - f1_34: 0.0000e+00 - f1_35: 0.9668 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.7074 - f1_41: 0.9934 - f1_44: 0.7334 - f1_45: 0.9875 - val_loss: 0.0515 - val_accuracy: 0.9855 - val_f1: 0.4952 - val_f1_1: 0.7792 - val_f1_2: 0.8003 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6632 - val_f1_5: 0.5310 - val_f1_6: 0.8630 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9646 - val_f1_12: 0.9468 - val_f1_13: 0.9666 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.5530 - val_f1_17: 0.7806 - val_f1_18: 0.2136 - val_f1_19: 0.8632 - val_f1_20: 0.9476 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9670 - val_f1_23: 0.0000e+00 - val_f1_24: 0.8163 - val_f1_25: 0.0000e+00 - val_f1_26: 0.5533 - val_f1_27: 0.9257 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6454 - val_f1_31: 0.8038 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9445 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6603 - val_f1_41: 0.9846 - val_f1_44: 0.6554 - val_f1_45: 0.9835\n",
            "Epoch 38/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0397 - accuracy: 0.9892 - f1: 0.5203 - f1_1: 0.8423 - f1_2: 0.8408 - f1_3: 0.0000e+00 - f1_4: 0.7729 - f1_5: 0.6195 - f1_6: 0.9159 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9701 - f1_12: 0.9746 - f1_13: 0.9744 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.6439 - f1_17: 0.8491 - f1_18: 0.0729 - f1_19: 0.9103 - f1_20: 0.9513 - f1_21: 0.0000e+00 - f1_22: 0.9835 - f1_23: 0.0000e+00 - f1_24: 0.8816 - f1_25: 0.0000e+00 - f1_26: 0.6559 - f1_27: 0.9340 - f1_29: 0.0000e+00 - f1_30: 0.7422 - f1_31: 0.8721 - f1_32: 0.9965 - f1_34: 0.0000e+00 - f1_35: 0.9647 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.7184 - f1_41: 0.9943 - f1_44: 0.7461 - f1_45: 0.9851 - val_loss: 0.0508 - val_accuracy: 0.9857 - val_f1: 0.5050 - val_f1_1: 0.7872 - val_f1_2: 0.8071 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6599 - val_f1_5: 0.5359 - val_f1_6: 0.8674 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9656 - val_f1_12: 0.9468 - val_f1_13: 0.9678 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.5707 - val_f1_17: 0.7738 - val_f1_18: 0.4944 - val_f1_19: 0.8623 - val_f1_20: 0.9480 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9776 - val_f1_23: 0.0519 - val_f1_24: 0.8153 - val_f1_25: 0.0000e+00 - val_f1_26: 0.5606 - val_f1_27: 0.9263 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6092 - val_f1_31: 0.8163 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9458 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6674 - val_f1_41: 0.9846 - val_f1_44: 0.6760 - val_f1_45: 0.9875\n",
            "Epoch 39/40\n",
            "16/16 [==============================] - 33s 2s/step - loss: 0.0388 - accuracy: 0.9894 - f1: 0.5405 - f1_1: 0.8435 - f1_2: 0.8450 - f1_3: 0.0000e+00 - f1_4: 0.8010 - f1_5: 0.6162 - f1_6: 0.9160 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9708 - f1_12: 0.9703 - f1_13: 0.9687 - f1_14: 0.0000e+00 - f1_15: 0.0000e+00 - f1_16: 0.7183 - f1_17: 0.8576 - f1_18: 0.6635 - f1_19: 0.9182 - f1_20: 0.9530 - f1_21: 0.0000e+00 - f1_22: 0.9843 - f1_23: 0.0139 - f1_24: 0.8866 - f1_25: 0.0000e+00 - f1_26: 0.7237 - f1_27: 0.9387 - f1_29: 0.0000e+00 - f1_30: 0.7455 - f1_31: 0.8806 - f1_32: 0.9967 - f1_34: 0.0000e+00 - f1_35: 0.9681 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.7143 - f1_41: 0.9945 - f1_44: 0.7410 - f1_45: 0.9904 - val_loss: 0.0508 - val_accuracy: 0.9857 - val_f1: 0.5082 - val_f1_1: 0.7926 - val_f1_2: 0.8146 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6632 - val_f1_5: 0.5645 - val_f1_6: 0.8650 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9661 - val_f1_12: 0.9468 - val_f1_13: 0.9749 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.5837 - val_f1_17: 0.7409 - val_f1_18: 0.4771 - val_f1_19: 0.8708 - val_f1_20: 0.9494 - val_f1_21: 0.0000e+00 - val_f1_22: 0.9780 - val_f1_23: 0.0942 - val_f1_24: 0.8060 - val_f1_25: 0.0000e+00 - val_f1_26: 0.5581 - val_f1_27: 0.9327 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6428 - val_f1_31: 0.7996 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9469 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6954 - val_f1_41: 0.9824 - val_f1_44: 0.6947 - val_f1_45: 0.9936\n",
            "Epoch 40/40\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0381 - accuracy: 0.9897 - f1: 0.5391 - f1_1: 0.8468 - f1_2: 0.8457 - f1_3: 0.0000e+00 - f1_4: 0.7927 - f1_5: 0.6437 - f1_6: 0.9209 - f1_8: 0.0000e+00 - f1_9: 0.0000e+00 - f1_10: 0.0000e+00 - f1_11: 0.9709 - f1_12: 0.9705 - f1_13: 0.9714 - f1_14: 0.0214 - f1_15: 0.0000e+00 - f1_16: 0.6925 - f1_17: 0.8554 - f1_18: 0.5555 - f1_19: 0.9219 - f1_20: 0.9543 - f1_21: 0.0000e+00 - f1_22: 0.9828 - f1_23: 0.0156 - f1_24: 0.8900 - f1_25: 0.0000e+00 - f1_26: 0.7042 - f1_27: 0.9408 - f1_29: 0.0000e+00 - f1_30: 0.7565 - f1_31: 0.8785 - f1_32: 0.9968 - f1_34: 0.0000e+00 - f1_35: 0.9665 - f1_36: 0.0000e+00 - f1_37: 0.0000e+00 - f1_38: 0.0000e+00 - f1_39: 0.0000e+00 - f1_40: 0.7355 - f1_41: 0.9951 - f1_44: 0.7454 - f1_45: 0.9910 - val_loss: 0.0496 - val_accuracy: 0.9861 - val_f1: 0.5149 - val_f1_1: 0.7949 - val_f1_2: 0.8201 - val_f1_3: 0.0000e+00 - val_f1_4: 0.6632 - val_f1_5: 0.5460 - val_f1_6: 0.8688 - val_f1_8: 0.0000e+00 - val_f1_9: 0.0000e+00 - val_f1_10: 0.0000e+00 - val_f1_11: 0.9666 - val_f1_12: 0.9468 - val_f1_13: 0.9694 - val_f1_14: 0.0000e+00 - val_f1_15: 0.0000e+00 - val_f1_16: 0.6443 - val_f1_17: 0.7635 - val_f1_18: 0.5362 - val_f1_19: 0.8715 - val_f1_20: 0.9491 - val_f1_21: 0.0202 - val_f1_22: 0.9788 - val_f1_23: 0.1532 - val_f1_24: 0.8099 - val_f1_25: 0.0000e+00 - val_f1_26: 0.5876 - val_f1_27: 0.9282 - val_f1_29: 0.0000e+00 - val_f1_30: 0.6686 - val_f1_31: 0.8123 - val_f1_32: 0.9946 - val_f1_34: 0.0000e+00 - val_f1_35: 0.9481 - val_f1_36: 0.0000e+00 - val_f1_37: 0.0000e+00 - val_f1_38: 0.0000e+00 - val_f1_39: 0.0000e+00 - val_f1_40: 0.6845 - val_f1_41: 0.9824 - val_f1_44: 0.6960 - val_f1_45: 0.9893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#History f1 for class"
      ],
      "metadata": {
        "id": "87_kBxnCwm0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional LSTM Single"
      ],
      "metadata": {
        "id": "mY1QsJSErdEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_val_list = np.zeros(len(tag2index))\n",
        "for i in no_punct_indexes:\n",
        "  f1_val_list[i] = history.history['val_f1_{}'.format(i)][-1]\n",
        "f1_list = np.zeros(len(tag2index))\n",
        "for i in no_punct_indexes:\n",
        "  f1_list[i] = history.history['f1_{}'.format(i)][-1]"
      ],
      "metadata": {
        "id": "nbNUZ6RoZ_qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index2tag = {value : key for (key, value) in tag2index.items()}\n",
        "index2tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHprJp5QaCIj",
        "outputId": "96f9bc22-dd10-4eae-e2ea-19e81cc1f570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '-PAD-',\n",
              " 1: 'MD',\n",
              " 2: ':',\n",
              " 3: 'VBG',\n",
              " 4: 'DT',\n",
              " 5: 'VBZ',\n",
              " 6: 'NNPS',\n",
              " 7: 'LS',\n",
              " 8: 'JJS',\n",
              " 9: 'RB',\n",
              " 10: 'IN',\n",
              " 11: '.',\n",
              " 12: 'RBS',\n",
              " 13: 'RBR',\n",
              " 14: 'JJ',\n",
              " 15: '$',\n",
              " 16: 'PDT',\n",
              " 17: 'JJR',\n",
              " 18: 'FW',\n",
              " 19: \"''\",\n",
              " 20: 'UH',\n",
              " 21: 'SYM',\n",
              " 22: '#',\n",
              " 23: 'EX',\n",
              " 24: 'NNP',\n",
              " 25: 'PRP$',\n",
              " 26: '``',\n",
              " 27: 'WP',\n",
              " 28: 'VBD',\n",
              " 29: 'CD',\n",
              " 30: 'PRP',\n",
              " 31: 'VBN',\n",
              " 32: 'TO',\n",
              " 33: 'WDT',\n",
              " 34: '-LRB-',\n",
              " 35: 'NN',\n",
              " 36: 'RP',\n",
              " 37: 'CC',\n",
              " 38: 'WP$',\n",
              " 39: 'NNS',\n",
              " 40: 'VB',\n",
              " 41: 'WRB',\n",
              " 42: 'VBP',\n",
              " 43: '-RRB-',\n",
              " 44: 'POS',\n",
              " 45: ','}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in no_punct_indexes:\n",
        "  print('Tag: {} --- F1: {}'.format(index2tag[i], f1_list[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoPk9XRiaEgx",
        "outputId": "86e9f175-9ecb-463c-bf87-e891e55c95cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag: MD --- F1: 0.9861435294151306\n",
            "Tag: VBG --- F1: 0.7493252158164978\n",
            "Tag: DT --- F1: 0.9788863658905029\n",
            "Tag: VBZ --- F1: 0.9588452577590942\n",
            "Tag: NNPS --- F1: 0.11751893162727356\n",
            "Tag: LS --- F1: 0.0\n",
            "Tag: JJS --- F1: 0.3466314971446991\n",
            "Tag: RB --- F1: 0.805275022983551\n",
            "Tag: IN --- F1: 0.9687918424606323\n",
            "Tag: RBS --- F1: 0.0\n",
            "Tag: RBR --- F1: 0.12233494222164154\n",
            "Tag: JJ --- F1: 0.8203631639480591\n",
            "Tag: $ --- F1: 0.9957756400108337\n",
            "Tag: PDT --- F1: 0.0\n",
            "Tag: JJR --- F1: 0.40267324447631836\n",
            "Tag: FW --- F1: 0.0\n",
            "Tag: UH --- F1: 0.0\n",
            "Tag: SYM --- F1: 0.0\n",
            "Tag: # --- F1: 0.0\n",
            "Tag: EX --- F1: 0.8568181991577148\n",
            "Tag: NNP --- F1: 0.9108277559280396\n",
            "Tag: PRP$ --- F1: 0.9917356967926025\n",
            "Tag: WP --- F1: 0.8087154030799866\n",
            "Tag: VBD --- F1: 0.9111243486404419\n",
            "Tag: CD --- F1: 0.9593055844306946\n",
            "Tag: PRP --- F1: 0.9825718402862549\n",
            "Tag: VBN --- F1: 0.8007776141166687\n",
            "Tag: TO --- F1: 0.9987005591392517\n",
            "Tag: WDT --- F1: 0.9528353214263916\n",
            "Tag: -LRB- --- F1: 0.21488092839717865\n",
            "Tag: NN --- F1: 0.8850233554840088\n",
            "Tag: RP --- F1: 0.6825176477432251\n",
            "Tag: CC --- F1: 0.9842092394828796\n",
            "Tag: WP$ --- F1: 0.0\n",
            "Tag: NNS --- F1: 0.9016332030296326\n",
            "Tag: VB --- F1: 0.9372258186340332\n",
            "Tag: WRB --- F1: 0.8198766708374023\n",
            "Tag: VBP --- F1: 0.8664230108261108\n",
            "Tag: -RRB- --- F1: 0.3077380657196045\n",
            "Tag: POS --- F1: 0.9972181916236877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in no_punct_indexes:\n",
        "  print('Tag: {} --- Val_F1: {}'.format(index2tag[i], f1_val_list[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AIxv0xZaG9M",
        "outputId": "65461dda-d1f9-4239-a56c-d38762a131c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag: MD --- Val_F1: 0.9788373112678528\n",
            "Tag: VBG --- Val_F1: 0.6657767295837402\n",
            "Tag: DT --- Val_F1: 0.9766331315040588\n",
            "Tag: VBZ --- Val_F1: 0.9402310252189636\n",
            "Tag: NNPS --- Val_F1: 0.0\n",
            "Tag: LS --- Val_F1: 0.0\n",
            "Tag: JJS --- Val_F1: 0.27857139706611633\n",
            "Tag: RB --- Val_F1: 0.7402987480163574\n",
            "Tag: IN --- Val_F1: 0.9639914631843567\n",
            "Tag: RBS --- Val_F1: 0.0\n",
            "Tag: RBR --- Val_F1: 0.06666665524244308\n",
            "Tag: JJ --- Val_F1: 0.6955986022949219\n",
            "Tag: $ --- Val_F1: 1.0\n",
            "Tag: PDT --- Val_F1: 0.0\n",
            "Tag: JJR --- Val_F1: 0.17834965884685516\n",
            "Tag: FW --- Val_F1: 0.0\n",
            "Tag: UH --- Val_F1: 0.0\n",
            "Tag: SYM --- Val_F1: 0.0\n",
            "Tag: # --- Val_F1: 0.0\n",
            "Tag: EX --- Val_F1: 0.7788460850715637\n",
            "Tag: NNP --- Val_F1: 0.8303753733634949\n",
            "Tag: PRP$ --- Val_F1: 0.9856583476066589\n",
            "Tag: WP --- Val_F1: 0.6509846448898315\n",
            "Tag: VBD --- Val_F1: 0.8635262846946716\n",
            "Tag: CD --- Val_F1: 0.9145641922950745\n",
            "Tag: PRP --- Val_F1: 0.9753745198249817\n",
            "Tag: VBN --- Val_F1: 0.7211470007896423\n",
            "Tag: TO --- Val_F1: 1.0\n",
            "Tag: WDT --- Val_F1: 0.9214633107185364\n",
            "Tag: -LRB- --- Val_F1: 0.07499998807907104\n",
            "Tag: NN --- Val_F1: 0.8356114029884338\n",
            "Tag: RP --- Val_F1: 0.4931360185146332\n",
            "Tag: CC --- Val_F1: 0.9666814804077148\n",
            "Tag: WP$ --- Val_F1: 0.0\n",
            "Tag: NNS --- Val_F1: 0.8381580710411072\n",
            "Tag: VB --- Val_F1: 0.8715111613273621\n",
            "Tag: WRB --- Val_F1: 0.615029513835907\n",
            "Tag: VBP --- Val_F1: 0.8141612410545349\n",
            "Tag: -RRB- --- Val_F1: 0.18304841220378876\n",
            "Tag: POS --- Val_F1: 0.996587336063385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(np.arange(len(norm)),norm)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d_bdJYUHvgwV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0597f527-efa1-496b-8323-e92730984106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(np.arange(len(f1_val_list)),f1_val_list)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-tR6MRO4yYH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0df0be4c-6fac-4c26-b68a-38a970dc715a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 40 epochs, batch 128\n",
        "loss: 0.0370 - accuracy: 0.9900 - f1: 0.5324"
      ],
      "metadata": {
        "id": "sjumesASaNsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU"
      ],
      "metadata": {
        "id": "VyT-Bx6-s4NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_val_list = np.zeros(len(tag2index))\n",
        "for i in no_punct_indexes:\n",
        "  f1_val_list[i] = history_gru.history['val_f1_{}'.format(i)][-1]\n",
        "f1_list = np.zeros(len(tag2index))\n",
        "for i in no_punct_indexes:\n",
        "  f1_list[i] = history_gru.history['f1_{}'.format(i)][-1]"
      ],
      "metadata": {
        "id": "4_KTbH5qiUnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in no_punct_indexes:\n",
        "  print('Tag: {} --- F1: {}'.format(index2tag[i], f1_list[i]))"
      ],
      "metadata": {
        "id": "ldEgVDA5mC2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d316c7f-9156-470b-a1e7-cc7614579712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag: VBP --- F1: 0.8468422889709473\n",
            "Tag: NN --- F1: 0.8457183241844177\n",
            "Tag: LS --- F1: 0.0\n",
            "Tag: WP --- F1: 0.7927243709564209\n",
            "Tag: VBG --- F1: 0.6436706781387329\n",
            "Tag: VB --- F1: 0.920914888381958\n",
            "Tag: WP$ --- F1: 0.0\n",
            "Tag: # --- F1: 0.0\n",
            "Tag: SYM --- F1: 0.0\n",
            "Tag: DT --- F1: 0.9709360599517822\n",
            "Tag: PRP$ --- F1: 0.9704599380493164\n",
            "Tag: PRP --- F1: 0.9713515639305115\n",
            "Tag: JJR --- F1: 0.02142856828868389\n",
            "Tag: RBS --- F1: 0.0\n",
            "Tag: WDT --- F1: 0.6924791932106018\n",
            "Tag: NNP --- F1: 0.8554279208183289\n",
            "Tag: EX --- F1: 0.5554788708686829\n",
            "Tag: CD --- F1: 0.9218987226486206\n",
            "Tag: IN --- F1: 0.9542962908744812\n",
            "Tag: JJS --- F1: 0.0\n",
            "Tag: CC --- F1: 0.9827914834022522\n",
            "Tag: RBR --- F1: 0.01562499813735485\n",
            "Tag: VBD --- F1: 0.8899809122085571\n",
            "Tag: -RRB- --- F1: 0.0\n",
            "Tag: RP --- F1: 0.7042356133460999\n",
            "Tag: VBZ --- F1: 0.9407545924186707\n",
            "Tag: UH --- F1: 0.0\n",
            "Tag: JJ --- F1: 0.7564661502838135\n",
            "Tag: NNS --- F1: 0.8785240650177002\n",
            "Tag: TO --- F1: 0.9967885613441467\n",
            "Tag: -LRB- --- F1: 0.0\n",
            "Tag: MD --- F1: 0.9665321707725525\n",
            "Tag: WRB --- F1: 0.0\n",
            "Tag: PDT --- F1: 0.0\n",
            "Tag: FW --- F1: 0.0\n",
            "Tag: NNPS --- F1: 0.0\n",
            "Tag: RB --- F1: 0.7354747653007507\n",
            "Tag: $ --- F1: 0.9950757622718811\n",
            "Tag: VBN --- F1: 0.7454406023025513\n",
            "Tag: POS --- F1: 0.9909838438034058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in no_punct_indexes:\n",
        "  print('Tag: {} --- Val_F1: {}'.format(index2tag[i], f1_val_list[i]))"
      ],
      "metadata": {
        "id": "9V6FASVZkmKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301de13c-ec3a-44ba-e1cf-3ff724feb3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag: VBP --- Val_F1: 0.7949159741401672\n",
            "Tag: NN --- Val_F1: 0.8200640082359314\n",
            "Tag: LS --- Val_F1: 0.0\n",
            "Tag: WP --- Val_F1: 0.6632034778594971\n",
            "Tag: VBG --- Val_F1: 0.5459580421447754\n",
            "Tag: VB --- Val_F1: 0.8688127994537354\n",
            "Tag: WP$ --- Val_F1: 0.0\n",
            "Tag: # --- Val_F1: 0.0\n",
            "Tag: SYM --- Val_F1: 0.0\n",
            "Tag: DT --- Val_F1: 0.9666126370429993\n",
            "Tag: PRP$ --- Val_F1: 0.9468235373497009\n",
            "Tag: PRP --- Val_F1: 0.9694107174873352\n",
            "Tag: JJR --- Val_F1: 0.0\n",
            "Tag: RBS --- Val_F1: 0.0\n",
            "Tag: WDT --- Val_F1: 0.6443347334861755\n",
            "Tag: NNP --- Val_F1: 0.7635376453399658\n",
            "Tag: EX --- Val_F1: 0.536245584487915\n",
            "Tag: CD --- Val_F1: 0.8714964389801025\n",
            "Tag: IN --- Val_F1: 0.9491329193115234\n",
            "Tag: JJS --- Val_F1: 0.020202018320560455\n",
            "Tag: CC --- Val_F1: 0.9788094162940979\n",
            "Tag: RBR --- Val_F1: 0.15324674546718597\n",
            "Tag: VBD --- Val_F1: 0.8099042773246765\n",
            "Tag: -RRB- --- Val_F1: 0.0\n",
            "Tag: RP --- Val_F1: 0.5876192450523376\n",
            "Tag: VBZ --- Val_F1: 0.9282264113426208\n",
            "Tag: UH --- Val_F1: 0.0\n",
            "Tag: JJ --- Val_F1: 0.6686109900474548\n",
            "Tag: NNS --- Val_F1: 0.8123034834861755\n",
            "Tag: TO --- Val_F1: 0.994636595249176\n",
            "Tag: -LRB- --- Val_F1: 0.0\n",
            "Tag: MD --- Val_F1: 0.9481189250946045\n",
            "Tag: WRB --- Val_F1: 0.0\n",
            "Tag: PDT --- Val_F1: 0.0\n",
            "Tag: FW --- Val_F1: 0.0\n",
            "Tag: NNPS --- Val_F1: 0.0\n",
            "Tag: RB --- Val_F1: 0.6844725012779236\n",
            "Tag: $ --- Val_F1: 0.9823914170265198\n",
            "Tag: VBN --- Val_F1: 0.6960094571113586\n",
            "Tag: POS --- Val_F1: 0.98931485414505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(np.arange(len(f1_val_list)),f1_val_list)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "XIuDhGE58wQk",
        "outputId": "cd7cdd4c-afcf-4c48-a24e-8f1cd14f63e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, figsize=(8,6))\n",
        "fig.suptitle('Tags distribution in train split vs val f1 score')\n",
        "axs[0].bar(np.arange(len(norm)),norm)\n",
        "axs[1].bar(np.arange(len(f1_list)),f1_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "5Y7C-rfr8yGu",
        "outputId": "895a5339-6baf-4e2e-a5ef-e2db7fef8c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 46 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 219
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pylab import rcParams\n",
        "plt.bar(np.arange(len(total_val_tags)),total_val_tags*f1_val_list)\n",
        "rcParams['figure.figsize'] = 11, 11\n",
        "plt.title('Total validation tags per class multiplied by val f1 scores')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "XpicISoW9JI3",
        "outputId": "5896f3ff-65fb-459f-94d2-b13850517ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x792 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Evaluation"
      ],
      "metadata": {
        "id": "zCyIRGDdS485"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional LSTM Single"
      ],
      "metadata": {
        "id": "UsxRGR9eriMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences_X,  test_tags_y = [], []\n",
        "\n",
        "for s in test_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word_index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word_index['-OOV-'])\n",
        " \n",
        "    test_sentences_X.append(s_int)\n",
        "\n",
        "for s in test_tags:\n",
        "    test_tags_y.append([tag2index[t] for t in s])\n",
        "\n",
        "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')"
      ],
      "metadata": {
        "id": "sUZ9F2amtq-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = model.predict(test_sentences_X)\n",
        "\n",
        "y_pred = np.zeros((y_val_pred.shape[0], y_val_pred.shape[1]), dtype=int)\n",
        "for i in range(len(y_val_pred)):\n",
        "  for j in range(len(y_val_pred[i])):\n",
        "    y_pred[i][j] = np.argmax(y_val_pred[i][j])"
      ],
      "metadata": {
        "id": "b7uGU-eftvUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrb = [tag2index['-LRB-']]\n",
        "rrb = [tag2index['-RRB-']]\n",
        "canc = [tag2index['#']]\n",
        "dol = [tag2index['$']]\n",
        "\n",
        "punct_cat_classes = to_categorical([point, virg, weird_apex, single_apex, two_dots, pad, lrb, rrb, canc, dol], len(tag2index))\n",
        "\n",
        "cum_tags = np.zeros(len(tag2index))\n",
        "for i in punct_cat_classes:\n",
        "  cum_tags += i[0]\n",
        "where_tags = np.where(np.logical_not(cum_tags))\n",
        "no_punct_indexes = where_tags[0]"
      ],
      "metadata": {
        "id": "OpoOertF4Hzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the f1_score from sklearn"
      ],
      "metadata": {
        "id": "2_DoVNlxTDY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "tags_flat = test_tags_y.flatten()\n",
        "pred_flat = y_pred.flatten()\n",
        "\n",
        "f1_model = f1_score(tags_flat, pred_flat, labels = no_punct_indexes, average='macro', zero_division=0)\n",
        "f1_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWRGwHcaTeAh",
        "outputId": "18bf320c-8b84-4c0c-d288-b8bb92baf707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6305990841813212"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU"
      ],
      "metadata": {
        "id": "iyWie2hNtDMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences_X,  test_tags_y = [], []\n",
        "\n",
        "for s in test_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word_index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word_index['-OOV-'])\n",
        " \n",
        "    test_sentences_X.append(s_int)\n",
        "\n",
        "for s in test_tags:\n",
        "    test_tags_y.append([tag2index[t] for t in s])\n",
        "\n",
        "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')"
      ],
      "metadata": {
        "id": "jpnbLG2PtFfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = model_gru.predict(test_sentences_X)\n",
        "\n",
        "y_pred = np.zeros((y_val_pred.shape[0], y_val_pred.shape[1]), dtype=int)\n",
        "for i in range(len(y_val_pred)):\n",
        "  for j in range(len(y_val_pred[i])):\n",
        "    y_pred[i][j] = np.argmax(y_val_pred[i][j])"
      ],
      "metadata": {
        "id": "DyNEQH3ktFfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrb = [tag2index['-LRB-']]\n",
        "rrb = [tag2index['-RRB-']]\n",
        "canc = [tag2index['#']]\n",
        "dol = [tag2index['$']]\n",
        "\n",
        "punct_cat_classes = to_categorical([point, virg, weird_apex, single_apex, two_dots, pad, lrb, rrb, canc, dol], len(tag2index))\n",
        "\n",
        "cum_tags = np.zeros(len(tag2index))\n",
        "for i in punct_cat_classes:\n",
        "  cum_tags += i[0]\n",
        "where_tags = np.where(np.logical_not(cum_tags))\n",
        "no_punct_indexes = where_tags[0]"
      ],
      "metadata": {
        "id": "25cBPXx9tFfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the f1_score from sklearn"
      ],
      "metadata": {
        "id": "P1JbYllNtFfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "tags_flat = test_tags_y.flatten()\n",
        "pred_flat = y_pred.flatten()\n",
        "\n",
        "f1_model = f1_score(tags_flat, pred_flat, labels = no_punct_indexes, average='macro', zero_division=0)\n",
        "f1_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c47806-8394-42ad-d1ea-f92407e305e3",
        "id": "7aCoS4ydtFfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5770281111991045"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "usG1eafJvaQ4",
        "8iUsOu-UvaQ4",
        "I3qoNG45vaQ6",
        "FiO1v6SJmm37",
        "d4IenRMamtLg",
        "E2IN3Mh-m85T",
        "YbT_r953oBA5",
        "l0m_PqWUoRsV",
        "H2IfH0KupuHE",
        "vQ-YIIK8p5OS",
        "CGqAO48bqWLF",
        "bI0aK0FusnW-",
        "mY1QsJSErdEX",
        "VyT-Bx6-s4NI",
        "UsxRGR9eriMx",
        "iyWie2hNtDMy"
      ],
      "name": "Assignment_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}